{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Use Raw CSV's created in R to update SDE.Stream with CSCI scores"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Stream_Data_Update.ipynb\n",
    "Created: October 26th, 2023\n",
    "Last Updated: December 1, 2025\n",
    "Sarah Newsome, Tahoe Regional Planning Agency\n",
    "Evelyn Malamut, Tahoe Regional Planning Agency\n",
    "This python script was developed to update SDE with yearly bioassessment data\n",
    "\n",
    "This script uses Python 3.13.7 and was designed to be used with ArcGIS Pro python environment \"arcgispro-py3-plotly\", which refers to the default cloned Python environment with plotly installed as an additional library."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import arcpy\n",
    "from datetime import datetime\n",
    "import os\n",
    "import sys\n",
    "from sqlalchemy.engine import URL\n",
    "from sqlalchemy import create_engine\n",
    "import sqlalchemy as sa\n",
    "import pandas as pd\n",
    "from arcgis import GIS\n",
    "from arcgis.features import FeatureSet, GeoAccessor, GeoSeriesAccessor, FeatureLayer\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import requests\n",
    "\n",
    "gis = GIS()\n",
    "# # Set Pandas display options to show all rows and columns\n",
    "# pd.set_option('display.max_rows', None)\n",
    "# pd.set_option('display.max_columns', None)\n",
    "# in memory output file path\n",
    "wk_memory = \"memory\" + \"\\\\\"\n",
    "\n",
    "# set workspace and sde connections \n",
    "working_folder = r\"F:/Research and Analysis/Fisheries/Streams/Bioassessment/California Stream Condition Index/California Stream Condition Index/2024_CSCI\"\n",
    "arcpy.env.workspace = r\"C:/GIS/Scratch.gdb\"\n",
    "\n",
    "# network path to connection files\n",
    "filePath = r\"F:\\GIS\\DB_CONNECT\"\n",
    "\n",
    "# database file path \n",
    "sdeBase    = os.path.join(filePath, \"Vector.sde\")\n",
    "sdeCollect = os.path.join(filePath, \"Collection.sde\")\n",
    "\n",
    "# local variables\n",
    "fdata = os.path.join(sdeBase, \"sde.SDE.Monitoring\")\n",
    "## Final feature class to append to in Enterprise Geodatabase\n",
    "sdeStreams = os.path.join(sdeBase, \"sde.SDE.Monitoring\\sde.SDE.Stream\")\n",
    "\n",
    "originalcsv = os.path.join(working_folder, \"CSCI_Report_2024.csv\")\n",
    "locationcsv = os.path.join(working_folder, \"Stations_2024.csv\")\n",
    "\n",
    "if not os.path.exists(originalcsv):\n",
    "    print(f\"Error: File not found at {originalcsv}\")\n",
    "\n",
    "if not os.path.exists(locationcsv):\n",
    "    print(f\"Error: File not found at {locationcsv}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to assign Station type and lat long and LTinfo website to Trend Sites\n",
    "\n",
    "\n",
    "#Calculate Rating for CSCI value\n",
    "#Define a function to categorize values based on ranges\n",
    "def categorize_value(value):\n",
    "    if 0 <= value < 0.6:\n",
    "        return 'poor'\n",
    "    elif 0.6 <= value < 0.8:\n",
    "        return 'marginal'\n",
    "    elif 0.8 <= value < 1.0:\n",
    "        return 'good'\n",
    "    else:\n",
    "        return 'excellent'\n",
    "    \n",
    "def get_fs_data(service_url):\n",
    "    \n",
    "    feature_layer = FeatureLayer(service_url)\n",
    "    query_result = feature_layer.query()\n",
    "    # Convert the query result to a list of dictionaries\n",
    "    feature_list = query_result.features\n",
    "\n",
    "    # Create a pandas DataFrame from the list of dictionaries\n",
    "    all_data = pd.DataFrame([feature.attributes for feature in feature_list])\n",
    "\n",
    "    return all_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create Dictionary Using Rest Service data\n",
    "# setup\n",
    "import pandas as pd\n",
    "from arcgis import GIS\n",
    "from arcgis.features import FeatureLayer\n",
    "\n",
    "# Connect to TRPA Enterprise GIS Portal *if it's a service only shared with org\n",
    "# portal_user = \"TRPA_PORTAL_ADMIN\"\n",
    "# portal_pwd = str(os.environ.get('Password'))\n",
    "# portal_url = \"https://maps.trpa.org/portal/\"\n",
    "\n",
    "# setup connection to GIS server this can be GIS() with a public service\n",
    "gis = GIS()\n",
    "\n",
    "\n",
    "# get Stream data as a Spatially Enabled Dataframe\n",
    "service_url = 'https://maps.trpa.org/server/rest/services/LTInfo_Monitoring/MapServer/8'\n",
    "feature_layer = FeatureLayer(service_url)\n",
    "query_result = feature_layer.query()\n",
    "\n",
    "# Convert the query result to a Spatially Enabled Dataframe\n",
    "sdfStreamHab = query_result.sdf\n",
    "\n",
    "sdfStreamHab.info()\n",
    "columnstokeep = ['SITE_NAME','STATION_TYPE', 'LATITUDE', 'LONGITUDE', 'LTINFO']\n",
    "sdfStreamHab = sdfStreamHab.loc[:, columnstokeep]\n",
    "unique_values = sdfStreamHab.drop_duplicates()\n",
    "\n",
    "# Select specific columns for look up\n",
    "selected_columns = ['STATION_TYPE', 'LATITUDE', 'LONGITUDE', 'LTINFO']\n",
    "\n",
    "# Convert selected columns to dictionary\n",
    "lookup_dict = unique_values.set_index('SITE_NAME')[selected_columns].to_dict(orient='index')\n",
    "\n",
    "# Display the dictionary\n",
    "print(lookup_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Transform CSCI Scores to Point feature class in Enterprise Geodatabase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create DataFrames from CSV files\n",
    "#For 2024 data add locations of new data and label in similar way\n",
    "dfCSCI = pd.read_csv(originalcsv)\n",
    "dflocations = pd.read_csv(locationcsv)\n",
    "\n",
    "# # Append DataFrames from additional CSV files\n",
    "# dfCSCI = dfCSCI.append(pd.read_csv(originalcsv), ignore_index=True)\n",
    "# dflocations = dflocations.append(pd.read_csv(locationcsv), ignore_index=True)\n",
    "\n",
    "# merge CSCI scores and location data\n",
    "RawData_df = pd.merge(dfCSCI, dflocations, how='inner', on='StationCode')\n",
    "\n",
    "try:\n",
    "    dfCSCI = pd.read_csv(originalcsv)\n",
    "except FileNotFoundError:\n",
    "    print(\"File not found. Please check the file path.\")\n",
    "except pd.errors.EmptyDataError:\n",
    "    print(\"The CSV file is empty.\")\n",
    "except pd.errors.ParserError:\n",
    "    print(\"Error parsing the CSV file.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get year from sample id\n",
    "RawData_df['Year']=RawData_df.SampleID.str.split(\"_\").str[-1]\n",
    "\n",
    "#Calculate Station Type \n",
    "RawData_df['STATION_TYPE'] = RawData_df['StationCode'].map(lambda x: lookup_dict[x]['STATION_TYPE'] if x in lookup_dict else 'Status')\n",
    "\n",
    "#Calculate LATITUDE\n",
    "RawData_df['LATITUDE'] = RawData_df['StationCode'].map(lambda x: lookup_dict[x]['LATITUDE']if x in lookup_dict else None)\n",
    "RawData_df['LATITUDE'] = RawData_df['LATITUDE'].fillna(RawData_df['New_Lat'])\n",
    "#Calculate LONGITUDE\n",
    "RawData_df['LONGITUDE'] = RawData_df['StationCode'].map(lambda x: lookup_dict[x]['LONGITUDE']if x in lookup_dict else None)\n",
    "RawData_df['LONGITUDE'] = RawData_df['LONGITUDE'].fillna(RawData_df['New_Long'])\n",
    "#Caculate LTINFO\n",
    "RawData_df['LTINFO'] = RawData_df['StationCode'].map(lambda x: lookup_dict[x]['LTINFO'] if x in lookup_dict else None)\n",
    "\n",
    "#Use only for threshold?\n",
    "# Apply the categorization function to create the new field\n",
    "#RawData_df['Rating'] = RawData_df['CSCI'].apply(categorize_value)\n",
    "\n",
    "\n",
    "Field_Mapping={\n",
    "    'StationCode': 'SITE_NAME',\n",
    "    'Year': 'YEAR_OF_COUNT',\n",
    "    'LATITUDE': 'LATITUDE',\n",
    "    'LONGITUDE': 'LONGITUDE',\n",
    "    'CSCI': 'COUNT_VALUE',\n",
    "    'STATION_TYPE': 'STATION_TYPE',\n",
    "    'LTINFO': 'LTINFO'\n",
    "    \n",
    "}\n",
    "# rename fields based on field mappings\n",
    "df_final = RawData_df.rename(columns=Field_Mapping).drop(columns=[col for col in RawData_df.columns if col not in Field_Mapping])\n",
    "\n",
    "# establish duration field\n",
    "def assign_duration(stationtype):\n",
    "    if stationtype == 'Status' :\n",
    "        return 'One-time'\n",
    "    else:\n",
    "        return 'Long-term'\n",
    "df_final['DURATION']= df_final['STATION_TYPE'].apply(assign_duration)\n",
    "\n",
    "# station code is site name, site name is station code.\n",
    "df_final['STATION_CODE']=df_final['SITE_NAME']\n",
    "\n",
    "# export to csv for QA\n",
    "df_final.to_csv(os.path.join(working_folder,\"StreamCSCI_proccesed.csv\"), index= False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert CSV to point feature class with NAD1983 as coordinate system\n",
    "arcpy.management.XYTableToPoint(os.path.join(working_folder,\"StreamCSCI_proccesed.csv\"), \n",
    "                                \"NewCSCI_points\", \n",
    "                                \"LONGITUDE\", \"LATITUDE\",\n",
    "                                coordinate_system= arcpy.SpatialReference(4269))\n",
    "\n",
    "# project to UTM Zone 10N\n",
    "arcpy.Project_management(\"NewCSCI_points_test\", \"NewStream_CSCI_Projected\", 26910)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# THIS IS HITTING SDE - BE CAREFUL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "inputfc= \"NewStream_CSCI_Projected\"\n",
    "\n",
    "# disconnect all users\n",
    "print(\"\\nDisconnecting all users...\")\n",
    "arcpy.DisconnectUser(sdeBase, \"ALL\")\n",
    " \n",
    "# unregister the sde feature class as versioned\n",
    "print (\"\\nUnregistering feature dataset as versioned...\")\n",
    "arcpy.UnregisterAsVersioned_management(fdata,\"NO_KEEP_EDIT\",\"COMPRESS_DEFAULT\")\n",
    "print (\"\\nFinished unregistering feature dataset as versioned.\")\n",
    "\n",
    "arcpy.management.Append(inputfc, sdeStreams,\"NO_TEST\")\n",
    "\n",
    "# disconnect all users\n",
    "print(\"\\nDisconnecting all users...\")\n",
    "arcpy.DisconnectUser(sdeBase, \"ALL\")\n",
    "\n",
    "# register SDE feature class as versioned\n",
    "arcpy.RegisterAsVersioned_management(fdata, \"NO_EDITS_TO_BASE\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
