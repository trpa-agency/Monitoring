{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#AQ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Import Data\n",
    "import pandas as pd\n",
    "import arcpy\n",
    "import os\n",
    "\n",
    "# 1. Specify File Paths\n",
    "file_paths = [r\"F:\\\\Research and Analysis\\\\Air Quality\\\\Annual Reports DRI\\\\AQ data 2023.xlsx\",\n",
    "              r\"F:\\\\Research and Analysis\\\\Air Quality\\\\Annual Reports DRI\\\\AQ data 2022.xlsx\",\n",
    "              r\"F:\\\\Research and Analysis\\\\Air Quality\\\\Annual Reports DRI\\\\AQ data 2021.xlsx\",\n",
    "              r\"F:\\\\Research and Analysis\\\\Air Quality\\\\Annual Reports DRI\\\\AQ data 2020.xlsx\",\n",
    "              r\"F:\\\\Research and Analysis\\\\Air Quality\\\\Annual Reports DRI\\\\AQ data 2019.xlsx\"\n",
    "              ]\n",
    "\n",
    "# 2. Read Data from Each File Daily Data\n",
    "dfs = []  # List to store DataFrames from each file\n",
    "sheet_name = 'daily'  # Name of the sheet to read\n",
    "\n",
    "for file_path in file_paths:\n",
    "    df = pd.read_excel(file_path, sheet_name=sheet_name, header=[0, 1])\n",
    "    dfs.append(df)\n",
    "\n",
    "# 3. Concatenate DAirrames\n",
    "DailyAir_df= pd.concat(dfs, ignore_index=True)\n",
    "\n",
    "# Melt the DataFrame to long format\n",
    "df_long = DailyAir_df.melt(id_vars=[('SITE', 'date')], var_name=['id', 'variable'], value_name='value')\n",
    "\n",
    "# Rename columns for clarity\n",
    "df_long = df_long.rename(columns={('SITE', 'date'): 'date'})\n",
    "\n",
    "# 4. Clean and Transform Data\n",
    "df_long['date'] = df_long['date'].dt.strftime('%Y-%m-%d')  # Convert date to string format\n",
    "\n",
    "df_long['date'] = df_long['date'].astype(str)\n",
    "#rename variable values\n",
    "# These are the values currenlty in the variable column in sde \n",
    "# CO - 8 hr max(ppm)\n",
    "# NO2 - 1 hr max(ppm)\n",
    "# O3 - 8 hr max(ppm)\n",
    "# PM10 - 24 hr max (mg/m3)\n",
    "# PM 2.5 - 24 hr max(mg/m3)\n",
    "\n",
    "\n",
    "# drop rows with variable name RH,BP, RWD, RWD.1, RWS Tmp\n",
    "df_long = df_long[~df_long['variable'].isin(['RH', 'BP', 'RWD', 'RWD.1', 'RWS', 'Tmp'])]\n",
    "#Rename Variables in variable column\n",
    "df_long['variable'] = df_long['variable'].replace({\n",
    "    'COmax': 'CO - 1 hr max (ppm)', \n",
    "    'max8hrCO': 'CO - 8 hr max (ppm)', \n",
    "    'NO2_avg': 'N02 - annual mean (ppm)', \n",
    "    'NO2max': 'N02 - 1 hr max (ppm)', \n",
    "    'O3max': 'O3 - 1 hr max (ppm)', \n",
    "    'max8hrO3': 'O3 - 8 hr max (ppm)', \n",
    "    #'PM10max': 'PM 10 - 24 hr max (mg/m3)',\n",
    "    'PM10avg': 'PM 10 - 24 hr max (mg/m3)',\n",
    "    #'PM2.5max': 'PM 2.5 - 24 hr max (mg/m3)',\n",
    "    #'PM2.5avg': 'PM 2.5 - annual mean (mg/m3)',\n",
    "    'PM2.5avg.1': 'PM 2.5 - 24 hr max (mg/m3)',\n",
    "    'PM2.5avg': 'PM 2.5 - 24 hr max (mg/m3)',\n",
    "    #'PM2.5avg.1': 'PM 2.5 - annual mean (mg/m3)'\n",
    "})\n",
    "\n",
    "\n",
    "# Remove or replace non-numeric values in 'value' column\n",
    "# Drop rows with null values in the 'value' column\n",
    "df_long = df_long.dropna(subset=['value'])\n",
    "df_long['value'] = pd.to_numeric(df_long['value'], errors='coerce')\n",
    "\n",
    "# Convert 'value' column to float64\n",
    "df_long['value'] = df_long['value'].astype('float64')\n",
    "#FORMAT DATAFRAMES\n",
    "# Define the path to the scratch geodatabase\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 21677 entries, 0 to 38198\n",
      "Data columns (total 4 columns):\n",
      " #   Column    Non-Null Count  Dtype  \n",
      "---  ------    --------------  -----  \n",
      " 0   date      21677 non-null  object \n",
      " 1   id        21677 non-null  object \n",
      " 2   variable  21677 non-null  object \n",
      " 3   value     21228 non-null  float64\n",
      "dtypes: float64(1), object(3)\n",
      "memory usage: 846.8+ KB\n"
     ]
    }
   ],
   "source": [
    "df_long.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Table 'AQ_temp' created and populated in F:\\Research and Analysis\\Workspace\\Sarah\\Scratch.gdb\n"
     ]
    }
   ],
   "source": [
    "type_mapping = {\n",
    "    #'int64': 'LONG',\n",
    "    'float64': 'DOUBLE',\n",
    "    'object': 'TEXT',\n",
    "    'string': 'TEXT',\n",
    "    #'datetime64[ns]': 'DATE'\n",
    "}\n",
    " \n",
    "# Set up geodatabase and output table name\n",
    "gdb_path = r\"F:\\Research and Analysis\\Workspace\\Sarah\\Scratch.gdb\"\n",
    "output_table = \"AQ_temp\"\n",
    "output_path = f\"{gdb_path}\\\\{output_table}\"\n",
    "\n",
    "#Delete existing table if it exists\n",
    "if arcpy.Exists(output_path):\n",
    "    arcpy.management.Delete(output_path)\n",
    "    print(f\"Deleted existing table: {output_table}\")\n",
    "\n",
    "# Create the table in the geodatabase\n",
    "arcpy.management.CreateTable(gdb_path, output_table)\n",
    "\n",
    "# # Identify date columns (assume they are 'object' type but contain dates)\n",
    "# date_columns = [col for col in df_long.columns if pd.api.types.is_datetime64_any_dtype(df_long[col])]\n",
    "\n",
    "\n",
    "# Add fields based on DataFrame dtypes\n",
    "for col_name, dtype in df_long.dtypes.items():\n",
    "    arcgis_type = type_mapping.get(str(dtype), 'TEXT')  # Default to TEXT if dtype is unknown\n",
    "    if arcgis_type == 'TEXT':\n",
    "        arcpy.management.AddField(output_path, col_name, arcgis_type, field_length=255)\n",
    "    else:\n",
    "        arcpy.management.AddField(output_path, col_name, arcgis_type)\n",
    " \n",
    "# Insert data into the table\n",
    "with arcpy.da.InsertCursor(output_path, df_long.columns.tolist()) as cursor:\n",
    "    for _, row in df_long.iterrows():\n",
    "        cursor.insertRow(row.tolist())\n",
    " \n",
    "print(f\"Table '{output_table}' created and populated in {gdb_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data successfully appended to F:\\Research and Analysis\\Workspace\\Sarah\\Scratch.gdb\\AirQuality_Final\n"
     ]
    }
   ],
   "source": [
    "#OLD# 4. Save DataFrame to CSV (Temporary File)\n",
    "temp_csv = r\"C:\\Users\\snewsome\\Documents\\Monitoring data updates\\temp_air_quality.csv\"\n",
    "df_long.to_csv(temp_csv, index=False)\n",
    "\n",
    "# 5. Convert CSV to Table in Geodatabase\n",
    "gdb_path = r\"F:\\Research and Analysis\\Workspace\\Sarah\\Scratch.gdb\"\n",
    "table_name = \"AirQuality_Temp\"\n",
    "output_table = os.path.join(gdb_path, table_name)\n",
    "\n",
    "if arcpy.Exists(output_table):\n",
    "    arcpy.Delete_management(output_table)  # Ensure old data is removed\n",
    "\n",
    "arcpy.TableToTable_conversion(temp_csv, gdb_path, table_name)\n",
    "\n",
    "# 6. Append to Final Feature Class\n",
    "final_fc = os.path.join(gdb_path, \"AirQuality_Final\")\n",
    "\n",
    "if not arcpy.Exists(final_fc):\n",
    "    # Create the feature class if it does not exist\n",
    "    arcpy.CreateFeatureclass_management(gdb_path, \"AirQuality_Final\", \"POINT\")\n",
    "\n",
    "# Append new data\n",
    "arcpy.Append_management(output_table, final_fc, \"NO_TEST\")\n",
    "\n",
    "print(\"Data successfully appended to\", final_fc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
