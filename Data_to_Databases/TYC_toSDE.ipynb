{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import Data\n",
    "import pandas as pd\n",
    "import arcpy\n",
    "import os\n",
    "from datetime import datetime\n",
    "import pathlib\n",
    "import numpy as np\n",
    "from arcgis import GIS\n",
    "from arcgis.features import FeatureLayer\n",
    "from arcgis.geometry import SpatialReference\n",
    "from functools import reduce\n",
    "from sqlalchemy.engine import URL\n",
    "from sqlalchemy import create_engine\n",
    "\n",
    "tycdatafile_path = r\"F:\\Research and Analysis\\Vegetation\\TYC\\TYC 2024.xlsx\"\n",
    "sheet_name = '2023'  # Name of the sheet to read\n",
    "\n",
    "df = pd.read_excel(tycdatafile_path, sheet_name=sheet_name)#, header=[0, 1])\n",
    "\n",
    "#drop row 0\n",
    "df = df.drop(0)\n",
    "\n",
    "#make a copy of this data frame that includes Site Name and Columns with years\n",
    "df2 = df.copy()\n",
    "\n",
    "#drop all columns that are not Site Name or a year\n",
    "df2 = df2[[' SITE NAME', 2024, 2023, 2022, 2021, 2020]]\n",
    "\n",
    "#drop rows 65-71\n",
    "df2 = df2.drop([64,65,66,67,68,69,70,71])\n",
    "\n",
    "df_long = df2.melt(id_vars=[' SITE NAME'], var_name='YEAR_OF_COUNT', value_name='COUNT_VALUE')\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# set environement workspace to Scratch\n",
    "arcpy.env.workspace = r\"F:/Research and Analysis/Workspace/Evelyn/Scratch.gdb\"\n",
    "# # clear memory workspace\n",
    "# arcpy.management.Delete('memory')\n",
    "\n",
    "# overwrite true\n",
    "arcpy.env.overwriteOutput = True\n",
    "# Set spatial reference to NAD 1983 UTM Zone 10N\n",
    "sr = arcpy.SpatialReference(26910)\n",
    "\n",
    "# function to get sql connection for tabular TRPA data Collection.sde?\n",
    "# db options are 'tabular' or 'tahoebmpsde'??\n",
    "def get_conn(db):\n",
    "    # Get database user and password from environment variables on machine running script\n",
    "    db_user             = os.environ.get('DB_USER')\n",
    "    db_password         = os.environ.get('DB_PASSWORD')\n",
    "\n",
    "    # driver is the ODBC driver for SQL Server\n",
    "    driver              = 'ODBC Driver 17 for SQL Server'\n",
    "    # server names are\n",
    "    sql_12              = 'sql12'\n",
    "    \n",
    "    # make it case insensitive\n",
    "    db = db.lower()\n",
    "    # make sql database connection with pyodbc\n",
    "    if db == 'sde':\n",
    "        connection_string = f\"DRIVER={driver};SERVER={sql_12};DATABASE={db};UID={db_user};PWD={db_password}\"\n",
    "        connection_url = URL.create(\"mssql+pyodbc\", query={\"odbc_connect\": connection_string})\n",
    "        engine = create_engine(connection_url)\n",
    "    # else return None\n",
    "    else:\n",
    "        engine = None\n",
    "    # connection file to use in pd.read_sql\n",
    "    return engine\n",
    "\n",
    "\n",
    "# network path to connection files\n",
    "filePath = \"F:\\\\GIS\\\\DB_CONNECT\"\n",
    "### SDE Vector is where the data will go into staging tables \n",
    "sdeVector    = os.path.join(filePath, \"Vector.sde\")\n",
    "# local variables sdata is starting data and f data is finishing datatables\n",
    "sdemonitoring= os.path.join(sdeVector, \"sde.SDE.Monitoring\")\n",
    "#make this a spatial df\n",
    "tycdata_path = os.path.join(sdemonitoring, \"sde.SDE.Yellow_Cress\")\n",
    "\n",
    "# Initialize an empty list to store the data\n",
    "tycdata = []\n",
    "\n",
    "# Extract site names and coordinates\n",
    "with arcpy.da.SearchCursor(tycdata_path, [\"SITE_NAME\", \"SHAPE@XY\", \"LATITUDE\", \"LONGITUDE\", \"OWNER\", \"LTINFO_HYPERLINK\", \"SHAPE\"], spatial_reference=sr) as cursor:\n",
    "    for row in cursor:\n",
    "        site_name = row[0]  # Site name\n",
    "        X,Y = row[1]\n",
    "        latitude = row[2]  # Extract X (longitude) and Y (latitude)\n",
    "        longitude = row[3]\n",
    "        owner = row[4]  # Owner\n",
    "        ltinfo_hyperlink = row[5]  # LTINFO Hyperlink\n",
    "        tycdata.append([site_name, X, Y, latitude, longitude, owner, ltinfo_hyperlink])\n",
    "\n",
    "tyc_df = pd.DataFrame(tycdata, columns=[\"SITE_NAME\", \"X\", \"Y\", \"LATITUDE\", \"LONGITUDE\", \"OWNER\", \"LTINFO_HYPERLINK\"])\n",
    "\n",
    "# # Extract site names and coordinates\n",
    "# with arcpy.da.SearchCursor(tycdata_path, [\"SITE_NAME\", \"SHAPE@XY, \"OWNER\", \"LTINFO_HYPERLINK\", \"SHAPE\"]) as cursor:\n",
    "#     for row in cursor:\n",
    "#         site_name = row[0]  # Site name\n",
    "#         longitude, latitude = row[1]  # Extract X (longitude) and Y (latitude)\n",
    "#         owner = row[2]  # Owner\n",
    "#         ltinfo_hyperlink = row[3]  # LTINFO Hyperlink\n",
    "#         tycdata.append([site_name, latitude, longitude, owner, ltinfo_hyperlink])\n",
    "\n",
    "# Create a pandas DataFrame\n",
    "# tyc_df = pd.DataFrame(tycdata, columns=[\"SITE_NAME\", \"LATITUDE\", \"LONGITUDE\", \"OWNER\", \"LTINFO_HYPERLINK\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Standardize column name in df and change year to int before processing\n",
    "df_long.rename(columns={' SITE NAME': 'SITE_NAME'}, inplace=True)\n",
    "df_long['YEAR_OF_COUNT'] = df_long['YEAR_OF_COUNT'].astype(int) \n",
    "df_long['COUNT_VALUE'] = df_long['COUNT_VALUE'].replace('NS', None) #changing NS (no survey) to missing value (<NULL>) to be consistent with SDE\n",
    "\n",
    "\n",
    "# # Strip whitespace to avoid mismatches\n",
    "df_long['SITE_NAME'] = df_long['SITE_NAME'].astype(str).str.strip()\n",
    "tyc_df['SITE_NAME'] = tyc_df['SITE_NAME'].str.strip()\n",
    "\n",
    "# # Merge the two DataFrames on 'Site_Name', remove duplicates\n",
    "merged_df = pd.merge(df_long, tyc_df, on='SITE_NAME', how='left')\n",
    "merged_df = merged_df.drop_duplicates()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Deleted existing table: tyc_temp\n",
      "Table 'tyc_temp' created and populated in F:\\Research and Analysis\\Workspace\\Evelyn\\Scratch.gdb\n"
     ]
    }
   ],
   "source": [
    "type_mapping = {\n",
    "    'int32': 'LONG',\n",
    "    'float64': 'DOUBLE',\n",
    "    'object': 'TEXT',\n",
    "    'string': 'TEXT',\n",
    "    #'datetime64[ns]': 'DATE'\n",
    "}\n",
    " \n",
    "# Set up geodatabase and output table name\n",
    "gdb_path = r\"F:\\Research and Analysis\\Workspace\\Evelyn\\Scratch.gdb\"\n",
    "output_table = \"tyc_temp\"\n",
    "output_path = f\"{gdb_path}\\\\{output_table}\"\n",
    "\n",
    "#Delete existing table if it exists\n",
    "if arcpy.Exists(output_path):\n",
    "    arcpy.management.Delete(output_path)\n",
    "    print(f\"Deleted existing table: {output_table}\")\n",
    "\n",
    "# Create the table in the geodatabase\n",
    "arcpy.management.CreateTable(gdb_path, output_table)\n",
    "\n",
    "# Add fields based on DataFrame dtypes\n",
    "for col_name, dtype in merged_df.dtypes.items():\n",
    "    arcgis_type = type_mapping.get(str(dtype), 'TEXT')  # Default to TEXT if dtype is unknown\n",
    "    if arcgis_type == 'TEXT':\n",
    "        arcpy.management.AddField(output_path, col_name, arcgis_type, field_length=255)\n",
    "    else:\n",
    "        arcpy.management.AddField(output_path, col_name, arcgis_type)\n",
    " \n",
    "# Insert data into the table\n",
    "with arcpy.da.InsertCursor(output_path, merged_df.columns.tolist()) as cursor:\n",
    "    for _, row in merged_df.iterrows():\n",
    "        cursor.insertRow(row.tolist())\n",
    " \n",
    "print(f\"Table '{output_table}' created and populated in {gdb_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div class='gpresult'><h2 class='msg-title'>Messages</h2><div id='messages'>Start Time: Thursday, November 6, 2025 11:31:57 AM<br>WARNING 040401: NULL geometry ignored. ObjectID = 24, 25, 29, 87, 88, 92, 150, 151, 155, 213, 214, 218, 276, 277, 281<br>Succeeded at Thursday, November 6, 2025 11:34:20 AM (Elapsed Time: 2 minutes 23 seconds)<br></div><div id = 'default' /></div></div>"
      ],
      "text/plain": [
       "<Result 'F:/Research and Analysis/Workspace/Evelyn/Scratch.gdb/NewTYC_points'>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "\n",
    "# convert CSV to point feature class\n",
    "arcpy.management.XYTableToPoint(output_path, \"NewTYC_points\", \n",
    "                                \"X\", \"Y\",\n",
    "                                coordinate_system= arcpy.SpatialReference(26910))\n",
    "\n",
    "#MIGHT NEED TO INCLUDE SR for gcs and pcs!! NAD 1983\n",
    "#arcpy.SpatialReference(4269, 26910)\n",
    "\n",
    "# arcpy.management.XYTableToPoint(output_path, \n",
    "#                                 \"NewTYC_points\", \n",
    "#                                 \"LONGITUDE\", \"LATITUDE\")\n",
    "\n",
    "# project to UTM Zone 10N\n",
    "#arcpy.Project_management(\"NewTYC_points\", \"NewTYC_points_Projected\", 26910)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fields ['X', 'Y'] deleted successfully from NewTYC_points.\n"
     ]
    }
   ],
   "source": [
    "# Removing X, Y field before adding to SDE\n",
    "\n",
    "# Specify the feature class and the fields to delete\n",
    "feature_class = \"NewTYC_points\"\n",
    "fields_to_delete = [\"X\", \"Y\"]\n",
    "\n",
    "# Delete the specified fields\n",
    "try:\n",
    "    arcpy.management.DeleteField(feature_class, fields_to_delete)\n",
    "    print(f\"Fields {fields_to_delete} deleted successfully from {feature_class}.\")\n",
    "except arcpy.ExecuteError:\n",
    "    print(arcpy.GetMessages(2))\n",
    "except Exception as e:\n",
    "    print(f\"An error occurred: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## UDPATE SDE\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
