{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#test\n",
    "\n",
    "import arcpy\n",
    "from datetime import datetime\n",
    "import os\n",
    "import sys\n",
    "from sqlalchemy.engine import URL\n",
    "from sqlalchemy import create_engine\n",
    "import sqlalchemy as sa\n",
    "import pandas as pd\n",
    "from arcgis import GIS\n",
    "from arcgis.features import FeatureSet, GeoAccessor, GeoSeriesAccessor, FeatureLayer\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import requests\n",
    "\n",
    "gis = GIS()\n",
    "# # Set Pandas display options to show all rows and columns\n",
    "# pd.set_option('display.max_rows', None)\n",
    "# pd.set_option('display.max_columns', None)\n",
    "# in memory output file path\n",
    "wk_memory = \"memory\" + \"\\\\\"\n",
    "\n",
    "# set workspace and sde connections \n",
    "working_folder = \"F:\\Research and Analysis\\Fisheries\\Streams\\Bioassessment\\California Stream Condition Index\\California Stream Condition Index\"\n",
    "workspace      = \"C:\\GIS\\Scratch.gdb\"\n",
    "arcpy.env.workspace = \"C:\\GIS\\Scratch.gdb\"\n",
    "\n",
    "# network path to connection files\n",
    "filePath = \"C:\\\\GIS\\\\DB_CONNECT\"\n",
    "\n",
    "# database file path \n",
    "sdeBase    = os.path.join(filePath, \"Vector.sde\")\n",
    "sdeCollect = os.path.join(filePath, \"Collection.sde\")\n",
    "\n",
    "# local variables\n",
    "fdata = os.path.join(sdeBase, \"sde.SDE.Monitoring\")\n",
    "## Final feature class to append to in Enterprise Geodatabase\n",
    "sdeStreams = os.path.join(sdeBase, \"sde.SDE.Monitoring\\sde.SDE.Stream\")\n",
    "## orginin CSVs that come from preprocessing or R tools created by State\n",
    "originalcsv = os.path.join(working_folder,\"2022_CSCI\",\"19-20NV-22allcore.csv\")\n",
    "locationcsv = os.path.join(working_folder, \"2022_CSCI\",\"Stations19_22.csv\")\n",
    "\n",
    "Field_Mapping={\n",
    "    'StationCode': 'SITE_NAME',\n",
    "    'Year': 'YEAR_OF_COUNT',\n",
    "    'New_Lat': 'LATITUDE',\n",
    "    'New_Long': 'LONGITUDE',\n",
    "    'CSCI': 'COUNT_VALUE',\n",
    "    'STATION_TYPE': 'STATION_TYPE'\n",
    "    \n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to map values based on the middle three characters\n",
    "def map_middle_three_chars(value):\n",
    "    middle_three = value[3:6]\n",
    "    if middle_three == 'REF':\n",
    "        return 'Reference'\n",
    "    # Add more conditions as needed\n",
    "    elif middle_three == 'TPA':\n",
    "        return 'Trend Panel A'\n",
    "    elif middle_three == 'TPB':\n",
    "        return 'Trend Panel B'\n",
    "    else:\n",
    "        return 'Targeted Monitoring'\n",
    "\n",
    "#Calculate Rating for CSCI value\n",
    "#Define a function to categorize values based on ranges\n",
    "def categorize_value(value):\n",
    "    if 0 <= value < 0.6:\n",
    "        return 'poor'\n",
    "    elif 0.6 <= value < 0.8:\n",
    "        return 'marginal'\n",
    "    elif 0.8 <= value < 1.0:\n",
    "        return 'good'\n",
    "    else:\n",
    "        return 'excellent'\n",
    "    \n",
    "def get_fs_data(service_url):\n",
    "    \n",
    "    feature_layer = FeatureLayer(service_url)\n",
    "    query_result = feature_layer.query()\n",
    "    # Convert the query result to a list of dictionaries\n",
    "    feature_list = query_result.features\n",
    "\n",
    "    # Create a pandas DataFrame from the list of dictionaries\n",
    "    all_data = pd.DataFrame([feature.attributes for feature in feature_list])\n",
    "\n",
    "    return all_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = get_fs_data('https://maps.trpa.org/server/rest/services/LTInfo_Monitoring/MapServer/8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 351 entries, 0 to 350\n",
      "Data columns (total 15 columns):\n",
      " #   Column            Non-Null Count  Dtype  \n",
      "---  ------            --------------  -----  \n",
      " 0   OBJECTID          351 non-null    int64  \n",
      " 1   STATION_CODE      351 non-null    object \n",
      " 2   SITE_NAME         351 non-null    object \n",
      " 3   YEAR_OF_COUNT     351 non-null    int64  \n",
      " 4   LONGITUDE         351 non-null    float64\n",
      " 5   LATITUDE          351 non-null    float64\n",
      " 6   COUNT_VALUE       351 non-null    float64\n",
      " 7   STATION_TYPE      351 non-null    object \n",
      " 8   DURATION          351 non-null    object \n",
      " 9   LTINFO            351 non-null    object \n",
      " 10  GlobalID          351 non-null    object \n",
      " 11  created_user      68 non-null     object \n",
      " 12  created_date      68 non-null     float64\n",
      " 13  last_edited_user  68 non-null     object \n",
      " 14  last_edited_date  68 non-null     float64\n",
      "dtypes: float64(5), int64(2), object(8)\n",
      "memory usage: 41.3+ KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Transform CSCI Scores to Point feature class in Enterprise Geodatabase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create data fraems from csv\n",
    "dfCSCI=pd.read_csv(originalcsv)\n",
    "dflocations=pd.read_csv(locationcsv)\n",
    "# join data frames to get Lat Long in final output\n",
    "df=dfCSCI.merge(dflocations, how='inner', on='StationCode')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get year from sample id\n",
    "df['Year']=df.SampleID.str.split(\"_\").str[-1]\n",
    "\n",
    "#Calculate Station Type from middle three charcters in station code\n",
    "df['STATION_TYPE'] = df['StationCode'].apply(map_middle_three_chars)\n",
    "\n",
    "# Apply the categorization function to create the new field\n",
    "df['Rating'] = df['CSCI'].apply(categorize_value)\n",
    "\n",
    "# rename feils based on field mappings\n",
    "df_final = df.rename(columns=Field_Mapping).drop(columns=[col for col in df.columns if col not in Field_Mapping])\n",
    "\n",
    "# establish duration field\n",
    "df_final['DURATION']='Long-term'\n",
    "\n",
    "# link to the dashboard\n",
    "df_final['LTINFO']='https://monitoring.laketahoeinfo.org/MonitoringSite/Detail/285'\n",
    "\n",
    "# station code is site name, site name is station code.\n",
    "df_final['STATION_CODE']=df_final['SITE_NAME']\n",
    "\n",
    "# export to csv\n",
    "df_final.to_csv(os.path.join(working_folder,\"StreamCSCI_proccesed.csv\"), index= False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div class='gpresult'><h2>Messages</h2><div id='messages' data-messages='[\"Start Time: Wednesday, November 29, 2023 2:21:00 PM\",\"Succeeded at Wednesday, November 29, 2023 2:21:04 PM (Elapsed Time: 4.10 seconds)\"]' data-show='true'><div id = 'default' /></div></div>"
      ],
      "text/plain": [
       "<Result 'C:\\\\GIS\\\\Scratch.gdb\\\\NewStream_CSCI_Projected'>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# convert CSV to point feature class\n",
    "arcpy.management.XYTableToPoint(os.path.join(working_folder,\"StreamCSCI_proccesed.csv\"), \n",
    "                                \"NewCSCI_points\", \n",
    "                                \"LONGITUDE\", \"LATITUDE\")\n",
    "\n",
    "# project to UTM Zone 10N\n",
    "arcpy.Project_management(\"NewCSCI_points\", \"NewStream_CSCI_Projected\", 26910)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Disconnecting all users...\n",
      "\n",
      "Unregistering feature dataset as versioned...\n",
      "\n",
      "Finished unregistering feature dataset as versioned.\n",
      "\n",
      "Disconnecting all users...\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div class='gpresult'><h2>Messages</h2><div id='messages' data-messages='[\"Start Time: Wednesday, November 29, 2023 2:26:02 PM\",\"Succeeded at Wednesday, November 29, 2023 2:26:31 PM (Elapsed Time: 29.57 seconds)\"]' data-show='true'><div id = 'default' /></div></div>"
      ],
      "text/plain": [
       "<Result 'C:\\\\GIS\\\\DB_CONNECT\\\\Vector.sde\\\\sde.SDE.Monitoring'>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "inputfc= \"NewStream_CSCI_Projected\"\n",
    "\n",
    "# disconnect all users\n",
    "print(\"\\nDisconnecting all users...\")\n",
    "arcpy.DisconnectUser(sdeBase, \"ALL\")\n",
    " \n",
    "# unregister the sde feature class as versioned\n",
    "print (\"\\nUnregistering feature dataset as versioned...\")\n",
    "arcpy.UnregisterAsVersioned_management(fdata,\"NO_KEEP_EDIT\",\"COMPRESS_DEFAULT\")\n",
    "print (\"\\nFinished unregistering feature dataset as versioned.\")\n",
    "\n",
    "arcpy.management.Append(inputfc, sdeStreams,\"NO_TEST\")\n",
    "\n",
    "# disconnect all users\n",
    "print(\"\\nDisconnecting all users...\")\n",
    "arcpy.DisconnectUser(sdeBase, \"ALL\")\n",
    "\n",
    "# register SDE feature class as versioned\n",
    "arcpy.RegisterAsVersioned_management(fdata, \"NO_EDITS_TO_BASE\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Dev"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import raw tabular data from csv\n",
    "csci_data = pd.read_csv('Raw_Data\\csci_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pivot to new format\n",
    "grouping_columns = ['StationCode','STREAM_NAME', 'COUNTY']\n",
    "csci_data_flat = csci_data.pivot(index=grouping_columns, columns='SAMPLEDATE',values='CSCI')\n",
    "csci_data_flat = csci_data_flat.reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Code to create stream csci sampling stations\n",
    "stream_csci_input_layer = \"import\"\n",
    "unique_stream_samples = \"\"\n",
    "\n",
    "stations=[]\n",
    "# Create a search cursor to iterate through the original feature layer\n",
    "with arcpy.da.SearchCursor(stream_csci_input_layer, ['SITE_NAME']) as cursor:\n",
    "    for row in cursor:\n",
    "        value = row[0]\n",
    "        if value not in stations:\n",
    "            stations.append(value)\n",
    "\n",
    "# Create an insert cursor for the output feature layer\n",
    "with arcpy.da.InsertCursor(output_feature_layer, [unique_column]) as cursor:\n",
    "    for value in unique_values:\n",
    "        cursor.insertRow((value,))\n",
    "\n",
    "# Clean up\n",
    "del cursor\n",
    "\n",
    "# Optionally, save the output feature layer to a file\n",
    "arcpy.CopyFeatures_management(output_feature_layer, \"C:/Path/To/Your/Output/FeatureClassFile\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#New feature class with the sampling station\n",
    "\n",
    "merged_df = pd.merge(sdfCensus, tdc_flat, on='TRPAID', how='inner')\n",
    "columns_drop=['GlobalID', 'YEAR', 'created_date', 'created_user', 'last_edited_date', 'last_edited_user', 'Shape.STArea()', 'Shape.STLength()']\n",
    "merged_df = merged_df.drop(columns=columns_drop)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
