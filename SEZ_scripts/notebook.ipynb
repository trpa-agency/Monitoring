{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Angora Creek - tributary': 519, 'Angora Creek - upper': 520, 'Angora meadows - 1': 87, 'Angora meadows - 2': 90, 'Angora meadows - 3': 91, 'Angora meadows - 4': 143, 'Angora meadows - 5': 144, 'Angora meadows - 6': 142, 'Angora meadows - 7': 89, 'Angora meadows - 8': 88, 'Angora meadows - 9': 92, 'Angora meadows tributary - 1': 217, 'Angora meadows tributary - 2': 99, 'Angora meadows tributary - 3': 97, 'Angora meadows tributary - 4': 94, 'Angora meadows tributary - 5': 214, 'Angora meadows tributary - 6': 146, 'Angora meadows tributary - 7': 93, 'Angora meadows tributary - 8': 95, 'Angora meadows tributary - 9': 96, 'Angora tributary': 446, 'Antone meadows': 187, 'Baldwin marsh - 1': 160, 'Benwood meadows - 1': 129, 'Benwood meadows - 2': 131, 'Big Meadow - 1': 47, 'Big Meadow - 2': 48, 'Big Meadow - 3': 38, 'Big Meadow - 4': 39, 'Big Meadow - 5': 37, 'Big Meadow - 6': 40, 'Big meadow - 7': 126, 'Big Meadow Creek - lower': 521, 'Big Meadow Creek - upper': 491, 'Big Meadow Creek - upper 2': 522, 'Bijou meadows - 1': 115, 'Bijou meadows - 2': 116, 'Bijou meadows - 3': 164, 'Bijou meadows - private': 114, 'Bijou meadows - tributary 1': 226, 'Bijou Park Creek meadows - 1': 219, 'Bijou Park Creek meadows - 2': 166, 'Bijou Park Creek meadows - 3': 167, 'Bijou Park Creek meadows - 4': 163, 'Bijou Park Creek meadows - 5': 489, 'Bijou Park Creek meadows - 6': 488, 'Blackwood Creek - lower 1': 523, 'Blackwood Creek - lower 2': 596, 'Blackwood Creek - middle 1': 597, 'Blackwood Creek - middle 2': 524, 'Blackwood Creek - middle 3': 598, 'Blackwood Creek - middle 4': 525, 'Blackwood Creek - Upper 1': 599, 'Blackwood Creek - Upper 2': 526, 'Blackwood Creek - upper 3': 527, 'Blackwood meadows - 1': 66, 'Blackwood meadows - 3': 65, 'Buck Lake meadows': 176, 'Buddhas meadow': 168, 'Burke Creek - middle': 528, 'Burke Creek - upper': 503, 'Burke Creek meadows - 1': 171, 'Burke Creek meadows - 2': 3, 'Burke Creek tributary': 461, 'Burton Creek - lower': 633, 'Burton Creek - upper': 529, 'Carnelian Canyon Creek - lower': 620, 'Carnelian Canyon Creek - upper': 621, 'Cascade Creek - lower': 501, 'Cascade Creek - upper': 498, 'Casino meadows': 170, 'Christmas Valley meadows - 1': 136, 'Christmas Valley meadows - 2': 134, 'Christmas Valley meadows - 3': 130, 'Christmas Valley meadows - 4': 225, 'Cold Creek - Highland Woods': 110, 'Cold Creek - middle': 530, 'Cold Creek - tributary 1': 532, 'Cold Creek - tributary 2': 533, 'Cold Creek - tributary 3': 531, 'Cold Creek - upper': 534, 'Cold Creek tributary - 4': 465, 'Cold Creek tributary - 5': 466, 'Colony Inn meadows - lower': 169, 'Colony Inn meadows - upper': 485, 'Cookhouse meadow': 128, 'Deer Creek - headwaters': 535, 'Deer Creek - lower': 537, 'Deer Creek - middle': 538, 'Deer Creek - middle 2': 539, 'Deer Creek - upper': 536, 'Deer Creek meadows': 30, 'Dollar Creek - lower': 540, 'Dollar Creek - upper': 512, 'Eagle Creek': 497, 'Echo Creek - below lake': 541, 'Echo Creek - upper': 494, 'Edgewood Creek - middle': 542, 'Edgewood Creek tributary - 2 - headwaters': 462, 'Edgewood Creek tributary - 2 - lower': 476, 'Edgewood Creek tributary - 2 - upper': 635, 'Edgewood Creek tributary - 3 - lower': 628, 'Edgewood Creek tributary - 3 - upper': 629, 'Edgewood meadows': 221, 'Elks Club meadows - 1': 141, 'Elks Club meadows - 2': 85, 'Fallen Leaf meadows - 1': 154, 'Fallen Leaf meadows - 2': 155, 'Fallen Leaf meadows - 3': 147, 'Fallen Leaf meadows - 4': 76, 'First Creek - lower': 543, 'First Creek - upper': 516, 'Freel Meadows - 1': 25, 'Freel Meadows - 2': 24, 'Gardner meadow': 150, 'General Creek - lower': 544, 'General Creek - middle': 506, 'General Creek - upper': 545, 'General Creek meadows': 61, 'Ginny Lake Meadows': 193, 'Glen Alpine Creek - lower': 546, 'Glen Alpine Creek - upper': 606, 'Glenbrook Creek - middle': 510, 'Glenbrook Creek - upper': 547, 'Glenbrook meadows - 1': 177, 'Glenbrook meadows - 2': 178, 'Golden Bear meadows - 1': 212, 'Golden Bear meadows - 2': 196, 'Grass Lake Creek': 609, 'Grass Lake meadow': 127, 'Griff Creek - lower': 514, 'Griff Creek - tributary': 548, 'Griff Creek - upper': 549, 'Griff Creek meadows': 35, 'Haypress Meadows': 50, 'Heavenly Valley Creek - middle': 550, 'Heavenly Valley Creek - upper': 499, 'Heavenly Valley Creek meadows - 1': 111, 'Heavenly Valley Creek meadows - 2': 112, 'Heavenly Valley Creek meadows - 3': 152, 'Heavenly Valley Creek meadows - 4': 113, 'Hell Hole meadows - 1': 230, 'Hell Hole Meadows - 2': 8, 'Hidden Valley Creek - lower': 551, 'Hidden Valley Creek - upper': 552, 'High meadows - 1': 203, 'High meadows - 2': 198, 'High Meadows - 3': 200, 'High meadows - 4': 202, 'High meadows - 5': 201, 'High meadows - 6': 199, 'Homewood Canyon Creek - lower': 600, 'Homewood Canyon Creek - upper': 508, 'Incline Creek - lower': 553, 'Incline Creek - middle 1': 554, 'Incline Creek - middle 2': 555, 'Incline Creek - middle 3': 636, 'Incline Creek - ski run': 556, 'Incline Creek - upper': 557, 'Incline Lake meadows - 1': 192, 'Incline Lake meadows - 2': 190, 'Incline Village tributary - 1': 458, 'Incline Village tributary - 2': 459, 'Incline Village tributary - 3': 460, 'Incline Village tributary - 4': 457, 'Kahle meadows - 2': 204, 'Kahle meadows - 3': 172, 'Kahle meadows - 4': 468, 'Kahle meadows - 5': 118, 'Kahle meadows - 6': 469, 'Kahle meadows - 7': 119, 'Kahle meadows - 8': 486, 'Kingsbury meadows': 222, 'Lake Forest meadows - 1': 185, 'Lake Forest meadows - 2': 186, 'Lake Forest meadows - 3': 184, 'Lake Forest meadows - 4': 487, 'Lake Forest meadows - 5': 223, 'Lake Forest meadows - 6': 183, 'Lake Forest tributary': 624, 'Lakeshore meadows': 72, 'Logan House Creek - lower': 558, 'Logan House Creek - upper': 507, 'Logan House meadow': 13, 'Lonely Gulch Creek - lower': 559, 'Lonely Gulch Creek - middle': 560, 'Lonely Gulch Creek - upper': 504, 'Madden Creek': 561, 'Marlette Creek - lower': 562, 'Marlette Creek - old dam site': 564, 'Marlette Creek - south fork (lower)': 642, 'Marlette Creek - south fork (upper)': 563, 'Marlette Creek - upper': 631, 'Marlette Lake meadows': 32, 'McFaul Creek - lower': 565, 'McFual meadow': 71, 'McKinney Creek - lower': 566, 'McKinney Creek - middle': 567, 'McKinney Creek - upper': 505, 'McKinney tributary - 1': 626, 'McKinney tributary - 2': 453, 'Meeks Bay Lagoon': 235, 'Meeks Bay meadows - 1': 205, 'Meeks Bay meadows - 2': 207, 'Meeks Bay meadows - 3': 36, 'Meeks Bay meadows - 4': 206, 'Meeks Creek - upper': 502, 'Meiss meadows - 1': 123, 'Meiss meadows - 2': 122, 'Meiss meadows - 3': 124, 'Meiss meadows - 4': 210, 'Meiss meadows - 5': 209, 'Meyers meadow': 218, 'Meyers tributary - 1': 447, 'Meyers tributary - 2': 467, 'Mill Creek - lower': 568, 'Mill Creek - upper': 515, 'Mill Creek meadows': 234, 'Mount Rainier Drive meadows - 1': 215, 'Mount Rainier Drive meadows - 2': 216, 'Muskawi Drive meadows': 83, 'North Logan House Creek': 509, 'North Logan House meadows': 12, 'North Zephyr Creek - lower': 570, 'North Zephyr Creek - middle': 615, 'North Zephyr Creek - tributary': 569, 'North Zephyr Creek - upper': 571, 'Nottaway Drive meadows': 213, 'Osgood Creek - above road': 572, 'Osgood Creek - below road': 573, 'Osgood Swamp': 482, 'Paige meadows': 182, 'Pope marsh meadow': 483, 'Quail Creek - lower': 574, 'Quail Creek - upper': 575, 'Quail Creek meadow': 26, 'Rosewood Creek - lower': 576, 'Rosewood Creek - middle 1': 586, 'Rosewood Creek - middle 2': 587, 'Rosewood Creek - middle 3': 588, 'Rubicon Creek': 601, 'Rubicon Creek - tributary': 602, 'Rubicon Meadows': 60, 'Saxon Creek - headwaters': 495, 'Saxon Creek - upper': 641, 'Saxon Creek meadows - above Fountain Place 1': 2, 'Saxon Creek meadows - above Fountain Place 2': 102, 'Saxon Creek meadows - below Fountain Place': 1, 'Saxon Creek tributary meadows - 1': 101, 'Saxon Creek tributary meadows - 3': 100, 'Saxon Creek tributary meadows - 4': 140, 'Saxon Creek tributary meadows - 5': 197, 'Saxon Creek tributary meadows - 6': 139, 'Saxon Creek tributary meadows - 7': 231, 'Second Creek - lower': 591, 'Second Creek - lower 2': 592, 'Second Creek - middle': 593, 'Second Creek - upper': 517, 'Secret Harbor Creek - lower': 618, 'Secret Harbor Creek - upper': 619, 'Sierra Tract wetlands': 211, 'Ski Run meadows': 220, 'Sky meadows': 79, 'Skylandia SEZ': 622, 'Slaughterhouse Creek - lower': 614, 'Slaughterhouse Creek - middle': 616, 'Slaughterhouse Creek - upper': 617, 'Slaughterhouse Meadows - 1': 6, 'Slaughterhouse meadows - 2': 180, 'small meadow 1': 11, 'small meadow 10': 64, 'small meadow 100': 77, 'small meadow 105': 125, 'small meadow 111': 132, 'small meadow 112': 133, 'small meadow 113': 135, 'small meadow 116': 181, 'small meadow 13': 20, 'small meadow 14': 19, 'small meadow 15': 18, 'small meadow 16': 21, 'small meadow 17': 28, 'small meadow 19': 63, 'small meadow 2': 10, 'small meadow 20': 623, 'small meadow 21': 67, 'small meadow 22': 53, 'small meadow 23': 54, 'small meadow 24': 56, 'small meadow 25': 55, 'small meadow 26': 57, 'small meadow 27': 58, 'small meadow 28': 59, 'small meadow 29': 174, 'small meadow 3': 70, 'small meadow 30': 175, 'small meadow 32': 51, 'small meadow 35': 49, 'small meadow 36': 52, 'small meadow 40': 74, 'small meadow 5': 29, 'small meadow 50': 23, 'small meadow 51': 42, 'small meadow 52': 41, 'small meadow 54': 22, 'small meadow 56': 46, 'small meadow 57': 73, 'small meadow 58': 173, 'small meadow 59': 14, 'small meadow 6': 17, 'small meadow 7': 27, 'small meadow 8': 69, 'small meadow 82': 232, 'small meadow 9': 68, 'small meadow 92': 31, 'small meadow 93': 33, 'small meadow 95': 43, 'small meadow 96': 44, 'small meadow 98': 62, 'small meadow 99': 75, 'Snow Creek tributary - 1': 451, 'Snow Creek tributary - 2': 452, 'Snow Creek wetlands - 1': 188, 'Snow Creek wetlands - 2': 189, 'South Lake Tahoe - wetland 1': 229, 'South Lake Tahoe airport': 484, 'South Lake Tahoe tributary - 1': 463, 'South Lake Tahoe tributary - 2': 464, 'South Lake Tahoe tributary - 3': 627, 'Spooner meadows - 1': 233, 'Spooner meadows - 2': 179, 'Spooner meadows - 3': 120, 'Spooner meadows - 5': 121, 'Star Lake meadows': 45, 'Susquehana meadows - 1': 108, 'Susquehana meadows - 2': 107, 'Tahoe City meadow': 224, 'Tahoe City tributary - 1': 449, 'Tahoe City tributary - 2': 450, 'Tahoe Island meadows - 1': 158, 'Tahoe Island meadows - 2': 156, 'Tahoe Keys': 162, 'Tahoe Paradise golf course': 632, 'Tahoe Valley meadows - 1': 153, 'Tahoe Valley meadows - 2': 228, 'Tahoe Vista meadows': 227, 'Tallac Creek - abv highway - 1': 334, 'Tallac Creek - abv highway - 2': 604, 'Tallac Creek - tributary': 500, 'Tallac marsh': 159, 'Tallac meadows': 157, 'Taylor Creek': 605, 'Taylor Creek marsh': 208, 'Third Creek - headwaters': 585, 'Third Creek - lower': 577, 'Third Creek - lower 2': 578, 'Third Creek - middle': 581, 'Third Creek - middle 1': 579, 'Third Creek - middle 2': 580, 'Third Creek - upper 1': 582, 'Third Creek - upper 2': 584, 'Third Creek - upper 3': 583, 'Third Creek meadows - 1': 191, 'Third Creek meadows - 3': 34, 'Third Creek meadows - 4': 195, 'Third Creek meadows - 6': 194, 'Third Creek meadows - 7': 16, 'Third Creek meadows - 8': 15, 'Trout Creek - Highland Woods': 109, 'Trout Creek - tributary 2': 613, 'Trout Creek - tributary 3': 612, 'Trout Creek - upper': 496, 'Trout Creek above Black Bart': 149, 'Trout Creek below Black Bart': 161, 'Trout Creek headwaters meadows - 1': 137, 'Trout Creek headwaters meadows - 2': 9, 'Trout Creek meadows - above Fountain Place': 103, 'Trout Creek meadows - above Pioneer 1': 148, 'Trout Creek meadows - above Pioneer 2': 106, 'Trout Creek meadows - above Pioneer 3': 105, 'Trout Creek meadows - above Pioneer 4': 104, 'Upper Truckee River - Meyers': 138, 'Upper Truckee River - Tahoe Paradise': 7, 'UTR - Airport reach': 82, 'UTR - Christmas Valley 1': 608, 'UTR - Christmas Valley 3': 493, 'UTR - golf course meadows': 86, 'UTR - Johnson meadows - 2': 151, 'UTR - Johnson meadows - 3': 81, 'UTR - middle': 492, 'UTR - Reach 5': 80, 'UTR - Reach 6': 84, 'UTR - tributary 1': 610, 'UTR - tributary 3': 611, 'UTR - upper': 490, 'UTR - Washoe Meadows': 607, 'UTR marsh - Trout Creek side': 165, 'UTR Marsh - UTR side': 78, 'Van Sickle meadows': 117, 'Ward Creek - lower': 594, 'Ward Creek - middle': 595, 'Ward Creek - upper': 511, 'Ward Creek meadow': 625, 'Washoan Blvd meadows': 145, 'Washoe State Parks meadow - 1': 4, 'Washoe State Parks meadow - 2': 98, 'Watson Creek': 513, 'West Shore tributary - 1': 455, 'West Shore tributary - 2 - lower': 639, 'West Shore tributary - 2 - upper': 448, 'West Shore tributary - 3': 456, 'West Shore tributary - 4': 454, 'Woods Creek - lower': 589, 'Woods Creek - middle': 590, 'Woods Creek - upper': 518}\n",
      "{'UTR - upper': 236, 'Big Meadow Creek - upper': 237, 'UTR - middle': 238, 'UTR - Christmas Valley 3': 239, 'Echo Creek - upper': 240, 'Saxon Creek - headwaters': 241, 'Trout Creek - upper': 242, 'Eagle Creek': 243, 'Cascade Creek - upper': 244, 'Heavenly Valley Creek - upper': 245, 'Tallac Creek - tributary': 246, 'Cascade Creek - lower': 247, 'Meeks Creek - upper': 248, 'Burke Creek - upper': 249, 'Lonely Gulch Creek - upper': 250, 'McKinney Creek - upper': 251, 'General Creek - middle': 252, 'Logan House Creek - upper': 253, 'Homewood Canyon Creek - upper': 254, 'North Logan House Creek': 255, 'Glenbrook Creek - middle': 256, 'Ward Creek - upper': 257, 'Dollar Creek - upper': 258, 'Watson Creek': 259, 'Griff Creek - lower': 260, 'Mill Creek - upper': 261, 'First Creek - upper': 262, 'Second Creek - upper': 263, 'Woods Creek - upper': 264, 'Angora Creek - tributary': 265, 'Angora Creek - upper': 266, 'Big Meadow Creek - lower': 267, 'Big Meadow Creek - upper 2': 268, 'Blackwood Creek - lower 1': 269, 'Blackwood Creek - middle 2': 270, 'Blackwood Creek - middle 4': 271, 'Blackwood Creek - Upper 2': 272, 'Blackwood Creek - upper 3': 273, 'Burke Creek - middle': 274, 'Burton Creek - upper': 275, 'Cold Creek - middle': 276, 'Cold Creek - tributary 3': 277, 'Cold Creek - tributary 2': 278, 'Cold Creek - upper': 279, 'Deer Creek - headwaters': 280, 'Deer Creek - upper': 281, 'Deer Creek - lower': 282, 'Deer Creek - middle': 283, 'Deer Creek - middle 2': 284, 'Dollar Creek - lower': 285, 'Echo Creek - below lake': 286, 'Edgewood Creek - middle': 287, 'First Creek - lower': 288, 'General Creek - lower': 289, 'General Creek - upper': 290, 'Glen Alpine Creek - lower': 291, 'Glenbrook Creek - upper': 292, 'Griff Creek - tributary': 293, 'Griff Creek - upper': 294, 'Heavenly Valley Creek - middle': 295, 'Hidden Valley Creek - lower': 296, 'Hidden Valley Creek - upper': 297, 'Incline Creek - lower': 298, 'Incline Creek - middle 1': 299, 'Incline Creek - middle 2': 300, 'Incline Creek - ski run': 301, 'Incline Creek - upper': 302, 'Logan House Creek - lower': 303, 'Lonely Gulch Creek - lower': 304, 'Lonely Gulch Creek - middle': 305, 'Madden Creek': 306, 'Marlette Creek - lower': 307, 'Marlette Creek - south fork (upper)': 308, 'McFaul Creek - lower': 309, 'McKinney Creek - lower': 310, 'McKinney Creek - middle': 311, 'Mill Creek - lower': 312, 'North Zephyr Creek - tributary': 313, 'North Zephyr Creek - lower': 314, 'North Zephyr Creek - upper': 315, 'Osgood Creek - above road': 316, 'Osgood Creek - below road': 317, 'Quail Creek - lower': 318, 'Quail Creek - upper': 319, 'Rosewood Creek - lower': 320, 'Rosewood Creek - middle 1': 321, 'Rosewood Creek - middle 2': 322, 'Rosewood Creek - middle 3': 323, 'Rubicon Creek': 324, 'Rubicon Creek - tributary': 325, 'Second Creek - lower': 326, 'Second Creek - lower 2': 327, 'Second Creek - middle': 328, 'Secret Harbor Creek - lower': 329, 'Secret Harbor Creek - upper': 330, 'Slaughterhouse Creek - lower': 331, 'Slaughterhouse Creek - middle': 332, 'Slaughterhouse Creek - upper': 333, 'Taylor Creek': 335, 'Third Creek - headwaters': 336, 'Third Creek - lower': 337, 'Third Creek - lower 2': 338, 'Third Creek - middle 1': 339, 'Third Creek - middle': 340, 'Third Creek - middle 2': 341, 'Third Creek - upper 1': 342, 'Third Creek - upper 2': 343, 'Third Creek - upper 3': 344, 'Trout Creek - tributary 2': 345, 'Trout Creek - tributary 3': 346, 'UTR - Christmas Valley 1': 347, 'UTR - tributary 3': 348, 'UTR - tributary 1': 349, 'UTR - Washoe Meadows': 350, 'Ward Creek - lower': 351, 'Ward Creek - middle': 352, 'Woods Creek - lower': 353, 'Woods Creek - middle': 354, 'Glen Alpine Creek - upper': 355, 'Grass Lake Creek': 356, 'Meiss meadows - 1': 357, 'Christmas Valley meadows - 2': 358, 'Christmas Valley meadows - 1': 359, 'Trout Creek meadows - above Fountain Place': 360, 'Trout Creek meadows - above Pioneer 3': 361, 'Taylor Creek marsh': 362, 'UTR marsh - Trout Creek side': 363, 'small meadow 14': 364, 'Slaughterhouse meadows - 2': 365, 'Antone meadows': 366, 'Snow Creek wetlands - 1': 367, 'Saxon Creek meadows - below Fountain Place': 368, 'Saxon Creek meadows - above Fountain Place 1': 369, 'Hell Hole Meadows - 2': 371, 'Trout Creek headwaters meadows - 2': 372, 'small meadow 1': 373, 'Ginny Lake Meadows': 374, 'Third Creek meadows - 8': 375, 'Third Creek meadows - 7': 376, 'small meadow 15': 377, 'small meadow 13': 378, 'small meadow 16': 379, 'small meadow 50': 380, 'small meadow 111': 381, 'small meadow 7': 382, 'small meadow 17': 383, 'small meadow 92': 384, 'Marlette Lake meadows': 385, 'Third Creek meadows - 3': 386, 'Griff Creek meadows': 387, 'Meeks Bay meadows - 3': 388, 'Big Meadow - 4': 389, 'small meadow 52': 390, 'small meadow 95': 391, 'Star Lake meadows': 392, 'Big Meadow - 1': 393, 'Rubicon Meadows': 394, 'McFual meadow': 395, 'UTR Marsh - UTR side': 396, 'UTR - Reach 5': 397, 'UTR - Johnson meadows - 2': 398, 'UTR - Johnson meadows - 3': 399, 'UTR - Airport reach': 400, 'UTR - Reach 6': 401, 'UTR - golf course meadows': 402, 'Angora meadows - 1': 403, 'Angora meadows - 8': 404, 'Angora meadows - 2': 405, 'Angora meadows - 3': 406, 'Saxon Creek tributary meadows - 1': 407, 'Saxon Creek meadows - above Fountain Place 2': 408, 'Trout Creek meadows - above Pioneer 4': 409, 'Trout Creek meadows - above Pioneer 2': 410, 'Trout Creek meadows - above Pioneer 1': 411, 'Trout Creek - Highland Woods': 412, 'Cold Creek - Highland Woods': 413, 'Heavenly Valley Creek meadows - 1': 414, 'Heavenly Valley Creek meadows - 2': 415, 'Heavenly Valley Creek meadows - 3': 416, 'Heavenly Valley Creek meadows - 4': 417, 'Kahle meadows - 5': 418, 'Meiss meadows - 3': 419, 'Benwood meadows - 1': 420, 'Christmas Valley meadows - 3': 421, 'Benwood meadows - 2': 422, 'small meadow 113': 423, 'Angora meadows - 6': 424, 'Trout Creek above Black Bart': 425, 'Baldwin marsh - 1': 426, 'Trout Creek below Black Bart': 427, 'Burke Creek meadows - 1': 428, 'Buck Lake meadows': 429, 'Glenbrook meadows - 1': 430, 'Spooner meadows - 2': 431, 'Lake Forest meadows - 3': 432, 'Snow Creek wetlands - 2': 433, 'Incline Lake meadows - 2': 434, 'Third Creek meadows - 1': 435, 'High meadows - 2': 436, 'High meadows - 6': 437, 'High meadows - 4': 438, 'High meadows - 1': 439, 'Meeks Bay meadows - 2': 440, 'Meeks Bay meadows - 1': 441, 'Meiss meadows - 4': 442, 'Meiss meadows - 5': 443, 'Hell Hole meadows - 1': 444, 'Spooner meadows - 1': 445, 'Blackwood Creek - lower 2': 470, 'Blackwood Creek - middle 3': 471, 'Kahle meadows - 3': 472, 'Meeks Bay Lagoon': 473, 'Kahle meadows - 6': 474, 'North Zephyr Creek - middle': 475, 'Marlette Creek - old dam site': 477, 'Tallac Creek - abv highway - 2': 478, 'Blackwood Creek - middle 1': 479, 'Homewood Canyon Creek - lower': 480, 'Blackwood Creek - Upper 1': 481, 'Tallac Creek - abv highway - 1': 603, 'Marlette Creek - upper': 630, 'Burton Creek - lower': 634, 'Incline Creek - middle 3': 637, 'Lake Forest meadows - 4': 638, 'Saxon Creek - upper': 640, 'Marlette Creek - south fork (lower)': 643, 'Upper Truckee River - Tahoe Paradise': 370}\n"
     ]
    }
   ],
   "source": [
    "#Get modules\n",
    "#indicators\n",
    "from Incision import *\n",
    "from Headcuts import *\n",
    "from Erosion import *\n",
    "from Invasives import *\n",
    "from Bioassessment import *\n",
    "from Conifer import *\n",
    "from VegVigor import *\n",
    "from AOP import *\n",
    "from Habitat import *\n",
    "from Ditches import *\n",
    "from FormatStagingTables import *\n",
    "from SEZScores import *\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 1: Process Indicators Post To Staging Tables"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Process when new Data is Available = External Data Sources"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#CONIFER#\n",
    "#!!!No Need to update if there is no new information\n",
    "#Current code grabs old data which is already in staging table\n",
    "from Conifer import *\n",
    "df=get_conifersez_data_sql()\n",
    "readydf=process_conifer(df)\n",
    "post_conifer_data(df, draft=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#AOP#\n",
    "#!!! No need to update if there is no new information- \n",
    "# code isn't complete for new data- do manually for now until we set up a script for sde.aquaticorganismpassage_usfs\n",
    "#Current code grabs old data which is already in staging table\n",
    "from AOP import *\n",
    "#Get data from SEZ_Assessment Unit Table in sde (this indicator doesn't get updated much)\n",
    "df = get_aopsez_data_sql()\n",
    "#rename the sql data so that we can \n",
    "readydf = Process_aop(df)\n",
    "#post_AOP_data(readydf, draft=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#VEG VIGOR#\n",
    "#Use data from SEZTable until we get new lidar data\n",
    "df=get_sez_data_sql()\n",
    "#df= get_oldvegvig_data()\n",
    "post_Veg_data(df, draft=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#HABITAT FRAGmentation and DITCHES\n",
    "#LiDAR data? this shouldn't change much \n",
    "# we can use data in the sez_habfrag_score and sez_ditches_scores tables and manually change"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Process Every Year= In-house Monitoring Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#BIOASSESSMENT#done Update EVERY YEAR after Processing BMI Data and updating SDE.Stream\n",
    "#Last updated 2023 \n",
    "from Bioassessment import *\n",
    "# from Bioassessment import *\n",
    "df = get_bioassessment_data()\n",
    "#clean, process, grade data\n",
    "readydf = process_grade_bioassessment(df, 2023)\n",
    "#post data to sde.VECTOR.stage headcut table or csv\n",
    "post_bioassessment(readydf, draft=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Priorities: [2 'None' nan 3 4]\n",
      "Draft data written to F:\\GIS\\GIS_DATA\\Monitoring\\Invasive_Species\\2024 Data Processing\\processedinvasivedata_2020.csv successfully.\n"
     ]
    }
   ],
   "source": [
    "#INVASIVE SPECIES#done Update EVERY YEAR after QA of data in sde.Collect (no duplicates, wrong decimal values, etc)\n",
    "#Last updated with 2024 data\n",
    "from Invasives import *\n",
    "#Get USFS rest service data spatially joined to SEZ's\n",
    "usfsdf= get_USFSinvasive_data()\n",
    "#Get new invasive data from sde collect\n",
    "Idf = get_combined_survey_and_invasive_data()\n",
    "# *To process old data 2019-2022 uncomment the following line (this data come from GDB and not sde collect)\n",
    "#Idf = get_invasive_data_gdb()\n",
    "#clean, merge with external data/ format plant type names\n",
    "df = merge_format_prioritize_invasive(Idf, usfsdf, 2024)\n",
    "#Process Data and grade/rate assessment\n",
    "#*Be sure to update the priority list in \"F:\\GIS\\PROJECTS\\ResearchAnalysis\\SEZ\\Invasives Priority Lookup.csv\"/ o reven better iun the REPO\n",
    "#rate_invasives is in utils if you need to update that\n",
    "invasive_summary, invasive_priority_summary = process_grade_invasives(df)\n",
    "#Format Data so it is ready for final QA and create csv\n",
    "readydf= final_format_invasive(df, invasive_priority_summary)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Optional way of getting data into ARC GIS Pro\n",
    "#When uploading CSV directly instead of this you need to format Year data type=SHORT\n",
    "#invasives create table in scratch gdb... or just upload csv directly into ArcGIS Pro\n",
    "#post data to scratch gdb for ease of appending to sez_scores_invasives table \n",
    "#df =post_invasive()\n",
    "\n",
    "#CSV path\n",
    "QAd_path = r\"F:\\GIS\\GIS_DATA\\Monitoring\\Invasive_Species\\2024 Data Processing\\processedinvasivedata_2024.csv\"\n",
    "if not os.path.exists(QAd_path):\n",
    "    raise FileNotFoundError(f\"CSV file not found at {QAd_path}\")\n",
    "\n",
    "# Load CSV\n",
    "df = pd.read_csv(QAd_path)\n",
    "print(f\"✅ CSV loaded: {QAd_path}\")\n",
    "\n",
    "# Output paths\n",
    "gdb_path = r\"F:\\Research and Analysis\\Workspace\\Sarah\\Scratch.gdb\"\n",
    "output_table = \"invasive_temp\"\n",
    "output_table_path = os.path.join(gdb_path, output_table)\n",
    "\n",
    "# Delete existing table if exists\n",
    "if arcpy.Exists(output_table_path):\n",
    "    arcpy.management.Delete(output_table_path)\n",
    "    print(f\"✅ Deleted existing table: {output_table}\")\n",
    "\n",
    "# Create empty table\n",
    "arcpy.management.CreateTable(gdb_path, output_table)\n",
    "\n",
    "# Define field types explicitly\n",
    "field_types = {\n",
    "    \"Assessment_Unit_Name\": \"TEXT\",\n",
    "    \"Year\": \"SHORT\",\n",
    "    \"Invasives_Plant_Types\": \"TEXT\",\n",
    "    \"Invasives_Data_Source\": \"TEXT\",\n",
    "    \"Invasives_Number_of_Invasives\": \"DOUBLE\",\n",
    "    \"Invasives_Rating\": \"TEXT\",\n",
    "    \"Invasives_Scores\": \"DOUBLE\",\n",
    "    \"Invasives_Percent_Cover\": \"DOUBLE\"\n",
    "}\n",
    "\n",
    "# Add fields\n",
    "for field_name, field_type in field_types.items():\n",
    "    arcpy.management.AddField(output_table_path, field_name, field_type)\n",
    "    print(f\"➕ Added field: {field_name} ({field_type})\")\n",
    "\n",
    "# Make sure DataFrame only has the expected fields\n",
    "df = df[list(field_types.keys())]\n",
    "\n",
    "# Insert rows\n",
    "with arcpy.da.InsertCursor(output_table_path, df.columns.tolist()) as cursor:\n",
    "    for _, row in df.iterrows():\n",
    "        cursor.insertRow(row.tolist())\n",
    "\n",
    "print(f\"✅ Table '{output_table}' created and populated in {gdb_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Draft data written to F:\\GIS\\GIS_DATA\\Monitoring\\Stream_Headcut\\Processed_Headcut_Data\\processedheadcutdata_2024.csv successfully.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\snewsome\\Documents\\GitHub\\Monitoring\\SEZ_scripts\\Headcuts.py:70: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  headcutdf['Headcut_Size']=headcutdf['headcut_depth'].apply(categorize_headcut)\n"
     ]
    }
   ],
   "source": [
    "#HEADCUT#done#Update Every Year after QA of data in sde.Collect\n",
    "#Last Updated 2024\n",
    "from Headcuts import *\n",
    "#Get raw headcut data prior 2023 and earlier that is stored in gdbs in F:GIS/data/Monitoring/\n",
    "#df= get_allheadcut_data()\n",
    "#Get new headcut data from sde collect\n",
    "df = get_combined_survey_and_headcut_data()\n",
    "#clean, process, grade data\n",
    "readydf = process_grade_headcut(df, 2024)\n",
    "#Add Data(CSV created) to sde.sez_scores_headcut in Pro\n",
    "#QA: make sure decimal points are in the right spot\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Draft data written to F:\\GIS\\GIS_DATA\\Monitoring\\Channel_Incision\\Processed_Incision_Data\\processedincisiondata_2024.csv successfully.\n"
     ]
    }
   ],
   "source": [
    "#INCISION# Update Every Year after QA of data in sde.Collect\n",
    "#Last Updated 2024\n",
    "from Incision import *\n",
    "\n",
    "#Get raw incision data prior 2023 and earlier that is stored in gdbs in F:GIS/data/Monitoring/\n",
    "#df= get_allincision_data()\n",
    "#Get incision data from sde collect\n",
    "df = get_combined_survey_and_incision_data()\n",
    "#clean, process, grade data\n",
    "readydf = process_grade_incision(df, 2024)\n",
    "#Add Data(CSV created) to sde.sez_scores_incision in Pro\n",
    "#QA:get rid of Null values until you add this to the code for QA SEZ Type, Check calculated vs incision ratio to make sure caluclations make sense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data written to F:\\GIS\\GIS_DATA\\Monitoring\\Stream_Erosion\\Processed_Erosion_Data\\processederosiondata_2024.csv successfully.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\snewsome\\Documents\\GitHub\\Monitoring\\SEZ_scripts\\Erosion.py:48: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['bank_multiplier'] = df['Bank_Type'].map({'Both Banks': 2, 'One Bank': 1, 'No Bank': 0})\n",
      "c:\\Users\\snewsome\\Documents\\GitHub\\Monitoring\\SEZ_scripts\\Erosion.py:49: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['eroded_banks_per_row'] = df['Shape_Length'] * df['bank_multiplier']\n"
     ]
    }
   ],
   "source": [
    "#EROSION# Update Every Year after QA of data in sde.Collect\n",
    "#Last updated 2024\n",
    "from Erosion import *\n",
    "\n",
    "#Get raw erosion data prior 2023 and earlier that is stored in gdbs in F:GIS/data/Monitoring/\n",
    "df= get_erosion_data()\n",
    "\n",
    "#clean, process, grade data\n",
    "readydf = process_grade_erosion(df, 2024)\n",
    "#Add Data(CSV created) to sde.sez_scores_incision in Pro\n",
    "#QA: make sure decimal points are in the right spot, check for null values, check for duplicates, check for correct SEZ type"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 2: Staging Tables to Final Table"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from FormatStagingTables import *\n",
    "# Staging to final\n",
    "dfbanks = get_fs_data(bank_stability_url)\n",
    "dfbiotic = get_fs_data(biotic_integrity_url)\n",
    "dfconifer = get_fs_data(conifer_url)\n",
    "dfditch = get_fs_data(ditches_url)\n",
    "dfinvasive = get_fs_data(invasives_url)\n",
    "dfhabitat = get_fs_data(Hab_Frag_url)\n",
    "dfvegetation = get_fs_data(vegetation_url)\n",
    "dfincision = get_fs_data(incision_url)\n",
    "dfheadcuts = get_fs_data(headcuts_url)\n",
    "dfAOP = get_fs_data(AOP_url)\n",
    "dfSEZ = get_fs_data_spatial(SEZ_url)\n",
    "dfheadcuts.drop(columns=['small', 'medium', 'large'], inplace=True)\n",
    "#Format Staging Tables\n",
    "#format biotic data average if two streams in one assessment unit\n",
    "averaged_biotic_df=average_biotic_scores(dfbiotic)\n",
    "\n",
    "#Same for meadow(large polygon) and riverine(small polygon) data drop these columns because not needed in final merge, will assign SEZ ID later\n",
    "columns_to_drop = ['Year', 'SEZ_ID', 'GlobalID', 'last_edited_user', 'created_date', 'OBJECTID', 'created_user', 'last_edited_date']\n",
    "\n",
    "#Create Dictionary of Dataframes to adjust year to be in datashource column and not its own column\n",
    "yeartodatasource = {\n",
    "    'dfbanks': dfbanks,\n",
    "    'dfheadcuts': dfheadcuts,\n",
    "    'dfincision': dfincision,\n",
    "    'dfinvasive': dfinvasive\n",
    "}\n",
    "\n",
    "# Iterate over each DataFrame in meadowdata\n",
    "for name, df in yeartodatasource.items():\n",
    "    # Iterate over columns in the DataFrame\n",
    "    for col in df.columns:\n",
    "        # Check if the column name contains 'Data'\n",
    "        if 'Data_' in col:\n",
    "            # Add Year to the column if it contains 'Data'\n",
    "            df[col] = df[col].astype(str) + ', ' + df['Year'].astype(str)\n",
    "\n",
    "#Name dataframes so we can reference later\n",
    "largepolygondata= {'dfbanks': dfbanks, \n",
    "                'dfaveraged_biotic': averaged_biotic_df,\n",
    "                'dfconifer': dfconifer,\n",
    "                'dfditch': dfditch,\n",
    "                'dfinvasive': dfinvasive,\n",
    "                'dfhabitat': dfhabitat,\n",
    "                'dfvegetation': dfvegetation,\n",
    "                'dfincision': dfincision,\n",
    "                'dfheadcuts': dfheadcuts,\n",
    "                'dfAOP': dfAOP\n",
    "}\n",
    "\n",
    "\n",
    "#Staging Tables Riverine/ small polygons\n",
    "smallpolygondata = {'dfbanks': dfbanks, \n",
    "                'dfaveraged_biotic': averaged_biotic_df,\n",
    "                'dfconifer': dfconifer,\n",
    "                'dfditch': dfditch,\n",
    "                'dfinvasive': dfinvasive,\n",
    "                'dfhabitat': dfhabitat,\n",
    "                'dfvegetation': dfvegetation,\n",
    "                'dfincision': dfincision,\n",
    "                'dfheadcuts': dfheadcuts,\n",
    "                'dfAOP': dfAOP\n",
    "}\n",
    "\n",
    "\n",
    "# Process large polygon (meadow) and small polygon (riverine) data -\n",
    "#Get most recent scores for each indicator\n",
    "# Clean Data in each dataframe, assign SEZ ID to each assessment unit, add year to datasource column for formatting purposes\n",
    "processed_largepolygon_data = process_data(largepolygondata, lookup_dict, columns_to_drop)\n",
    "processed_smallpolygon_data = process_data(smallpolygondata, lookup_riverine, columns_to_drop)\n",
    "\n",
    "\n",
    "# Merge large polygon and small polygon data\n",
    "# Function to merge all DataFrames on multiple keys)\n",
    "# # #moved to formatstagingtables.py\n",
    "def merge_dataframes(data_dict, keys):\n",
    "    return reduce(lambda left, right: pd.merge(left, right, on=keys, how='inner'), data_dict.values())\n",
    "\n",
    "\n",
    "# # Merge small polygon DataFrames\n",
    "smallpolygon_df = merge_dataframes(processed_smallpolygon_data, ['SEZ_ID', 'Assessment_Unit_Name' ])\n",
    "\n",
    "# Merge large polygon DataFrames so all indicators that have data\n",
    "largepolygon_df = merge_dataframes(processed_largepolygon_data, ['SEZ_ID', 'Assessment_Unit_Name' ])\n",
    "\n",
    "\n",
    "# Append smallpolygon_df to largepolygon_df to have a complete list of all meadows and all sez ids\n",
    "final_combined_df = pd.concat([largepolygon_df, smallpolygon_df], ignore_index=True)\n",
    "\n",
    "# Print the final combined DataFrame to check\n",
    "#print(\"Final Combined DataFrame:\")\n",
    "print(final_combined_df)\n",
    "\n",
    "\n",
    "# # Join SEZinfo to combined df to get a dataframe with more info about each Assessment Unit\n",
    "# #Prep SEZ Baseline Data for assessment unit...will need to rethink if acreage changes.. or just manually change in sde\n",
    "keep_columns = ['SHAPE', 'Assessment_Unit_Name', 'Threshold_Year', 'SEZ_ID', 'Feature_Type', 'SEZ_Type', 'Ownership_Primary', 'Ownership_Secondary', 'Ownership_Secondary_2', 'Ownership_Secondary_3', 'Acres', 'Comments']\n",
    "# #dfSEZ is assessment unit information from SDE\n",
    "dfSEZ['SEZ_ID']= dfSEZ['SEZ_ID'].astype(int)\n",
    "dfSEZinfo= dfSEZ.loc[:,keep_columns].copy()\n",
    "\n",
    "#filter dfSEZinfo for threshol dyear ='2019'\n",
    "dfSEZinfo = dfSEZinfo[dfSEZinfo['Threshold_Year'] == '2019']\n",
    "\n",
    "# # Join SEZinfo to the combined_df using SEZ_ID\n",
    "final_df = pd.merge(final_combined_df, dfSEZinfo, on=['SEZ_ID', 'Assessment_Unit_Name'], how='right')\n",
    "#-----------------------------------\n",
    "# Define Year Data is processed\n",
    "#-----------------------------------\n",
    "# #Assign Threshold Calculations which is the Threshold Year--> is just the most recent data within the past 4 years\n",
    "final_df['Threshold_Year'] = 'test'\n",
    "\n",
    "# Step 1: Get the most recent year in the dataset\n",
    "#most_recent_year = final_df['Year'].max()\n",
    "\n",
    "# Step 2: Define the Threshold_Year based on the most recent year\n",
    "# If the data's year is within the last 4 years from the most recent year, it's considered valid\n",
    "#final_df['Threshold_Year'] = final_df['Year'].apply(\n",
    "#    lambda x: most_recent_year if most_recent_year - x <= 4 else None\n",
    "#)\n",
    "\n",
    "# Optional: Print to verify\n",
    "#print(f\"Most Recent Year: {most_recent_year}\")\n",
    "\n",
    "print(final_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove values for indicators based on sez type\n",
    "#Use old data from most recent year evaluation to fill in gaps. (data from 2019 that was updated with external data such as simon sedimentation ratings)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  Use new data and fill in nulls with old data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#Bring in Last year threshold scores for any indicators thataren't in our raw data- some bank stability came from our stream surveys but aren't in the data\n",
    "#Fill in any indicators that have missing data with data from 2019\n",
    "\n",
    "# Rename fields based on field mappings\n",
    "dfSEZprep = dfSEZ.rename(columns=field_mapping)\n",
    "\n",
    "# Ensure 'Threshold Year' is properly filtered\n",
    "dfSEZprep = dfSEZprep[dfSEZprep['Threshold Year'] == '2019']\n",
    "\n",
    "# Filter out columns in dfSEZprep that are not in final_df\n",
    "dfSEZprep = dfSEZprep[[col for col in final_df.columns if col in dfSEZprep.columns]]\n",
    "\n",
    "# Set SEZ_ID as index for both DataFrames\n",
    "final_df.set_index('SEZ_ID', inplace=True)\n",
    "dfSEZprep.set_index('SEZ_ID', inplace=True)\n",
    "\n",
    "# Ensure dfSEZprep has no duplicate SEZ_IDs\n",
    "dfSEZprep = dfSEZprep[~dfSEZprep.index.duplicated(keep='last')]\n",
    "\n",
    "# Align dfSEZprep index with final_df before filling missing values\n",
    "final_df = final_df.fillna(dfSEZprep.reindex(final_df.index))\n",
    "\n",
    "# Reset the index to restore SEZ_ID as a column\n",
    "final_df.reset_index(inplace=True)\n",
    "\n",
    "print(dfSEZprep)\n",
    "print(final_df)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## QA tool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#-------------\n",
    "#QAOnly\n",
    "#------------\n",
    "# #RUN FOR QA so you can see the resulting dataframe/scores/formatting etc.\n",
    "#CSV will be posteed to the SEZ_scripts folder in file explorer\n",
    "# List of columns to export (excluding 'geometry' or 'Shape')\n",
    "columns_to_export = [col for col in final_df.columns if col != 'SHAPE']\n",
    "final_df[columns_to_export].to_csv('ready_df.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Calcluate SEZ Quality based on SEZ Type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from SEZScores import *\n",
    "#Calculate Score based on SEZ_Type  #Future- make it so any indicator that isn't in the lists below for SEZ Type says NA\n",
    "#Use SEZ_Type to select only needed indicators for SEZ Type\n",
    "# Define the score columns needed for each SEZ Type\n",
    "# Function to get the score columns based on SEZ_Type\n",
    "\n",
    "\n",
    "# Apply the appropriate score columns based on SEZ_Type\n",
    "final_df['Score_Columns'] = final_df['SEZ_Type'].apply(get_score_columns)\n",
    "\n",
    "\n",
    "# Apply the score calculation to each row\n",
    "final_df[['Final_Total_Points', 'Final_Points_Possible']] = final_df.apply(calculate_scores, axis=1)\n",
    "\n",
    "# Calculate the final percent\n",
    "final_df['Final_Percent'] = final_df['Final_Total_Points'] / final_df['Final_Points_Possible']\n",
    "\n",
    "# Calculate the final rating and score\n",
    "final_df['Final_Rating'] = final_df['Final_Percent'].apply(rate_SEZ)\n",
    "final_df['Final_Score'] = final_df['Final_Rating'].apply(score_indicator)\n",
    "\n",
    "# Drop the temporary 'Score_Columns' column\n",
    "final_df = final_df.drop(columns=['Score_Columns'])\n",
    "print(final_df)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Final set up\n",
    "\n",
    "\n",
    "#Field Mapping\n",
    "field_mapping = {\n",
    "    'Assessment_Unit_Name': 'Assessment_Unit_Name',\n",
    "    'SHAPE': 'SHAPE',\n",
    "    'Threshold_Year': 'Threshold Year',\n",
    "    'Comments': 'Comments',\n",
    "    'SEZ_Type': 'SEZ_Type',\n",
    "    'Final_Rating': 'Final_Rating',\n",
    "    'Final_Percent': 'Final_Percent',\n",
    "    'SEZ_ID': 'SEZ_ID',\n",
    "    'Final_Points_Possible': 'Final_Points_Possible',\n",
    "    'Final_Total_Points': 'Final_Total_Points',\n",
    "    'Acres': 'Acres',\n",
    "    'AOP_BarriersPerMile':'AquaticOrganismPassage_Barriers',\n",
    "    'AOP_NumberofBarriers': 'AquaticOrganismPassage_NumberOf',\n",
    "    'AOP_Score': 'AquaticOrganismPassage_Score',\n",
    "    'AOP_Rating': 'AquaticOrganismPassage_Rating',\n",
    "    'AOP_StreamMiles': 'AquaticOrganismPassage_StreamMiles',\n",
    "    'AOP_DataSource': 'AquaticOrganismPassage_DataSour',\n",
    "    'Bank_Stability_Data_Source': 'Bank_Stability_Data_Source',\n",
    "    'Bank_Stability_Percent_Unstable': 'Bank_Stability_Percent_Unstable',\n",
    "    'Bank_Stability_Rating': 'Bank_Stability_Rating',\n",
    "    'Bank_Stability_Score': 'Bank_Stability_Score',\n",
    "    'Biotic_Integrity_Rating': 'Biotic_Integrity_Rating',\n",
    "    'Biotic_Integrity_CSCI': 'Biotic_Integrity_CSCI',\n",
    "    'Biotic_Integrity_Data_Source': 'Biotic_Integrity_Data_Source',\n",
    "    'Biotic_Integrity_Score': 'Biotic_Integrity_Score',\n",
    "    'Comments': 'Comments',\n",
    "    'Conifer_Percent_Encroached': 'Conifer_Encroachment_Percent_En',\n",
    "    'Conifer_Encroachment_Data_Sourc': 'Conifer_Encroachment_Data_Sourc',\n",
    "    'Conifer_Encroachment_Rating': 'Conifer_Encroachment_Rating',\n",
    "    'Conifer_Encroachment_Score': 'Conifer_Encroachment_Score',\n",
    "    'ConiferEncroachment_Comments': 'Conifer_Encroachment_Comments',\n",
    "    'Ditches_Data_Source': 'Ditches_Data_Source',\n",
    "    'Ditches_Length': 'Ditches_Length',\n",
    "    'Ditches_Meadow_Length': 'Ditches_Meadow_Length',\n",
    "    'Ditches_Percent': 'Ditches_Percent',\n",
    "    'Ditches_Rating': 'Ditches_Rating',\n",
    "    'Ditches_Score': 'Ditches_Score',\n",
    "    'Feature_Type': 'Feature_Type',\n",
    "    'Habitat_Frag_Data_Source': 'Habitat_Fragmentation_Data_Sour',\n",
    "    'Habitat_Frag_Impervious_Acres': 'Habitat_Fragmentation_Imperviou',\n",
    "    'Habitat_Frag_Percent_Impervious': 'Habitat_Fragmentation_Percent_I',\n",
    "    'Habitat_Frag_Rating': 'Habitat_Fragmentation_Rating',\n",
    "    'Habitat_Frag_Score': 'Habitat_Fragmentation_Score',\n",
    "    'Headcuts_Data_Source': 'Headcuts_Data_Source',\n",
    "    'Number_of_Headcuts': 'Headcuts_Number_of_Headcuts',\n",
    "    'Headcuts_Rating': 'Headcuts_Rating',\n",
    "    'Headcuts_Score': 'Headcuts_Score',\n",
    "    'Incision_Data_Source': 'Incision_Data_Source',\n",
    "    'Incision_Rating': 'Incision_Rating',\n",
    "    'Incision_Score': 'Incision_Score',\n",
    "    'Incision_Ratio': 'Incision_Ratio',\n",
    "    'Invasive_Percent_Cover': 'Invasive_Percent_Cover',\n",
    "    'Invasives_Rating': 'Invasive_Rating',\n",
    "    'Invasives_Data_Source': 'Invasives_Data_Source',\n",
    "    'Invasives_Number_of_Invasives': 'Invasives_Number_of_Invasives',\n",
    "    'Invasives_Plant_Types': 'Invasives_Plant_Types',\n",
    "    'Invasives_Scores': 'Invasives_Scores',\n",
    "    'NDVI_ID': 'NDVI_ID',\n",
    "    'Ownership_Primary': 'Ownership_Primary',\n",
    "    'Ownership_Secondary': 'Ownership_Secondary',\n",
    "    'Ownership_Secondary_2': 'Ownership_Secondary_2',\n",
    "    'Ownership_Secondary_3': 'Ownership_Secondary_3',\n",
    "    'VegetationVigor_DataSource': 'VegetationVigor_DataSource',\n",
    "    'VegetationVigor_Rating': 'VegetationVigor_Rating',\n",
    "    'VegetationVigor_Raw': 'VegetationVigor_Raw',\n",
    "    'VegetationVigor_Score': 'VegetationVigor_Score'\n",
    "}\n",
    "# Rename fields based on field mappings\n",
    "SEZscores_readydf = final_df.rename(columns=field_mapping).drop(columns=[col for col in final_df.columns if col not in field_mapping])\n",
    "\n",
    "\n",
    "print(SEZscores_readydf)\n",
    "#----------------------------------------------------\n",
    "#Post results to CSV in gis/projects/Researchanalysis/SEZ for further QA\n",
    "#----------------------------------------------------\n",
    " \n",
    "#export all columns but shape\n",
    "columns_to_export = [col for col in SEZscores_readydf.columns if col != 'SHAPE']\n",
    "#Store csv on F drive for QA/add comments manually on F drive and to change up comments later based on SEZ's that scores changed\n",
    "#final_results = \"F:\\GIS\\PROJECTS\\ResearchAnalysis\\SEZ\\Threshold24_SEZScores.csv\"\n",
    "\n",
    "# Write to excel\n",
    "#SEZscores_readydf[columns_to_export].to_excel(final_results, index=False)\n",
    "\n",
    "\n",
    "# Convert DataFrame to a list of dictionaries\n",
    "#data = readydf.to_dict(orient='records')\n",
    "\n",
    "# Get the field names from the field mapping\n",
    "#field_names = list(readydf.columns)\n",
    "\n",
    "# Append data to existing table\n",
    "#with arcpy.da.InsertCursor(allsezscores, field_names) as cursor:\n",
    " #   for row in data:\n",
    "  #      cursor.insertRow([row[field] for field in field_names])\n",
    "\n",
    "#print(\"Data appended to table successfully.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## QA Tools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#This creates a csv of score changes and all information in row \n",
    "\n",
    "#Before Final comparison do more QA\n",
    "    # Check to make sure there are 641 ASsessment Units\n",
    "    #Check Final Points and make sure there are no really low numbers could be missing data\n",
    "    #Check all staging tables for completeness- There are ratings A-D, check on null data for that SEZ\n",
    "    #other QA methods can be added to this list\n",
    "\n",
    "#Check to see which SEZ Scores Changed\n",
    "Threshold23sezdata= SEZscores_readydf\n",
    "Threshold19sezdata = dfSEZ\n",
    "\n",
    "# Merge the datasets on Assessment_Unit_Name and SEZ_ID\n",
    "merged_df = pd.merge(\n",
    "    Threshold23sezdata[['Assessment_Unit_Name', 'SEZ_ID', 'Final_Rating', 'SEZ_Type']],\n",
    "    Threshold19sezdata[['Assessment_Unit_Name', 'SEZ_ID', 'Final_Rating', 'SEZ_Type']],\n",
    "    on=['Assessment_Unit_Name', 'SEZ_ID'],\n",
    "    suffixes=('_2023', '_2019')\n",
    ")\n",
    "\n",
    "# Identify Assessment Unit Names with a change in Final Rating\n",
    "changed_scores_df = merged_df[merged_df['Final_Rating_2023'] != merged_df['Final_Rating_2019']]\n",
    "\n",
    "# List of Assessment Unit Names with a change in score\n",
    "changed_assessment_units = changed_scores_df[['Assessment_Unit_Name', 'SEZ_ID', 'Final_Rating_2023', 'Final_Rating_2019']]\n",
    "\n",
    "# Output the DataFrame with changed scores\n",
    "print(changed_scores_df)\n",
    "\n",
    "# Output the list of Assessment Unit Names with a change in score\n",
    "print(changed_assessment_units)\n",
    "\n",
    "#Post results to CSV in gis/projects/Researchanalysis/SEZ for further QA\n",
    "columns_to_export = [col for col in changed_assessment_units.columns if col != 'SHAPE']\n",
    "#Store csv on F drive for QA/add comments manually on F drive and to change up comments later based on SEZ's that scores changed\n",
    "#Changed_Scores_List = \"F:\\GIS\\PROJECTS\\ResearchAnalysis\\SEZ\\Threshold24_SEZScoreChanges.csv\"\n",
    "# Assuming ready_df is the DataFrame you want to write to CSV\n",
    "#changed_scores_df.to_csv(Changed_Scores_List, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Otion for different CSV Look at only changed scores so we can update comments and make sure data is good, need to run this to get long format csv\n",
    "# List of all columns with 'Rating' in their name for both datasets\n",
    "rating_columns_2023 = [col for col in Threshold23sezdata.columns if 'Rating' in col]\n",
    "rating_columns_2019 = [col for col in Threshold19sezdata.columns if 'Rating' in col]\n",
    "\n",
    "# Ensure both DataFrames have the same Assessment_Unit_Name and SEZ_ID columns\n",
    "Threshold23sezdata = Threshold23sezdata[['Assessment_Unit_Name', 'SEZ_ID'] + rating_columns_2023]\n",
    "Threshold19sezdata = Threshold19sezdata[['Assessment_Unit_Name', 'SEZ_ID'] + rating_columns_2019]\n",
    "\n",
    "# Merge the datasets on Assessment_Unit_Name and SEZ_ID, for units that have changed scores\n",
    "final_merged_df = pd.merge(\n",
    "    Threshold23sezdata,\n",
    "    Threshold19sezdata,\n",
    "    on=['Assessment_Unit_Name', 'SEZ_ID'],\n",
    "    suffixes=('_2023', '_2019')\n",
    ")\n",
    "\n",
    "# Filter the final merged DataFrame to only include units that changed scores\n",
    "final_changed_scores_df = final_merged_df[final_merged_df['Assessment_Unit_Name'].isin(changed_assessment_units['Assessment_Unit_Name'])]\n",
    "\n",
    "# Print the final DataFrame with all rating columns and changed scores\n",
    "print(final_changed_scores_df)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Save the final DataFrame to a CSV file\n",
    "#final_changed_scores_df.to_csv(\"F:\\GIS\\PROJECTS\\ResearchAnalysis\\SEZ\\Threshold24_SEZScoreChanges_indicators.csv\", index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#BEST QA csv.. shows indicators scores and final score changes by year of threshold\n",
    "#futureadd in final points and points possible and comments\n",
    "# Used changed changed_assessment_units to get Rating scores from df's \n",
    "#Create CSV with assessment units that have changed , all indicator scores and final rating by year and SEZID\n",
    "\n",
    "# List of all columns with 'Rating' in their name for both datasets\n",
    "rating_columns_2023 = [col for col in Threshold23sezdata.columns if 'Rating' in col]\n",
    "rating_columns_2019 = [col for col in Threshold19sezdata.columns if 'Rating' in col]\n",
    "\n",
    "# Ensure both DataFrames have the same Assessment_Unit_Name and SEZ_ID columns\n",
    "Threshold23sezdata = Threshold23sezdata[['Assessment_Unit_Name', 'SEZ_ID'] + rating_columns_2023]\n",
    "Threshold19sezdata = Threshold19sezdata[['Assessment_Unit_Name', 'SEZ_ID'] + rating_columns_2019]\n",
    "\n",
    "# Merge changed_assessment_units with Threshold23sezdata and Threshold19sezdata to get ratings for changed units\n",
    "merged_23 = pd.merge(changed_assessment_units, Threshold23sezdata, on=['Assessment_Unit_Name', 'SEZ_ID'])\n",
    "merged_19 = pd.merge(changed_assessment_units, Threshold19sezdata, on=['Assessment_Unit_Name', 'SEZ_ID'])\n",
    "\n",
    "# Extract columns with 'Rating' for both datasets\n",
    "rating_columns_2023 = [col for col in merged_23.columns if 'Rating' in col]\n",
    "rating_columns_2019 = [col for col in merged_19.columns if 'Rating' in col]\n",
    "\n",
    "# Filtered DataFrames with only relevant columns\n",
    "filtered_23 = merged_23[['Assessment_Unit_Name', 'SEZ_ID'] + rating_columns_2023]\n",
    "filtered_19 = merged_19[['Assessment_Unit_Name', 'SEZ_ID'] + rating_columns_2019]\n",
    "\n",
    "# Add a 'Year' column to each DataFrame\n",
    "filtered_23['Year'] = '2023'\n",
    "filtered_19['Year'] = '2019'\n",
    "\n",
    "# Concatenate filtered_23 and filtered_19 DataFrames\n",
    "allratings = pd.concat([filtered_23, filtered_19], ignore_index=True)\n",
    "\n",
    "\n",
    "#Function to map SEZ_Type based on Assessment_Unit_Name\n",
    "def get_sez_type(row):\n",
    "    return lookup_all.get(row['SEZ_ID'], {}).get('SEZ_Type', None)\n",
    "\n",
    "# Apply the function to add SEZ_Type column\n",
    "allratings['SEZ_Type'] = allratings.apply(get_sez_type, axis=1)\n",
    "\n",
    "# Apply the function to add SEZ_Type column\n",
    "allratings['SEZ_Type'] = allratings.apply(get_sez_type, axis=1)\n",
    "\n",
    "# Drop the specified columns from merged_df\n",
    "columns_to_drop = ['Final_Rating_2019', 'Final_Rating_2023']\n",
    "allratings.drop(columns=columns_to_drop, inplace=True)\n",
    "\n",
    "# Save the final long format DataFrame to a CSV file\n",
    "#allratings.to_csv(\"F:\\\\GIS\\\\PROJECTS\\\\ResearchAnalysis\\\\SEZ\\\\allchangedscores_longformat.csv\", index=False)\n",
    "\n",
    "allratings.to_csv(\"C:\\\\Users\\\\snewsome\\\\Documents\\\\SEZallchangedscores_longformat.csv\", index=False)\n",
    "\n",
    "# Note to SELF - when group editing csv and fixing comments for changed scores this must be in an excel and is easiest if put online into google office sheets. \n",
    "\n",
    "# I would like to code the comments eventually. For example if the Rating is a C then the comment should start with \"This meadow is moderately degraded yet stable since the scores have not changed in blank years. Describe the indicators that are causing the score to be what it is\""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
