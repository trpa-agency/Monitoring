{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Get modules\n",
    "#indicators\n",
    "from Incision import *\n",
    "from Headcuts import *\n",
    "from Erosion import *\n",
    "from Invasives import *\n",
    "from Bioassessment import *\n",
    "from Conifer import *\n",
    "from VegVigor import *\n",
    "from AOP import *\n",
    "from Habitat import *\n",
    "from Ditches import *\n",
    "from FormatStagingTables import *\n",
    "from SEZScores import *\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 1: Process Indicators Post To Staging Tables"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Process when new Data is Available = External Data Sources"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#CONIFER#\n",
    "#!!!No Need to update if there is no new information\n",
    "#Current code grabs old data which is already in staging table\n",
    "from Conifer import *\n",
    "df=get_conifersez_data_sql()\n",
    "readydf=process_conifer(df)\n",
    "post_conifer_data(df, draft=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#AOP#\n",
    "#!!! No need to update if there is no new information- \n",
    "# code isn't complete for new data- do manually for now until we set up a script for sde.aquaticorganismpassage_usfs\n",
    "#Current code grabs old data which is already in staging table\n",
    "from AOP import *\n",
    "#Get data from SEZ_Assessment Unit Table in sde (this indicator doesn't get updated much)\n",
    "df = get_aopsez_data_sql()\n",
    "#rename the sql data so that we can \n",
    "readydf = Process_aop(df)\n",
    "#post_AOP_data(readydf, draft=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#VEG VIGOR#\n",
    "#Use data from SEZTable until we get new lidar data\n",
    "df=get_sez_data_sql()\n",
    "#df= get_oldvegvig_data()\n",
    "post_Veg_data(df, draft=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#HABITAT FRAGmentation and DITCHES\n",
    "#LiDAR data? this shouldn't change much \n",
    "# we can use data in the sez_habfrag_score and sez_ditches_scores tables and manually change"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Process Every Year= In-house Monitoring Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#BIOASSESSMENT#done Update EVERY YEAR after Processing BMI Data and updating SDE.Stream\n",
    "#Last updated 2023 \n",
    "from Bioassessment import *\n",
    "# from Bioassessment import *\n",
    "df = get_bioassessment_data()\n",
    "#clean, process, grade data\n",
    "readydf = process_grade_bioassessment(df, 2023)\n",
    "#post data to sde.VECTOR.stage headcut table or csv\n",
    "post_bioassessment(readydf, draft=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#INVASIVE SPECIES#done Update EVERY YEAR after QA of data in sde.Collect\n",
    "#Last Updated 2023\n",
    "from Invasives import *\n",
    "#Get USFS rest service data spatially joined to SEZ's\n",
    "usfsdf= get_USFSinvasive_data()\n",
    "#Get new invasive data from sde collect\n",
    "Idf = get_combined_survey_and_invasive_data()\n",
    "#clean, merge with external data/ format plant type names\n",
    "df = merge_format_prioritize_invasive(Idf, usfsdf, 2024)\n",
    "#Process Data and grade/rate assessment\n",
    "#Be sure to update the priority list in \"F:\\GIS\\PROJECTS\\ResearchAnalysis\\SEZ\\Invasives Priority Lookup.csv\"\n",
    "#rate_invasives is in utils if you need to update that\n",
    "invasive_summary, invasive_priority_summary = process_grade_invasives(df)\n",
    "#Format Data so it is ready to be added to sde/csv for one last QA\n",
    "readydf= final_format_invasive(df, invasive_priority_summary)\n",
    "#post data to sde.VECTOR.stage headcut table or csv\n",
    "post_invasive(readydf, draft=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#HEADCUT#done#Update Every Year after QA of data in sde.Collect\n",
    "#Last Updated 2023\n",
    "from Headcuts import *\n",
    "#Get raw headcut data prior 2024 and earlier that is stored in gdbs in F:GIS/data/Monitoring/\n",
    "#df= get_allheadcut_data()\n",
    "#Get new headcut data from sde collect\n",
    "df = get_combined_survey_and_headcut_data()\n",
    "#clean, process, grade data\n",
    "readydf = process_grade_headcut(df, 2024)\n",
    "#post data to sde.VECTOR.stage headcut table or csv\n",
    "#draft = True is for QA and False is final and will be put into database\n",
    "post_headcut(readydf, draft=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#INCISION# Update Every Year after QA of data in sde.Collect\n",
    "#Last Updated 2023\n",
    "from Incision import *\n",
    "\n",
    "#Get raw incision data prior 2023 and earlier that is stored in gdbs in F:GIS/data/Monitoring/\n",
    "#df= get_allincision_data()\n",
    "#Get incision data from sde collect\n",
    "df = get_combined_survey_and_incision_data()\n",
    "#clean, process, grade data\n",
    "readydf = process_grade_incision(df, 2022)\n",
    "#post data to sde.VECTOR.stage incision table or csv\n",
    "post_incision(readydf, draft=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#EROSION# Update Every Year after QA of data in sde.Collect\n",
    "#Last updated 2023\n",
    "from Erosion import *\n",
    "\n",
    "#Get raw erosion data prior 2023 and earlier that is stored in gdbs in F:GIS/data/Monitoring/\n",
    "df= get_erosion_data()\n",
    "\n",
    "#clean, process, grade data\n",
    "readydf = process_grade_erosion(df, 2024)\n",
    "#post data to sde.VECTOR.stage incision table or csv\n",
    "post_erosion(readydf, draft=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 2: Staging Tables to Final Table"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from functools import reduce\n",
    "from FormatStagingTables import *\n",
    "# Staging to final\n",
    "dfbanks = get_fs_data(bank_stability_url)\n",
    "dfbiotic = get_fs_data(biotic_integrity_url)\n",
    "dfconifer = get_fs_data(conifer_url)\n",
    "dfditch = get_fs_data(ditches_url)\n",
    "dfinvasive = get_fs_data(invasives_url)\n",
    "dfhabitat = get_fs_data(Hab_Frag_url)\n",
    "dfvegetation = get_fs_data(vegetation_url)\n",
    "dfincision = get_fs_data(incision_url)\n",
    "dfheadcuts = get_fs_data(headcuts_url)\n",
    "dfAOP = get_fs_data(AOP_url)\n",
    "dfSEZ = get_fs_data_spatial(SEZ_url)\n",
    "dfheadcuts.drop(columns=['small', 'medium', 'large'], inplace=True)\n",
    "#Format Staging Tables\n",
    "#format biotic data average if two streams in one assessment unit\n",
    "averaged_biotic_df=average_biotic_scores(dfbiotic)\n",
    "\n",
    "#Same for meadow(large polygon) and riverine(small polygon) data drop these columns because not needed in final merge, will assign SEZ ID later\n",
    "columns_to_drop = ['Year', 'SEZ_ID', 'GlobalID', 'last_edited_user', 'created_date', 'OBJECTID', 'created_user', 'last_edited_date']\n",
    "\n",
    "#Create Dictionary of Dataframes to adjust year to be in datashource column and not its own column\n",
    "yeartodatasource = {\n",
    "    'dfbanks': dfbanks,\n",
    "    'dfheadcuts': dfheadcuts,\n",
    "    'dfincision': dfincision,\n",
    "    'dfinvasive': dfinvasive\n",
    "}\n",
    "\n",
    "# Iterate over each DataFrame in meadowdata\n",
    "for name, df in yeartodatasource.items():\n",
    "    # Iterate over columns in the DataFrame\n",
    "    for col in df.columns:\n",
    "        # Check if the column name contains 'Data'\n",
    "        if 'Data_' in col:\n",
    "            # Add Year to the column if it contains 'Data'\n",
    "            df[col] = df[col].astype(str) + ', ' + df['Year'].astype(str)\n",
    "\n",
    "#Name dataframes so we can reference later\n",
    "largepolygondata= {'dfbanks': dfbanks, \n",
    "                'dfaveraged_biotic': averaged_biotic_df,\n",
    "                'dfconifer': dfconifer,\n",
    "                'dfditch': dfditch,\n",
    "                'dfinvasive': dfinvasive,\n",
    "                'dfhabitat': dfhabitat,\n",
    "                'dfvegetation': dfvegetation,\n",
    "                'dfincision': dfincision,\n",
    "                'dfheadcuts': dfheadcuts,\n",
    "                'dfAOP': dfAOP\n",
    "}\n",
    "\n",
    "\n",
    "#Staging Tables Riverine/ small polygons\n",
    "smallpolygondata = {'dfbanks': dfbanks, \n",
    "                'dfaveraged_biotic': averaged_biotic_df,\n",
    "                'dfconifer': dfconifer,\n",
    "                'dfditch': dfditch,\n",
    "                'dfinvasive': dfinvasive,\n",
    "                'dfhabitat': dfhabitat,\n",
    "                'dfvegetation': dfvegetation,\n",
    "                'dfincision': dfincision,\n",
    "                'dfheadcuts': dfheadcuts,\n",
    "                'dfAOP': dfAOP\n",
    "}\n",
    "\n",
    "\n",
    "# Process large polygon (meadow) and small polygon (riverine) data -\n",
    "#Get most recent scores for each indicator\n",
    "# Clean Data in each dataframe, assign SEZ ID to each assessment unit, add year to datasource column for formatting purposes\n",
    "processed_largepolygon_data = process_data(largepolygondata, lookup_dict, columns_to_drop)\n",
    "processed_smallpolygon_data = process_data(smallpolygondata, lookup_riverine, columns_to_drop)\n",
    "\n",
    "\n",
    "# Merge large polygon and small polygon data\n",
    "# Function to merge all DataFrames on multiple keys)\n",
    "# # #moved to formatstagingtables.py\n",
    "def merge_dataframes(data_dict, keys):\n",
    "    return reduce(lambda left, right: pd.merge(left, right, on=keys, how='inner'), data_dict.values())\n",
    "\n",
    "\n",
    "# # Merge small polygon DataFrames\n",
    "smallpolygon_df = merge_dataframes(processed_smallpolygon_data, ['SEZ_ID', 'Assessment_Unit_Name' ])\n",
    "\n",
    "# Merge large polygon DataFrames so all indicators that have data\n",
    "largepolygon_df = merge_dataframes(processed_largepolygon_data, ['SEZ_ID', 'Assessment_Unit_Name' ])\n",
    "\n",
    "\n",
    "# Append smallpolygon_df to largepolygon_df to have a complete list of all meadows and all sez ids\n",
    "final_combined_df = pd.concat([largepolygon_df, smallpolygon_df], ignore_index=True)\n",
    "\n",
    "# Print the final combined DataFrame to check\n",
    "#print(\"Final Combined DataFrame:\")\n",
    "print(final_combined_df)\n",
    "\n",
    "\n",
    "# # Join SEZinfo to combined df to get a dataframe with more info about each Assessment Unit\n",
    "# #Prep SEZ Baseline Data for assessment unit...will need to rethink if acreage changes.. or just manually change in sde\n",
    "keep_columns = ['SHAPE', 'Assessment_Unit_Name', 'Threshold_Year', 'SEZ_ID', 'Feature_Type', 'SEZ_Type', 'Ownership_Primary', 'Ownership_Secondary', 'Ownership_Secondary_2', 'Ownership_Secondary_3', 'Acres', 'Comments']\n",
    "# #dfSEZ is assessment unit information from SDE\n",
    "dfSEZ['SEZ_ID']= dfSEZ['SEZ_ID'].astype(int)\n",
    "dfSEZinfo= dfSEZ.loc[:,keep_columns].copy()\n",
    "\n",
    "#filter dfSEZinfo for threshol dyear ='2019'\n",
    "dfSEZinfo = dfSEZinfo[dfSEZinfo['Threshold_Year'] == '2019']\n",
    "\n",
    "# # Join SEZinfo to the combined_df using SEZ_ID\n",
    "final_df = pd.merge(final_combined_df, dfSEZinfo, on=['SEZ_ID', 'Assessment_Unit_Name'], how='right')\n",
    "#-----------------------------------\n",
    "# Define Year Data is processed\n",
    "#-----------------------------------\n",
    "# #Assign Threshold Calculations which is the Threshold Year--> is just the most recent data within the past 4 years\n",
    "final_df['Threshold_Year'] = 'test'\n",
    "\n",
    "# Step 1: Get the most recent year in the dataset\n",
    "#most_recent_year = final_df['Year'].max()\n",
    "\n",
    "# Step 2: Define the Threshold_Year based on the most recent year\n",
    "# If the data's year is within the last 4 years from the most recent year, it's considered valid\n",
    "#final_df['Threshold_Year'] = final_df['Year'].apply(\n",
    "#    lambda x: most_recent_year if most_recent_year - x <= 4 else None\n",
    "#)\n",
    "\n",
    "# Optional: Print to verify\n",
    "#print(f\"Most Recent Year: {most_recent_year}\")\n",
    "\n",
    "print(final_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove values for indicators based on sez type\n",
    "#Use old data from most recent year evaluation to fill in gaps. (data from 2019 that was updated with external data such as simon sedimentation ratings)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ? Create table from last year and then overwrite with new dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ? Use new data and fill in nulls with old data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#Bring in Last year threshold scores for any indicators thataren't in our raw data- some bank stability came from our stream surveys but aren't in the data\n",
    "#Fill in any indicators that have missing data with data from 2019\n",
    "\n",
    "# Rename fields based on field mappings\n",
    "dfSEZprep = dfSEZ.rename(columns=field_mapping)\n",
    "\n",
    "# Ensure 'Threshold Year' is properly filtered\n",
    "dfSEZprep = dfSEZprep[dfSEZprep['Threshold Year'] == '2019']\n",
    "\n",
    "# Filter out columns in dfSEZprep that are not in final_df\n",
    "dfSEZprep = dfSEZprep[[col for col in final_df.columns if col in dfSEZprep.columns]]\n",
    "\n",
    "# Set SEZ_ID as index for both DataFrames\n",
    "final_df.set_index('SEZ_ID', inplace=True)\n",
    "dfSEZprep.set_index('SEZ_ID', inplace=True)\n",
    "\n",
    "# Ensure dfSEZprep has no duplicate SEZ_IDs\n",
    "dfSEZprep = dfSEZprep[~dfSEZprep.index.duplicated(keep='last')]\n",
    "\n",
    "# Align dfSEZprep index with final_df before filling missing values\n",
    "final_df = final_df.fillna(dfSEZprep.reindex(final_df.index))\n",
    "\n",
    "# Reset the index to restore SEZ_ID as a column\n",
    "final_df.reset_index(inplace=True)\n",
    "\n",
    "print(dfSEZprep)\n",
    "print(final_df)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## QA tool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#-------------\n",
    "#QAOnly\n",
    "#------------\n",
    "# #RUN FOR QA so you can see the resulting dataframe/scores/formatting etc.\n",
    "#CSV will be posteed to the SEZ_scripts folder in file explorer\n",
    "# List of columns to export (excluding 'geometry' or 'Shape')\n",
    "columns_to_export = [col for col in final_df.columns if col != 'SHAPE']\n",
    "final_df[columns_to_export].to_csv('ready_df.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Calcluate SEZ Quality based on SEZ Type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from SEZScores import *\n",
    "#Calculate Score based on SEZ_Type  #Future- make it so any indicator that isn't in the lists below for SEZ Type says NA\n",
    "#Use SEZ_Type to select only needed indicators for SEZ Type\n",
    "# Define the score columns needed for each SEZ Type\n",
    "# Function to get the score columns based on SEZ_Type\n",
    "\n",
    "\n",
    "# Apply the appropriate score columns based on SEZ_Type\n",
    "final_df['Score_Columns'] = final_df['SEZ_Type'].apply(get_score_columns)\n",
    "\n",
    "\n",
    "# Apply the score calculation to each row\n",
    "final_df[['Final_Total_Points', 'Final_Points_Possible']] = final_df.apply(calculate_scores, axis=1)\n",
    "\n",
    "# Calculate the final percent\n",
    "final_df['Final_Percent'] = final_df['Final_Total_Points'] / final_df['Final_Points_Possible']\n",
    "\n",
    "# Calculate the final rating and score\n",
    "final_df['Final_Rating'] = final_df['Final_Percent'].apply(rate_SEZ)\n",
    "final_df['Final_Score'] = final_df['Final_Rating'].apply(score_indicator)\n",
    "\n",
    "# Drop the temporary 'Score_Columns' column\n",
    "final_df = final_df.drop(columns=['Score_Columns'])\n",
    "print(final_df)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Final set up\n",
    "\n",
    "\n",
    "#Field Mapping\n",
    "field_mapping = {\n",
    "    'Assessment_Unit_Name': 'Assessment_Unit_Name',\n",
    "    'SHAPE': 'SHAPE',\n",
    "    'Threshold_Year': 'Threshold Year',\n",
    "    'Comments': 'Comments',\n",
    "    'SEZ_Type': 'SEZ_Type',\n",
    "    'Final_Rating': 'Final_Rating',\n",
    "    'Final_Percent': 'Final_Percent',\n",
    "    'SEZ_ID': 'SEZ_ID',\n",
    "    'Final_Points_Possible': 'Final_Points_Possible',\n",
    "    'Final_Total_Points': 'Final_Total_Points',\n",
    "    'Acres': 'Acres',\n",
    "    'AOP_BarriersPerMile':'AquaticOrganismPassage_Barriers',\n",
    "    'AOP_NumberofBarriers': 'AquaticOrganismPassage_NumberOf',\n",
    "    'AOP_Score': 'AquaticOrganismPassage_Score',\n",
    "    'AOP_Rating': 'AquaticOrganismPassage_Rating',\n",
    "    'AOP_StreamMiles': 'AquaticOrganismPassage_StreamMiles',\n",
    "    'AOP_DataSource': 'AquaticOrganismPassage_DataSour',\n",
    "    'Bank_Stability_Data_Source': 'Bank_Stability_Data_Source',\n",
    "    'Bank_Stability_Percent_Unstable': 'Bank_Stability_Percent_Unstable',\n",
    "    'Bank_Stability_Rating': 'Bank_Stability_Rating',\n",
    "    'Bank_Stability_Score': 'Bank_Stability_Score',\n",
    "    'Biotic_Integrity_Rating': 'Biotic_Integrity_Rating',\n",
    "    'Biotic_Integrity_CSCI': 'Biotic_Integrity_CSCI',\n",
    "    'Biotic_Integrity_Data_Source': 'Biotic_Integrity_Data_Source',\n",
    "    'Biotic_Integrity_Score': 'Biotic_Integrity_Score',\n",
    "    'Comments': 'Comments',\n",
    "    'Conifer_Percent_Encroached': 'Conifer_Encroachment_Percent_En',\n",
    "    'Conifer_Encroachment_Data_Sourc': 'Conifer_Encroachment_Data_Sourc',\n",
    "    'Conifer_Encroachment_Rating': 'Conifer_Encroachment_Rating',\n",
    "    'Conifer_Encroachment_Score': 'Conifer_Encroachment_Score',\n",
    "    'ConiferEncroachment_Comments': 'Conifer_Encroachment_Comments',\n",
    "    'Ditches_Data_Source': 'Ditches_Data_Source',\n",
    "    'Ditches_Length': 'Ditches_Length',\n",
    "    'Ditches_Meadow_Length': 'Ditches_Meadow_Length',\n",
    "    'Ditches_Percent': 'Ditches_Percent',\n",
    "    'Ditches_Rating': 'Ditches_Rating',\n",
    "    'Ditches_Score': 'Ditches_Score',\n",
    "    'Feature_Type': 'Feature_Type',\n",
    "    'Habitat_Frag_Data_Source': 'Habitat_Fragmentation_Data_Sour',\n",
    "    'Habitat_Frag_Impervious_Acres': 'Habitat_Fragmentation_Imperviou',\n",
    "    'Habitat_Frag_Percent_Impervious': 'Habitat_Fragmentation_Percent_I',\n",
    "    'Habitat_Frag_Rating': 'Habitat_Fragmentation_Rating',\n",
    "    'Habitat_Frag_Score': 'Habitat_Fragmentation_Score',\n",
    "    'Headcuts_Data_Source': 'Headcuts_Data_Source',\n",
    "    'Number_of_Headcuts': 'Headcuts_Number_of_Headcuts',\n",
    "    'Headcuts_Rating': 'Headcuts_Rating',\n",
    "    'Headcuts_Score': 'Headcuts_Score',\n",
    "    'Incision_Data_Source': 'Incision_Data_Source',\n",
    "    'Incision_Rating': 'Incision_Rating',\n",
    "    'Incision_Score': 'Incision_Score',\n",
    "    'Incision_Ratio': 'Incision_Ratio',\n",
    "    'Invasive_Percent_Cover': 'Invasive_Percent_Cover',\n",
    "    'Invasives_Rating': 'Invasive_Rating',\n",
    "    'Invasives_Data_Source': 'Invasives_Data_Source',\n",
    "    'Invasives_Number_of_Invasives': 'Invasives_Number_of_Invasives',\n",
    "    'Invasives_Plant_Types': 'Invasives_Plant_Types',\n",
    "    'Invasives_Scores': 'Invasives_Scores',\n",
    "    'NDVI_ID': 'NDVI_ID',\n",
    "    'Ownership_Primary': 'Ownership_Primary',\n",
    "    'Ownership_Secondary': 'Ownership_Secondary',\n",
    "    'Ownership_Secondary_2': 'Ownership_Secondary_2',\n",
    "    'Ownership_Secondary_3': 'Ownership_Secondary_3',\n",
    "    'VegetationVigor_DataSource': 'VegetationVigor_DataSource',\n",
    "    'VegetationVigor_Rating': 'VegetationVigor_Rating',\n",
    "    'VegetationVigor_Raw': 'VegetationVigor_Raw',\n",
    "    'VegetationVigor_Score': 'VegetationVigor_Score'\n",
    "}\n",
    "# Rename fields based on field mappings\n",
    "SEZscores_readydf = final_df.rename(columns=field_mapping).drop(columns=[col for col in final_df.columns if col not in field_mapping])\n",
    "\n",
    "\n",
    "print(SEZscores_readydf)\n",
    "#----------------------------------------------------\n",
    "#Post results to CSV in gis/projects/Researchanalysis/SEZ for further QA\n",
    "#----------------------------------------------------\n",
    " \n",
    "#export all columns but shape\n",
    "columns_to_export = [col for col in SEZscores_readydf.columns if col != 'SHAPE']\n",
    "#Store csv on F drive for QA/add comments manually on F drive and to change up comments later based on SEZ's that scores changed\n",
    "#final_results = \"F:\\GIS\\PROJECTS\\ResearchAnalysis\\SEZ\\Threshold24_SEZScores.csv\"\n",
    "\n",
    "# Write to excel\n",
    "#SEZscores_readydf[columns_to_export].to_excel(final_results, index=False)\n",
    "\n",
    "\n",
    "# Convert DataFrame to a list of dictionaries\n",
    "#data = readydf.to_dict(orient='records')\n",
    "\n",
    "# Get the field names from the field mapping\n",
    "#field_names = list(readydf.columns)\n",
    "\n",
    "# Append data to existing table\n",
    "#with arcpy.da.InsertCursor(allsezscores, field_names) as cursor:\n",
    " #   for row in data:\n",
    "  #      cursor.insertRow([row[field] for field in field_names])\n",
    "\n",
    "#print(\"Data appended to table successfully.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## QA Tools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#This creates a csv of score changes and all information in row \n",
    "\n",
    "#Before Final comparison do more QA\n",
    "    # Check to make sure there are 641 ASsessment Units\n",
    "    #Check Final Points and make sure there are no really low numbers could be missing data\n",
    "    #Check all staging tables for completeness- There are ratings A-D, check on null data for that SEZ\n",
    "    #other QA methods can be added to this list\n",
    "\n",
    "#Check to see which SEZ Scores Changed\n",
    "Threshold23sezdata= SEZscores_readydf\n",
    "Threshold19sezdata = dfSEZ\n",
    "\n",
    "# Merge the datasets on Assessment_Unit_Name and SEZ_ID\n",
    "merged_df = pd.merge(\n",
    "    Threshold23sezdata[['Assessment_Unit_Name', 'SEZ_ID', 'Final_Rating', 'SEZ_Type']],\n",
    "    Threshold19sezdata[['Assessment_Unit_Name', 'SEZ_ID', 'Final_Rating', 'SEZ_Type']],\n",
    "    on=['Assessment_Unit_Name', 'SEZ_ID'],\n",
    "    suffixes=('_2023', '_2019')\n",
    ")\n",
    "\n",
    "# Identify Assessment Unit Names with a change in Final Rating\n",
    "changed_scores_df = merged_df[merged_df['Final_Rating_2023'] != merged_df['Final_Rating_2019']]\n",
    "\n",
    "# List of Assessment Unit Names with a change in score\n",
    "changed_assessment_units = changed_scores_df[['Assessment_Unit_Name', 'SEZ_ID', 'Final_Rating_2023', 'Final_Rating_2019']]\n",
    "\n",
    "# Output the DataFrame with changed scores\n",
    "print(changed_scores_df)\n",
    "\n",
    "# Output the list of Assessment Unit Names with a change in score\n",
    "print(changed_assessment_units)\n",
    "\n",
    "#Post results to CSV in gis/projects/Researchanalysis/SEZ for further QA\n",
    "columns_to_export = [col for col in changed_assessment_units.columns if col != 'SHAPE']\n",
    "#Store csv on F drive for QA/add comments manually on F drive and to change up comments later based on SEZ's that scores changed\n",
    "#Changed_Scores_List = \"F:\\GIS\\PROJECTS\\ResearchAnalysis\\SEZ\\Threshold24_SEZScoreChanges.csv\"\n",
    "# Assuming ready_df is the DataFrame you want to write to CSV\n",
    "#changed_scores_df.to_csv(Changed_Scores_List, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Otion for different CSV Look at only changed scores so we can update comments and make sure data is good, need to run this to get long format csv\n",
    "# List of all columns with 'Rating' in their name for both datasets\n",
    "rating_columns_2023 = [col for col in Threshold23sezdata.columns if 'Rating' in col]\n",
    "rating_columns_2019 = [col for col in Threshold19sezdata.columns if 'Rating' in col]\n",
    "\n",
    "# Ensure both DataFrames have the same Assessment_Unit_Name and SEZ_ID columns\n",
    "Threshold23sezdata = Threshold23sezdata[['Assessment_Unit_Name', 'SEZ_ID'] + rating_columns_2023]\n",
    "Threshold19sezdata = Threshold19sezdata[['Assessment_Unit_Name', 'SEZ_ID'] + rating_columns_2019]\n",
    "\n",
    "# Merge the datasets on Assessment_Unit_Name and SEZ_ID, for units that have changed scores\n",
    "final_merged_df = pd.merge(\n",
    "    Threshold23sezdata,\n",
    "    Threshold19sezdata,\n",
    "    on=['Assessment_Unit_Name', 'SEZ_ID'],\n",
    "    suffixes=('_2023', '_2019')\n",
    ")\n",
    "\n",
    "# Filter the final merged DataFrame to only include units that changed scores\n",
    "final_changed_scores_df = final_merged_df[final_merged_df['Assessment_Unit_Name'].isin(changed_assessment_units['Assessment_Unit_Name'])]\n",
    "\n",
    "# Print the final DataFrame with all rating columns and changed scores\n",
    "print(final_changed_scores_df)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Save the final DataFrame to a CSV file\n",
    "#final_changed_scores_df.to_csv(\"F:\\GIS\\PROJECTS\\ResearchAnalysis\\SEZ\\Threshold24_SEZScoreChanges_indicators.csv\", index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#BEST QA csv.. shows indicators scores and final score changes by year of threshold\n",
    "#futureadd in final points and points possible and comments\n",
    "# Used changed changed_assessment_units to get Rating scores from df's \n",
    "#Create CSV with assessment units that have changed , all indicator scores and final rating by year and SEZID\n",
    "\n",
    "# List of all columns with 'Rating' in their name for both datasets\n",
    "rating_columns_2023 = [col for col in Threshold23sezdata.columns if 'Rating' in col]\n",
    "rating_columns_2019 = [col for col in Threshold19sezdata.columns if 'Rating' in col]\n",
    "\n",
    "# Ensure both DataFrames have the same Assessment_Unit_Name and SEZ_ID columns\n",
    "Threshold23sezdata = Threshold23sezdata[['Assessment_Unit_Name', 'SEZ_ID'] + rating_columns_2023]\n",
    "Threshold19sezdata = Threshold19sezdata[['Assessment_Unit_Name', 'SEZ_ID'] + rating_columns_2019]\n",
    "\n",
    "# Merge changed_assessment_units with Threshold23sezdata and Threshold19sezdata to get ratings for changed units\n",
    "merged_23 = pd.merge(changed_assessment_units, Threshold23sezdata, on=['Assessment_Unit_Name', 'SEZ_ID'])\n",
    "merged_19 = pd.merge(changed_assessment_units, Threshold19sezdata, on=['Assessment_Unit_Name', 'SEZ_ID'])\n",
    "\n",
    "# Extract columns with 'Rating' for both datasets\n",
    "rating_columns_2023 = [col for col in merged_23.columns if 'Rating' in col]\n",
    "rating_columns_2019 = [col for col in merged_19.columns if 'Rating' in col]\n",
    "\n",
    "# Filtered DataFrames with only relevant columns\n",
    "filtered_23 = merged_23[['Assessment_Unit_Name', 'SEZ_ID'] + rating_columns_2023]\n",
    "filtered_19 = merged_19[['Assessment_Unit_Name', 'SEZ_ID'] + rating_columns_2019]\n",
    "\n",
    "# Add a 'Year' column to each DataFrame\n",
    "filtered_23['Year'] = '2023'\n",
    "filtered_19['Year'] = '2019'\n",
    "\n",
    "# Concatenate filtered_23 and filtered_19 DataFrames\n",
    "allratings = pd.concat([filtered_23, filtered_19], ignore_index=True)\n",
    "\n",
    "\n",
    "#Function to map SEZ_Type based on Assessment_Unit_Name\n",
    "def get_sez_type(row):\n",
    "    return lookup_all.get(row['SEZ_ID'], {}).get('SEZ_Type', None)\n",
    "\n",
    "# Apply the function to add SEZ_Type column\n",
    "allratings['SEZ_Type'] = allratings.apply(get_sez_type, axis=1)\n",
    "\n",
    "# Apply the function to add SEZ_Type column\n",
    "allratings['SEZ_Type'] = allratings.apply(get_sez_type, axis=1)\n",
    "\n",
    "# Drop the specified columns from merged_df\n",
    "columns_to_drop = ['Final_Rating_2019', 'Final_Rating_2023']\n",
    "allratings.drop(columns=columns_to_drop, inplace=True)\n",
    "\n",
    "# Save the final long format DataFrame to a CSV file\n",
    "#allratings.to_csv(\"F:\\\\GIS\\\\PROJECTS\\\\ResearchAnalysis\\\\SEZ\\\\allchangedscores_longformat.csv\", index=False)\n",
    "\n",
    "allratings.to_csv(\"C:\\\\Users\\\\snewsome\\\\Documents\\\\SEZallchangedscores_longformat.csv\", index=False)\n",
    "\n",
    "# Note to SELF - when group editing csv and fixing comments for changed scores this must be in an excel and is easiest if put online into google office sheets. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
