{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Get modules\n",
    "#indicators\n",
    "from Incision import *\n",
    "from Headcuts import *\n",
    "from Erosion import *\n",
    "from Invasives import *\n",
    "from Bioassessment import *\n",
    "from Conifer import *\n",
    "from VegVigor import *\n",
    "from AOP import *\n",
    "from Habitat import *\n",
    "from Ditches import *\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Process Indicators Post To Staging Tables"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Process Every Year= In-house Monitoring Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#CONIFER#\n",
    "#!!!No Need to update if there is no new information\n",
    "#Current code grabs old data which is already in staging table\n",
    "from Conifer import *\n",
    "df=get_conifersez_data_sql()\n",
    "readydf=process_conifer(df)\n",
    "post_conifer_data(df, draft=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#AOP#\n",
    "#!!! No need to update if there is no new information- \n",
    "# code isn't complete for new data- do manually for now until we set up a script for sde.aquaticorganismpassage_usfs\n",
    "#Current code grabs old data which is already in staging table\n",
    "from AOP import *\n",
    "#Get data from SEZ_Assessment Unit Table in sde (this indicator doesn't get updated much)\n",
    "df = get_aopsez_data_sql()\n",
    "#rename the sql data so that we can \n",
    "readydf = Process_aop(df)\n",
    "#post_AOP_data(readydf, draft=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#BIOASSESSMENT#done Update EVERY YEAR\n",
    "#Last updated 2023\n",
    "from Bioassessment import *\n",
    "# from Bioassessment import *\n",
    "df = get_bioassessment_data()\n",
    "#clean, process, grade data\n",
    "readydf = process_grade_bioassessment(df, 2023)\n",
    "#post data to sde.VECTOR.stage headcut table or csv\n",
    "post_bioassessment(readydf, draft=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#INVASIVE SPECIES#done Update EVERY YEAR\n",
    "#Last Updated 2023\n",
    "from Invasives import *\n",
    "#Get USFS rest service data spatially joined to SEZ's\n",
    "usfsdf= get_USFSinvasive_data()\n",
    "#Get new invasive data from sde collect\n",
    "Idf = get_combined_survey_and_invasive_data()\n",
    "#clean, merge with external data/ format plant type names\n",
    "df = merge_format_prioritize_invasive(Idf, usfsdf, 2024)\n",
    "#Process Data and grade/rate assessment\n",
    "#Be sure to update the priority list in \"F:\\GIS\\PROJECTS\\ResearchAnalysis\\SEZ\\Invasives Priority Lookup.csv\"\n",
    "#rate_invasives is in utils if you need to update that\n",
    "invasive_summary, invasive_priority_summary = process_grade_invasives(df)\n",
    "#Format Data so it is ready to be added to sde/csv for one last QA\n",
    "readydf= final_format_invasive(df, invasive_priority_summary)\n",
    "#post data to sde.VECTOR.stage headcut table or csv\n",
    "post_invasive(readydf, draft=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "invasive_priority_summary.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#HEADCUT#done#Update Every Year\n",
    "from Headcuts import *\n",
    "#Get raw headcut data prior 2024 and earlier that is stored in gdbs in F:GIS/data/Monitoring/\n",
    "#df= get_allheadcut_data()\n",
    "#Get new headcut data from sde collect\n",
    "df = get_combined_survey_and_headcut_data()\n",
    "#clean, process, grade data\n",
    "readydf = process_grade_headcut(df, 2024)\n",
    "#post data to sde.VECTOR.stage headcut table or csv\n",
    "post_headcut(readydf, draft=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "#INCISION# Update Every Year\n",
    "#Get raw incision data prior 2023 and earlier that is stored in gdbs in F:GIS/data/Monitoring/\n",
    "#df= get_allincision_data()\n",
    "#Get incision data from sde collect\n",
    "df = get_combined_survey_and_incision_data()\n",
    "#clean, process, grade data\n",
    "readydf = process_grade_incision(df, 2024)\n",
    "#post data to sde.VECTOR.stage incision table or csv\n",
    "post_incision(readydf, draft=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#EROSION# Update Every Year\n",
    "from Erosion import *\n",
    "\n",
    "#Get raw erosion data prior 2023 and earlier that is stored in gdbs in F:GIS/data/Monitoring/\n",
    "df= get_erosion_data()\n",
    "\n",
    "#clean, process, grade data\n",
    "readydf = process_grade_erosion(df, 2024)\n",
    "#post data to sde.VECTOR.stage incision table or csv\n",
    "post_erosion(readydf, draft=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#VEG VIGOR#\n",
    "#Use data from SEZTable until we get new lidar data\n",
    "df=get_sez_data_sql()\n",
    "#df= get_oldvegvig_data()\n",
    "post_Veg_data(df, draft=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Staging Tables to Final Table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\snewsome\\Documents\\GitHub\\Monitoring\\SEZ_scripts\\FormatStagingTables.py:64: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[col] = df[col] + ', ' + df['Year'].astype(str)\n",
      "c:\\Users\\snewsome\\Documents\\GitHub\\Monitoring\\SEZ_scripts\\FormatStagingTables.py:64: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[col] = df[col] + ', ' + df['Year'].astype(str)\n",
      "c:\\Users\\snewsome\\Documents\\GitHub\\Monitoring\\SEZ_scripts\\FormatStagingTables.py:64: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[col] = df[col] + ', ' + df['Year'].astype(str)\n",
      "c:\\Users\\snewsome\\Documents\\GitHub\\Monitoring\\SEZ_scripts\\FormatStagingTables.py:64: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[col] = df[col] + ', ' + df['Year'].astype(str)\n",
      "c:\\Users\\snewsome\\Documents\\GitHub\\Monitoring\\SEZ_scripts\\FormatStagingTables.py:64: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[col] = df[col] + ', ' + df['Year'].astype(str)\n",
      "c:\\Users\\snewsome\\Documents\\GitHub\\Monitoring\\SEZ_scripts\\FormatStagingTables.py:64: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[col] = df[col] + ', ' + df['Year'].astype(str)\n",
      "c:\\Users\\snewsome\\Documents\\GitHub\\Monitoring\\SEZ_scripts\\FormatStagingTables.py:64: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[col] = df[col] + ', ' + df['Year'].astype(str)\n",
      "c:\\Users\\snewsome\\Documents\\GitHub\\Monitoring\\SEZ_scripts\\FormatStagingTables.py:64: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[col] = df[col] + ', ' + df['Year'].astype(str)\n",
      "c:\\Users\\snewsome\\Documents\\GitHub\\Monitoring\\SEZ_scripts\\FormatStagingTables.py:64: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[col] = df[col] + ', ' + df['Year'].astype(str)\n",
      "c:\\Users\\snewsome\\Documents\\GitHub\\Monitoring\\SEZ_scripts\\FormatStagingTables.py:64: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[col] = df[col] + ', ' + df['Year'].astype(str)\n",
      "c:\\Users\\snewsome\\Documents\\GitHub\\Monitoring\\SEZ_scripts\\FormatStagingTables.py:64: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[col] = df[col] + ', ' + df['Year'].astype(str)\n",
      "c:\\Users\\snewsome\\Documents\\GitHub\\Monitoring\\SEZ_scripts\\FormatStagingTables.py:64: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[col] = df[col] + ', ' + df['Year'].astype(str)\n",
      "c:\\Users\\snewsome\\Documents\\GitHub\\Monitoring\\SEZ_scripts\\FormatStagingTables.py:64: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[col] = df[col] + ', ' + df['Year'].astype(str)\n",
      "c:\\Users\\snewsome\\Documents\\GitHub\\Monitoring\\SEZ_scripts\\FormatStagingTables.py:64: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[col] = df[col] + ', ' + df['Year'].astype(str)\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "The truth value of a DataFrame is ambiguous. Use a.empty, a.bool(), a.item(), a.any() or a.all().",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_41768\\521587049.py\u001b[0m in \u001b[0;36m?\u001b[1;34m()\u001b[0m\n\u001b[0;32m     62\u001b[0m \u001b[1;31m# def merge_dataframes(data_dict, keys):\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     63\u001b[0m  \u001b[1;31m#   return reduce(lambda left, right: pd.merge(left, right, on=keys, how='outer'), data_dict.values())\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     64\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     65\u001b[0m \u001b[1;31m# Merge small polygon DataFrames\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 66\u001b[1;33m \u001b[0msmallpolygon_df\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmerge_dataframes\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mprocessed_smallpolygon_data\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     67\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     68\u001b[0m \u001b[1;31m# Merge large polygon DataFrames so all indicators that have data\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     69\u001b[0m \u001b[0mlargepolygon_df\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmerge_dataframes\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mprocessed_largepolygon_data\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\snewsome\\Documents\\GitHub\\Monitoring\\SEZ_scripts\\FormatStagingTables.py\u001b[0m in \u001b[0;36m?\u001b[1;34m(data_dict, key)\u001b[0m\n\u001b[0;32m     78\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     79\u001b[0m     \u001b[0mReturns\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     80\u001b[0m         \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mMerged\u001b[0m \u001b[0mDataFrame\u001b[0m \u001b[1;32mwith\u001b[0m \u001b[0mone\u001b[0m \u001b[0mrow\u001b[0m \u001b[0mper\u001b[0m \u001b[0munique\u001b[0m \u001b[0mSEZ_ID\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     81\u001b[0m     \"\"\"\n\u001b[1;32m---> 82\u001b[1;33m     \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mdata_dict\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mkey\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata_dict\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     83\u001b[0m         \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mf\"Invalid input: Ensure data_dict contains DataFrames with '{key}'.\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     84\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     85\u001b[0m     \u001b[1;31m# Convert dictionary values (DataFrames) to a list\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Program Files\\ArcGIS\\Pro\\bin\\Python\\envs\\arcgispro-py3\\Lib\\site-packages\\pandas\\core\\generic.py\u001b[0m in \u001b[0;36m?\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1464\u001b[0m     \u001b[1;33m@\u001b[0m\u001b[0mfinal\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1465\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__nonzero__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m->\u001b[0m \u001b[0mNoReturn\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1466\u001b[1;33m         raise ValueError(\n\u001b[0m\u001b[0;32m   1467\u001b[0m             \u001b[1;34mf\"The truth value of a {type(self).__name__} is ambiguous. \"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1468\u001b[0m             \u001b[1;34m\"Use a.empty, a.bool(), a.item(), a.any() or a.all().\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1469\u001b[0m         )\n",
      "\u001b[1;31mValueError\u001b[0m: The truth value of a DataFrame is ambiguous. Use a.empty, a.bool(), a.item(), a.any() or a.all()."
     ]
    }
   ],
   "source": [
    "from functools import reduce\n",
    "from FormatStagingTables import *\n",
    "# Staging to final\n",
    "dfbanks = get_fs_data(bank_stability_url)\n",
    "dfbiotic = get_fs_data(biotic_integrity_url)\n",
    "dfconifer = get_fs_data(conifer_url)\n",
    "dfditch = get_fs_data(ditches_url)\n",
    "dfinvasive = get_fs_data(invasives_url)\n",
    "dfhabitat = get_fs_data(Hab_Frag_url)\n",
    "dfvegetation = get_fs_data(vegetation_url)\n",
    "dfincision = get_fs_data(incision_url)\n",
    "dfheadcuts = get_fs_data(headcuts_url)\n",
    "dfAOP = get_fs_data(AOP_url)\n",
    "dfSEZ = get_fs_data_spatial(SEZ_url)\n",
    "dfheadcuts.drop(columns=['small', 'medium', 'large'], inplace=True)\n",
    "#Format Staging Tables\n",
    "#format biotic data average if two streams in one assessment unit\n",
    "averaged_biotic_df=average_biotic_scores(dfbiotic)\n",
    "#Prep SEZ Baseline Data for assessment unit...will need to rethink if acreage changes.. or just manually change in sde\n",
    "keep_columns = ['SHAPE', 'SEZ_ID', 'Feature_Type', 'SEZ_Type', 'Ownership_Primary', 'Ownership_Secondary', 'Ownership_Secondary_2', 'Ownership_Secondary_3', 'Acres', 'Comments']\n",
    "#dfSEZ is assessment unit information from SDE?\n",
    "dfSEZ.loc[:,keep_columns].copy()\n",
    "dfSEZ['SEZ_ID']= dfSEZ['SEZ_ID'].astype(int)\n",
    "#Same for meadow(large polygon) and riverine(small polygon) data drop these columns because not needed in final merge, will assign SEZ ID later\n",
    "columns_to_drop = {'Year', 'SEZ_ID', 'GlobalID', 'last_edited_user', 'created_date', 'OBJECTID', 'created_user', 'last_edited_date'}\n",
    "\n",
    "#Name dataframes so we can reference later\n",
    "largepolygondata= {'dfbanks': dfbanks, \n",
    "                'dfaveraged_biotic': averaged_biotic_df,\n",
    "                'dfconifer': dfconifer,\n",
    "                'dfditch': dfditch,\n",
    "                'dfinvasive': dfinvasive,\n",
    "                'dfhabitat': dfhabitat,\n",
    "                'dfvegetation': dfvegetation,\n",
    "                'dfincision': dfincision,\n",
    "                'dfheadcuts': dfheadcuts,\n",
    "                'dfAOP': dfAOP\n",
    "}\n",
    "\n",
    "\n",
    "#Staging Tables Riverine/ small polygons\n",
    "smallpolygondata = {'dfbanks': dfbanks, \n",
    "                'dfaveraged_biotic': averaged_biotic_df,\n",
    "                'dfconifer': dfconifer,\n",
    "                'dfditch': dfditch,\n",
    "                'dfinvasive': dfinvasive,\n",
    "                'dfhabitat': dfhabitat,\n",
    "                'dfvegetation': dfvegetation,\n",
    "                'dfincision': dfincision,\n",
    "                'dfheadcuts': dfheadcuts,\n",
    "                'dfAOP': dfAOP\n",
    "}\n",
    "# Process large polygon (meadow) and small polygon (riverine) data -\n",
    "#Get most recent scores for each indicator\n",
    "# Clean Data in each dataframe, assign SEZ ID to each assessment unit, add year to datasource column for formatting purposes\n",
    "processed_largepolygon_data = process_data(largepolygondata, lookup_dict, columns_to_drop)\n",
    "processed_smallpolygon_data = process_data(smallpolygondata, lookup_riverine, columns_to_drop)\n",
    "\n",
    "# Merge large polygon and small polygon data\n",
    "# Function to merge all DataFrames on multiple keys(why on multiple keys? and not just SEZ ID)\n",
    "#moved to formatstagingtables.py\n",
    "# def merge_dataframes(data_dict, keys):\n",
    " #   return reduce(lambda left, right: pd.merge(left, right, on=keys, how='outer'), data_dict.values())\n",
    "\n",
    "# Merge small polygon DataFrames\n",
    "smallpolygon_df = merge_dataframes(processed_smallpolygon_data)\n",
    "\n",
    "# Merge large polygon DataFrames so all indicators that have data\n",
    "largepolygon_df = merge_dataframes(processed_largepolygon_data)\n",
    "\n",
    "# Append smallpolygon_df to largepolygon_df to have a complete list of all meadows and all sez ids\n",
    "final_combined_df = pd.concat([largepolygon_df, smallpolygon_df], ignore_index=True)\n",
    "\n",
    "# Print the final combined DataFrame to check\n",
    "print(\"Final Combined DataFrame:\")\n",
    "print(final_combined_df)\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "arcgispro-py3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
