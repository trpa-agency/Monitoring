{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set Up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import arcpy\n",
    "from datetime import datetime\n",
    "import os\n",
    "import sys\n",
    "from sqlalchemy.engine import URL\n",
    "from sqlalchemy import create_engine\n",
    "import sqlalchemy as sa\n",
    "import pandas as pd\n",
    "from arcgis import GIS\n",
    "from arcgis.features import FeatureSet, GeoAccessor, GeoSeriesAccessor, FeatureLayer\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import requests\n",
    "\n",
    "gis = GIS()\n",
    "# # Set Pandas display options to show all rows and columns\n",
    "# pd.set_option('display.max_rows', None)\n",
    "# pd.set_option('display.max_columns', None)\n",
    "# in memory output file path\n",
    "wk_memory = \"memory\" + \"\\\\\"\n",
    "\n",
    "# set workspace and sde collections \n",
    "\n",
    "# setup connection string???\n",
    "connection_string = \"DRIVER={ODBC Driver 17 for SQL Server};SERVER=sql12;DATABASE=sde;UID=sde;PWD=staff\"\n",
    "connection_url = URL.create(\"mssql+pyodbc\", query={\"odbc_connect\": connection_string})\n",
    "engine = create_engine(connection_url)\n",
    "\n",
    "with engine.begin() as sdeConnect:\n",
    "    dfTTsde      = pd.read_sql(\"SELECT * FROM sde.SDE.Travel_Times\", sdeConnect)\n",
    "\n",
    "# set workspace and sde connections \n",
    "working_folder = \"C:\\GIS\"\n",
    "workspace      = \"C:\\GIS\\Scratch.gdb\"\n",
    "arcpy.env.workspace = \"C:\\GIS\\Scratch.gdb\"\n",
    "\n",
    "# network path to connection files\n",
    "filePath = \"C:\\\\GIS\\\\DB_CONNECT\"\n",
    "# network path to connection files\n",
    "filePath = r'F:\\Research and Analysis\\Workspace\\Sarah'\n",
    "# database file path \n",
    "#SDE Collection New data collected is put into SDE.Survey under the indicator name\n",
    "#SDE Vector is where the data will go \n",
    "#Collection.sde.SDE.Survey\n",
    "#sdeBase    = os.path.join(filePath, \"Vector.sde\")\n",
    "#sdeCollect = os.path.join(filePath, \"Collection.sde\")\n",
    "sdeBase    = os.path.join(filePath, \"SarahVector.sde\")\n",
    "sdeCollect = os.path.join(filepath, \"SarahCollect.sde\")\n",
    "# local variables\n",
    "\n",
    "fdata = os.path.join(sdeBase, \"sde.SDE.Monitoring\")\n",
    "sdata = os.path.join(sdeCollect, \"sde.SDE.Assessment_Unit\")\n",
    "## Final feature class to append to in Enterprise Geodatabase double check this\n",
    "sdeSEZ = os.path.join(fdata \"sde.SDE.SEZ_Assessment_Unit\")\n",
    "sez_surveytable = os.path.join(sdeCollect, \"sde.Survey.SDE.sez_survey\")\n",
    "SEZ_datatable = os.path.join(sdeBase, \"sde.Monitoring.sde.Assessment_Unit\")\n",
    "\n",
    "\n",
    "#working_folder = \"F:/GIS/GIS_DATA/Monitoring/\"\n",
    "workspace ='F:\\Research and Analysis\\Workspace\\Sarah\\Data Management 2023\\Scratch.gdb'\n",
    "arcpy.env.workspace = 'F:\\Research and Analysis\\Workspace\\Sarah\\Data Management 2023\\Scratch.gdb'\n",
    "\n",
    "\n",
    "\n",
    "# database file path \n",
    "\n",
    "#sdeCollect = os.path.join(filePath, \"Collection.sde\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "## GDB with Raw Data straight from S123 not in the original folder (that one is not edited)\n",
    "#headcut23gdb = os.path.join(working_folder,\"Stream_Headcut\",\"Stream_Headcut_Survey\", \"Stream_Headcut_Survey_2023.gdb\")\n",
    "#headcut22gdb = os.path.join(working_folder,\"Stream_Headcut\",\"Stream_Headcut_Survey\", \"Stream_Headcut_Survey_2022.gdb\")\n",
    "#headcut20gdb = os.path.join(working_folder,\"Stream_Headcut\",\"Stream_Headcut_Survey\", \"Stream_Headcut_Survey_2020.gdb\")\n",
    "#erosion23gdb = os.path.join(working_folder, \"Stream_Erosion\",\"Stream_Erosion_Survey\", \"Stream_Erosion_Survey_2023.gdb\")\n",
    "#erosion22gdb = os.path.join(working_folder, \"Stream_Erosion\",\"Stream_Erosion_Survey\", \"Stream_Erosion_Survey_2022.gdb\")\n",
    "#erosion20gdb = os.path.join(working_folder, \"Stream_Erosion\",\"Stream_Erosion_Survey\", \"Stream_Erosion_Survey_2020.gdb\")\n",
    "#channelincision23gdb = os.path.join(working_folder,\"Channel_Incision\",\"Channel_Incision_Survey\",\"Channel_Incision_Survey_2023.gdb\")\n",
    "#channelincision22gdb = os.path.join(working_folder, \"Channel_Incision\",\"Channel_Incision_Survey\",\"Channel_Incision_Survey_2022.gdb\")\n",
    "#channelincision20gdb = os.path.join(working_folder, \"Channel_Incision\",\"Channel_Incision_Survey\",\"Channel_Incision_Survey_2020.gdb\")\n",
    "#invasiveplant23gdb= os.path.join(working_folder,\"Invasive_Species\",\"Invasive_Species_Survey\",\"Invasive_Species_Survey_2023.gdb\")\n",
    "#invasiveplant22gdb= os.path.join(working_folder,\"Invasive_Species\",\"Invasive_Species_Survey\",\"Invasive_Species_Survey_2022.gdb\")\n",
    "#invasiveplant20gdb= os.path.join(working_folder,\"Invasive_Species\",\"Invasive_Species_Survey\",\"Invasive_Species_Survey_2020.gdb\")\n",
    "\n",
    "#This is thelocatoin for the final SEZ GDB to be updated in the gdb on f drive in the AssessmentUnits Master (polygon) i believe\n",
    "#FinalGDBtoupdate:F:\\GIS\\PROJECTS\\ResearchAnalysis\\SEZ\\Data \\SEZ_Data.gdb\n",
    "\n",
    "#Monitoring Dashboard location\n",
    "#Finalsdelocation:f'Vector.SDE' Sde.Monitoring Sde. SEZ_Assessment_Unit\n",
    "\n",
    "#Threshold Location? sde.tabular"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Stream Erosion "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "#2023gdb\n",
    "# Name of the feature class or table\n",
    "fc_name = 'Stream_Erosion'\n",
    "\n",
    "# List to store rows from the attribute table\n",
    "data = []\n",
    "\n",
    "# Fields to include in the DataFrame\n",
    "fields = ['Assessment_Unit_Name', 'Bank_Type', 'Shape_Length']  # Add the names of the fields you want to include\n",
    "\n",
    "# Create a DataFrame from the list of rows\n",
    "erosion23df = pd.DataFrame(data, columns=fields)\n",
    "\n",
    "# Print the DataFrame\n",
    "print(erosion23df)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Input feature class \n",
    "input_fc = 'Stream_Erosion'\n",
    "\n",
    "# Convert feature class to Pandas DataFrame\n",
    "erosionfields = ['Assessment_Unit_Name', 'Shape_Length', 'Bank_Type', 'Percent_Unstable',]\n",
    "erosiondf = pd.DataFrame.from_records(data=arcpy.da.SearchCursor(input_fc, erosionfields), columns=erosionfields)\n",
    "\n",
    "# Initialize variables\n",
    "erosion_df['bank_multiplier'] = erosion_df['Bank_Type'].apply(lambda x: 2 if x == 'Both Banks' else (1 if x == 'One Bank' else 0))\n",
    "\n",
    "# Calculate the total length of banks assessed\n",
    "total_banks_assessed = (erosion_df['Shape_Length'].sum()) * 2\n",
    "\n",
    "# Calculate the total length of eroded banks\n",
    "total_eroded_banks = (erosion_df['Shape_Length'] * erosion_df['bank_multiplier']).sum()\n",
    "\n",
    "# calculate percent unstable 'percent_unstable' column!!! Bank Stability and we will need to add a column to the dataframe\n",
    "erosion_df['percent_unstable'] = (total_eroded_banks / total_banks_assessed) * 100\n",
    "\n",
    "print(\"Total Banks Assessed:\", total_banks_assessed)\n",
    "print(\"Total Eroded Banks:\", total_eroded_banks)\n",
    "print(\"Updated DataFrame:\")\n",
    "print(erosion_df)\n",
    "\n",
    "#field mapping? what is the fi nal location\n",
    "#field_mapping ={\n",
    "\n",
    "    #'Assessment_Unit_Name': \n",
    "    #'Shape_Length'\n",
    "    #\"Bank_Type\"\n",
    "    #'Percent_Unstable'\n",
    "#}\n",
    "\n",
    "# Create a new DataFrame Final_df with columns based on the field mapping\n",
    "#df = df.rename(columns=field_mapping)\n",
    "\n",
    "# Convert DataFrame to Spatially Enabled DataFrame\n",
    "sedf = GeoAccessor.from_xy(erosion_df, x_column='LONGITUDE', y_column='LATITUDE')\n",
    "\n",
    "# Convert the SEDF to a feature class without sanitizing columns where do i want this to live... its all of the gdb's combined so where do i update it.. to each gdb or individually or create a new one or put a copy into scratch.gdb and then some how write back \n",
    "sedf.spatial.to_featureclass(location=os.path.join(workspace, 'Erosion_Staging'), sanitize_columns=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Channel Incision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Channel Incision Process Data\n",
    "\n",
    "# List of paths to geodatabases\n",
    "channelincisiongdbs = ['channelincision20gdb', 'channelincision22gdb', 'channelincision23gdb']\n",
    "\n",
    "# Initialize an empty list to store DataFrames\n",
    "channeldfs = []\n",
    "\n",
    "# Iterate over each geodatabase\n",
    "for gdb in channelincisiongdbs:\n",
    "    # List feature classes or tables in the geodatabase\n",
    "    feature_classes = arcpy.ListFeatureClasses(\"*\", \"All\", gdb)\n",
    "    tables = arcpy.ListTables(\"*\", \"All\", gdb)\n",
    "    \n",
    "    # Iterate over feature classes and tables\n",
    "    for fc in feature_classes + tables:\n",
    "        # Convert feature class or table to DataFrame\n",
    "        df = pd.DataFrame(arcpy.da.FeatureClassToNumPyArray(fc, '*'))\n",
    "        dhanneldfs.append(df)\n",
    "\n",
    "# Concatenate all DataFrames into a single DataFrame\n",
    "erosion_df = pd.concat(channeldfs)\n",
    "\n",
    "#Processing of Channel Incision Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Invasive Species"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Invasive Species"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### HEadcuts\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Headcuts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bioassessment/ Biotic Integrity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Bioassessment scores- get all stream data into sde.Stream first... then look at Biotic Integrit Data Source to find which stream was used to evaluate each meadow.. this will help with percent of stream miles I believe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Conifer Encroachment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Aquatic Organism /Fish Passage"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Code to make it a spatially enabled dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#code to conver to spatially enable geodataframe\n",
    "# Create a new DataFrame Final_df with columns based on the field mapping\n",
    "#df = df.rename(columns=field_mapping)\n",
    "\n",
    "# Convert DataFrame to Spatially Enabled DataFrame\n",
    "#sedf = GeoAccessor.from_xy(df, x_column='LONGITUDE', y_column='LATITUDE')\n",
    "\n",
    "# Convert the SEDF to a feature class without sanitizing columns\n",
    "#sedf.spatial.to_featureclass(location=os.path.join(workspace, 'PlanAreaNoise_23_Staging'), sanitize_columns=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Code for Grading each parameter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Grading for each parameter add to final SDE file?\n",
    "#Defining Grade for Channel Stability based on Erosiondf[percent_unstable]\n",
    "def categorize_erosion(Percent_Unstable):\n",
    "    if 0 <= value < 5:\n",
    "        return 'A'\n",
    "    elif 5 <= value < 20:\n",
    "        return 'B'\n",
    "    elif 20 <= value < 50:\n",
    "        return 'C'\n",
    "    else:\n",
    "        return 'D'\n",
    "\n",
    "\n",
    "#Define Grade for Incision based off of bankful height to bankful depth\n",
    "\n",
    "def categorize_incision(bankful_ratio)\n",
    "     if 0 <= bankful_ratio < 1.2:\n",
    "        return 'A'\n",
    "    elif 1.2 <= bankful_ratio < 1.6:\n",
    "        return 'B'\n",
    "    elif 1.6 <= bankful_ratio < 2.1:\n",
    "        return 'C'\n",
    "    else:\n",
    "        return 'D'\n",
    "\n",
    "#Define Grade for Headcut based off of headcut size---fix this\n",
    "def categorize_headcut(value)\n",
    "     if value = 0\n",
    "        return 'A'\n",
    "    elif 1.2 <= value < 1.6:\n",
    "        return 'B'\n",
    "    elif value =\n",
    "        return 'C'\n",
    "    else:\n",
    "        return 'D'\n",
    "\n",
    "Define Grade for Invasive based off of invasive\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
