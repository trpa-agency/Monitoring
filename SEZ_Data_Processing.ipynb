{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set Up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "import arcpy\n",
    "from datetime import datetime\n",
    "import os\n",
    "import sys\n",
    "from sqlalchemy.engine import URL\n",
    "from sqlalchemy import create_engine\n",
    "import sqlalchemy as sa\n",
    "import pandas as pd\n",
    "from arcgis import GIS\n",
    "from arcgis.features import FeatureSet, GeoAccessor, GeoSeriesAccessor, FeatureLayer\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import requests\n",
    "\n",
    "\n",
    "gis = GIS()\n",
    "# # Set Pandas display options to show all rows and columns\n",
    "# pd.set_option('display.max_rows', None)\n",
    "# pd.set_option('display.max_columns', None)\n",
    "\n",
    "# in memory output file path\n",
    "wk_memory = \"memory\" + \"\\\\\"\n",
    "\n",
    "\n",
    "# set workspace and sde connections \n",
    "#working_folder = \"C:\\GIS\"\n",
    "#working_folder = \"F:/GIS/GIS_DATA/Monitoring/\"\n",
    "#workspace      = \"C:\\GIS\\Scratch.gdb\"\n",
    "#arcpy.env.workspace = \"C:\\GIS\\Scratch.gdb\"\n",
    "#workspace ='F:\\Research and Analysis\\Workspace\\Sarah\\Data Management 2023\\Scratch.gdb'\n",
    "#arcpy.env.workspace = 'F:\\Research and Analysis\\Workspace\\Sarah\\Data Management 2023\\Scratch.gdb'\n",
    "\n",
    "# network path to connection files\n",
    "filePath = \"F:\\\\GIS\\\\DB_CONNECT\"\n",
    "\n",
    "#path to GDB's to update and master data\n",
    "master_path = \"F:\\GIS\\PROJECTS\\ResearchAnalysis\\SEZ\\Data\\SEZ_Data.gdb\"\n",
    "SEZ_Master = os.path.join(master_path, \"AssessmentUnits_Master\")\n",
    "#set workspace for connection to GDB\n",
    "workspace=master_path\n",
    "# database file paths \n",
    "### SDE Collection New data collected is put into SDE.Survey under the indicator name\n",
    "### SDE Vector is where the data will go \n",
    "#sdeBase    = os.path.join(filePath, \"Vector.sde\")\n",
    "sdeCollect = os.path.join(filePath, \"Collection.sde\")\n",
    "sdeBase    = os.path.join(filePath, \"SarahVector.sde\")\n",
    "#sdeCollect = os.path.join(filepath, \"SarahCollect.sde\")\n",
    "\n",
    "# setup connection string???\n",
    "connection_string = \"DRIVER={ODBC Driver 17 for SQL Server};SERVER=sql12;DATABASE=sde;UID=sde;PWD=staff\"\n",
    "connection_url = URL.create(\"mssql+pyodbc\", query={\"odbc_connect\": connection_string})\n",
    "engine = create_engine(connection_url)\n",
    "\n",
    "#with engine.begin() as sdeConnect:\n",
    " #   erosiondf      = pd.read_sql(\"SELECT * FROM sde.SDE.Stream_Erosion\", sdeConnect)\n",
    "\n",
    "# local variables sdata is starting data and f data is finishing datatables\n",
    "ffdata = os.path.join(sdeBase, \"sde.SDE.Monitoring\")\n",
    "sdata = os.path.join(sdeCollect, \"sde.SDE.Survey\")\n",
    "fdata = os.path.join(master_path, \"AssessmentUnits_Master\")\n",
    "\n",
    "##Tables we get the data from in Collect\n",
    "sezsurveytable = os.path.join(sdata, \"sde.SDE.sez_survey\")\n",
    "erosiondata = os.path.join(sdata, \"sde.SDE.Stream_Erosion\")\n",
    "incisiondata = os.path.join(sdata, \"sde.SDE.sez_channel_incision\")\n",
    "invasivedata = os.path.join(sdata, \"sde.SDE.sez_invasive_plant\")\n",
    "headcutdata = os.path.join(sdata, \"sde.SDE.sez_stream_headcut\")\n",
    "streamdata = os.path.join(ffdata, \"sde.SDE.Stream\")\n",
    "\n",
    "\n",
    "#Staging Tables currently living in SEZ_Data.GDB\n",
    "stage_bank_stability = os.path.join(master_path, \"bank_stability\") \n",
    "stage_All_SEZ_Scores = os.path.join(master_path, \"All_SEZ_Scores\")\n",
    "stage_biotic_integrity = os.path.join(master_path, \"biotic_integrity\")\n",
    "stage_headcuts_table = os.path.join(master_path, \"heacuts_table\")\n",
    "stage_incision = os.path.join(master_path, \"incision\")\n",
    "stage_invasives = os.path.join(master_path, \"invasives\")\n",
    "\n",
    "\n",
    "\n",
    "#Final table to append to\n",
    "#finalSEZtable = os.path.join(fdata, \"sde.SDE.SEZ_Assessment_Unit\")\n",
    "#finalSEZtable = os.path.join(master_path, \"AssessmentUnits_Master\")\n",
    "\n",
    "\n",
    "# network path to connection files??????\n",
    "#filePath = \"C:\\\\GIS\\\\DB_CONNECT\"\n",
    "# network path to connection files\n",
    "#filePath = r'F:\\Research and Analysis\\Workspace\\Sarah'\n",
    "\n",
    "#--------------------------------------------#\n",
    "#Notes to self\n",
    "#--------------------------------------------#\n",
    "#F:\\GIS\\PROJECTS\\ResearchAnalysis\\SEZ\\Data\\SEZ_Data.gdb. \n",
    "###'Assessment_Unit_Master' has all data for SEZ\n",
    "###“Bioassessment Sample Locations” has stream sites in SEZs\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "## GDB with Raw Data straight from S123 not in the original folder (that one is not edited)\n",
    "#headcut23gdb = os.path.join(working_folder,\"Stream_Headcut\",\"Stream_Headcut_Survey\", \"Stream_Headcut_Survey_2023.gdb\")\n",
    "#headcut22gdb = os.path.join(working_folder,\"Stream_Headcut\",\"Stream_Headcut_Survey\", \"Stream_Headcut_Survey_2022.gdb\")\n",
    "#headcut20gdb = os.path.join(working_folder,\"Stream_Headcut\",\"Stream_Headcut_Survey\", \"Stream_Headcut_Survey_2020.gdb\")\n",
    "#erosion23gdb = os.path.join(working_folder, \"Stream_Erosion\",\"Stream_Erosion_Survey\", \"Stream_Erosion_Survey_2023.gdb\")\n",
    "#erosion22gdb = os.path.join(working_folder, \"Stream_Erosion\",\"Stream_Erosion_Survey\", \"Stream_Erosion_Survey_2022.gdb\")\n",
    "#erosion20gdb = os.path.join(working_folder, \"Stream_Erosion\",\"Stream_Erosion_Survey\", \"Stream_Erosion_Survey_2020.gdb\")\n",
    "#channelincision23gdb = os.path.join(working_folder,\"Channel_Incision\",\"Channel_Incision_Survey\",\"Channel_Incision_Survey_2023.gdb\")\n",
    "#channelincision22gdb = os.path.join(working_folder, \"Channel_Incision\",\"Channel_Incision_Survey\",\"Channel_Incision_Survey_2022.gdb\")\n",
    "#channelincision20gdb = os.path.join(working_folder, \"Channel_Incision\",\"Channel_Incision_Survey\",\"Channel_Incision_Survey_2020.gdb\")\n",
    "#invasiveplant23gdb= os.path.join(working_folder,\"Invasive_Species\",\"Invasive_Species_Survey\",\"Invasive_Species_Survey_2023.gdb\")\n",
    "#invasiveplant22gdb= os.path.join(working_folder,\"Invasive_Species\",\"Invasive_Species_Survey\",\"Invasive_Species_Survey_2022.gdb\")\n",
    "#invasiveplant20gdb= os.path.join(working_folder,\"Invasive_Species\",\"Invasive_Species_Survey\",\"Invasive_Species_Survey_2020.gdb\")\n",
    "\n",
    "#This is thelocatoin for the final SEZ GDB to be updated in the gdb on f drive in the AssessmentUnits Master (polygon) i believe\n",
    "#FinalGDBtoupdate:F:\\GIS\\PROJECTS\\ResearchAnalysis\\SEZ\\Data \\SEZ_Data.gdb\n",
    "\n",
    "#Monitoring Dashboard location\n",
    "#Finalsdelocation:f'Vector.SDE' Sde.Monitoring Sde. SEZ_Assessment_Unit\n",
    "\n",
    "#Threshold Location? sde.tabular"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lookup Dictionary for SEZ ID's\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "General function failure",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_15024\\416542397.py\u001b[0m in \u001b[0;36m<cell line: 17>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     16\u001b[0m \u001b[1;31m# Iterate over the rows in the second feature class and append to data list\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     17\u001b[0m \u001b[1;32mwith\u001b[0m \u001b[0marcpy\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mda\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mSearchCursor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mSEZ_Master\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfields\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mcursor\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 18\u001b[1;33m     \u001b[1;32mfor\u001b[0m \u001b[0mrow\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mcursor\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     19\u001b[0m         \u001b[0mdata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrow\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     20\u001b[0m \u001b[1;31m# Convert the data to a Pandas DataFrame\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mRuntimeError\u001b[0m: General function failure"
     ]
    }
   ],
   "source": [
    "#-----------------------------------------------------------------------------------#\n",
    "#Create look up dictionary for SEZ_ID fill in--currently works for stream erosion code\n",
    "#-----------------------------------------------------------------------------------#\n",
    "\n",
    "# Set workspace environment\n",
    "arcpy.env.workspace = master_path\n",
    "\n",
    "# Specify the feature class name SEZ_Master\n",
    "#feature_class = \"AssessmentUnits_Master\"\n",
    "# Create a cursor to iterate over the rows in the feature class\n",
    "fields = ['Assessment_Unit_Name', 'SEZ_ID']\n",
    "\n",
    "data = []\n",
    "\n",
    "\n",
    "# Iterate over the rows in the second feature class and append to data list\n",
    "with arcpy.da.SearchCursor(SEZ_Master, fields) as cursor:\n",
    "    for row in cursor:\n",
    "        data.append(row)\n",
    "# Convert the data to a Pandas DataFrame\n",
    "df = pd.DataFrame(data, columns=fields)\n",
    "\n",
    "# Define function to update SEZ ID lookup dictionary\n",
    "def update_SEZID_lookup_dict(df, lookup_dict):\n",
    "    for index, row in df.iterrows():\n",
    "        # Update SEZ_ID column in DataFrame with data from the lookup dictionary\n",
    "        df.at[index, 'SEZ_ID'] = lookup_dict.get(row['Assessment_Unit_Name'], None)\n",
    "\n",
    "    return df\n",
    "\n",
    "# Assuming 'Assessment_Unit_Name' is the common identifier between DataFrame and lookup dictionary\n",
    "selected_columns = ['Assessment_Unit_Name', 'SEZ_ID']\n",
    "\n",
    "# Drop duplicates based on 'Assessment_Unit_Name' and keep the first occurrence\n",
    "unique_values = df.drop_duplicates(subset='Assessment_Unit_Name', keep='first')\n",
    "\n",
    "# Convert selected columns to dictionary\n",
    "lookup_dict = unique_values[selected_columns].set_index('Assessment_Unit_Name').to_dict(orient='index')\n",
    "\n",
    "# Display the dictionary\n",
    "print(lookup_dict)\n",
    "\n",
    "# Update 'SEZ_ID' in other DataFrame with data from the lookup dictionary do this for each indicator...\n",
    "#Other_df = update_SEZID_lookup_dict(Other_df, lookup_dict)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "General function failure",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_15024\\1533236597.py\u001b[0m in \u001b[0;36m<cell line: 16>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     15\u001b[0m \u001b[1;31m# Iterate over the rows in the SEZ_Master feature class and append to data list\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     16\u001b[0m \u001b[1;32mwith\u001b[0m \u001b[0marcpy\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mda\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mSearchCursor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mSEZ_Master\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mMasterfields\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mcursor\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 17\u001b[1;33m     \u001b[1;32mfor\u001b[0m \u001b[0mrow\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mcursor\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     18\u001b[0m         \u001b[0mMasterdata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrow\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     19\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mRuntimeError\u001b[0m: General function failure"
     ]
    }
   ],
   "source": [
    "#-----------------------------------------------------------------------------------#\n",
    "# Create look up dictionary for SEZ_ID fill in with Global ID,SEZ ID, and Assessment Unit Name\n",
    "\n",
    "# Set workspace environment\n",
    "arcpy.env.workspace = master_path\n",
    "\n",
    "# Define the fields for SEZ_Master and the additional feature class\n",
    "Masterfields = ['Assessment_Unit_Name', 'SEZ_ID']\n",
    "surveyfields = ['assessment_unit_name', 'GlobalID']  # Add any additional fields you need\n",
    "\n",
    "# Create empty lists to store data\n",
    "Masterdata = []\n",
    "surveydata = []\n",
    "\n",
    "# Iterate over the rows in the SEZ_Master feature class and append to data list\n",
    "with arcpy.da.SearchCursor(SEZ_Master, Masterfields) as cursor:\n",
    "    for row in cursor:\n",
    "        Masterdata.append(row)\n",
    "\n",
    "# Iterate over the rows in the additional feature class and append to data list\n",
    "with arcpy.da.SearchCursor(sezsurveytable, surveyfields) as cursor:\n",
    "    for row in cursor:\n",
    "        surveydata.append(row)\n",
    "\n",
    "# Convert the data to Pandas DataFrames\n",
    "Masterdf = pd.DataFrame(Masterdata, columns=Masterfields)\n",
    "surveydf = pd.DataFrame(surveydata, columns=surveyfields)\n",
    "# Convert the column name in surveydf to match Masterdf\n",
    "surveydf = surveydf.rename(columns={'assessment_unit_name': 'Assessment_Unit_Name'})\n",
    "# Merge the DataFrames on 'Assessment_Unit_Name'\n",
    "SEZIDdf = pd.merge(Masterdf, surveydf, on='Assessment_Unit_Name', how='inner')\n",
    "\n",
    "# Check for missing values in 'GlobalID' or 'SEZ_ID'\n",
    "missing_values = SEZIDdf[SEZIDdf['GlobalID'].isna() | SEZIDdf['SEZ_ID'].isna()]\n",
    "\n",
    "# Replace missing values in 'SEZ_ID' with NaN\n",
    "SEZIDdf.loc[missing_values.index, 'SEZ_ID'] = np.nan\n",
    "\n",
    "\n",
    "\n",
    "# Display the merged DataFrame\n",
    "print(SEZIDdf)\n",
    "# Assuming 'Assessment_Unit_Name' is the common identifier between DataFrame and lookup dictionary\n",
    "selected_columns = ['Assessment_Unit_Name', 'SEZ_ID', 'GlobalID']\n",
    "\n",
    "# Drop duplicates based on 'Assessment_Unit_Name' and keep the first occurrence\n",
    "unique_values = SEZIDdf.drop_duplicates(subset='Assessment_Unit_Name', keep='first')\n",
    "\n",
    "# Convert selected columns to dictionary\n",
    "lookup_dict = unique_values[selected_columns].set_index('Assessment_Unit_Name').to_dict(orient='index')\n",
    "\n",
    "# Display the dictionary\n",
    "print(lookup_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pprint\n",
    "\n",
    "# Display the dictionary using pprint\n",
    "pprint.pprint(lookup_dict)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Code for Grading each parameter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Grading for each parameter add to final SDE file?\n",
    "#Defining Grade for Bank Stability based on Erosiondf[percent_unstable]\n",
    "def categorize_erosion(Percent_Unstable):\n",
    "    if 0 <= Percent_Unstable < 5:\n",
    "        return 'A'\n",
    "    elif 5 <= Percent_Unstable < 20:\n",
    "        return 'B'\n",
    "    elif 20 <= Percent_Unstable < 50:\n",
    "        return 'C'\n",
    "    else:\n",
    "        return 'D'\n",
    "    \n",
    "#Scoring based off of grading - check this\n",
    "def score_indicator(Rating):\n",
    "    if  Rating == 'A':\n",
    "        return '12'\n",
    "    elif Rating == 'B':\n",
    "        return '9'\n",
    "    elif Rating == 'C':\n",
    "        return '6'\n",
    "    else:\n",
    "        return '3'\n",
    "\n",
    "#Define Grade for Incision based off of incisino ratio\n",
    "\n",
    "def categorize_incision(bankfull_ratio):\n",
    "    if 0 <= bankfull_ratio < 1.2:\n",
    "        return 'A'\n",
    "    elif 1.2 <= bankfull_ratio < 1.6:\n",
    "        return 'B'\n",
    "    elif 1.6 <= bankfull_ratio < 2.1:\n",
    "        return 'C'\n",
    "    else:\n",
    "        return 'D'\n",
    "\n",
    "#Define Grade for Bioassessment Score\n",
    "#def categorize_csci(biotic_integrity)\n",
    " #    if   biotic_integrity > 0.92:\n",
    "  #      return 'A'\n",
    "   # elif 0.79 < biotic_integrity <= 0.92:\n",
    "    #    return 'B'\n",
    "    #elif 0.62 < biotic_integrity <= 0.79:\n",
    "     #   return 'C'\n",
    "    #else:\n",
    "     #   return 'D'\n",
    "\n",
    "#Define Grade for Invasive Plant Species Rating\n",
    "\n",
    "#def categorize_invasive(Invasive_Level)\n",
    "      \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#Define Size for Headcut based off of headcut size---fix this\n",
    "##A = 0 headcut, B 1+small headcut\n",
    "#def categorize_headcut(value)\n",
    " #    if 0.1 <= value < 0.5:\n",
    "  #      return 'small'\n",
    "   # elif 0.5 <= value < 1:\n",
    "    #    return 'medium'\n",
    "    #else:\n",
    "     #   return 'large'\n",
    "\n",
    "#Define Size for Headcut based off of headcut size---fix this\n",
    "##A = 0 headcut, B 1+small headcut\n",
    "#def categorize_headcutgrade(headcutgrade)\n",
    " #    if value = 0\n",
    "  #      return 'A'\n",
    "   # elif 1.2 <= value < 1.6:\n",
    "    #    return 'B'\n",
    "    #elif value =\n",
    "     #   return 'C'\n",
    "    #else:\n",
    "     #   return 'D'\n",
    "\n",
    "#Define Grade for Invasive \n",
    "#A=0, B=1 level 2, C 2 level 2 or 1 level 1, D=3+ level 2 or 2+ level 1\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Stream Erosion "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                              Assessment_Unit_Name  Shape.STLength()  \\\n",
      "0                         Angora Creek - tributary         13.800945   \n",
      "1                         Angora Creek - tributary         88.188503   \n",
      "2                         Angora Creek - tributary       1582.500924   \n",
      "3                         Angora Creek - tributary         70.220430   \n",
      "4                         Angora Creek - tributary         12.679912   \n",
      "...                                            ...               ...   \n",
      "2220  Saxon Creek meadows - above Fountain Place 2         71.738302   \n",
      "2221          Edgewood Creek tributary - 2 - upper         98.594528   \n",
      "2222                Carnelian Canyon Creek - lower        176.354488   \n",
      "2223                             Kahle meadows - 5         26.598415   \n",
      "2224                             Kahle meadows - 5         72.955145   \n",
      "\n",
      "     Bank_Type  Percent_Unstable                Survey_Date  SEZ_ID  Year  \\\n",
      "0     One Bank               NaN 2023-05-24 09:49:00.000000     265  2023   \n",
      "1      No Bank               NaN 2023-05-24 09:53:00.000001     265  2023   \n",
      "2      No Bank               NaN 2023-05-24 10:01:00.000000     265  2023   \n",
      "3      No Bank               NaN 2023-05-24 09:56:00.000001     265  2023   \n",
      "4     One Bank               NaN 2023-05-24 09:52:00.000000     265  2023   \n",
      "...        ...               ...                        ...     ...   ...   \n",
      "2220   No Bank               NaN 2019-07-29 09:26:37.000000     102  2019   \n",
      "2221   No Bank               NaN 2020-05-27 09:48:17.000000     635  2020   \n",
      "2222   No Bank               NaN 2020-09-14 12:40:12.000000     620  2020   \n",
      "2223   No Bank               NaN 2019-06-19 08:43:50.000000     118  2019   \n",
      "2224   No Bank               NaN 2019-09-11 15:13:12.000000     118  2019   \n",
      "\n",
      "      bank_multiplier  eroded_banks_per_row  banks_assessed_per_unit  \\\n",
      "0                   1             13.800945              4089.993846   \n",
      "1                   0              0.000000              4089.993846   \n",
      "2                   0              0.000000              4089.993846   \n",
      "3                   0              0.000000              4089.993846   \n",
      "4                   1             12.679912              4089.993846   \n",
      "...               ...                   ...                      ...   \n",
      "2220                0              0.000000              2507.358452   \n",
      "2221                0              0.000000              2979.834875   \n",
      "2222                0              0.000000               483.248779   \n",
      "2223                0              0.000000               199.107119   \n",
      "2224                0              0.000000               199.107119   \n",
      "\n",
      "      SEZ_total_eroded  Bank_Stability_Percent_Unstable Bank_Stability_Rating  \\\n",
      "0            35.146955                         0.859340                     A   \n",
      "1            35.146955                         0.859340                     A   \n",
      "2            35.146955                         0.859340                     A   \n",
      "3            35.146955                         0.859340                     A   \n",
      "4            35.146955                         0.859340                     A   \n",
      "...                ...                              ...                   ...   \n",
      "2220        155.001726                         6.181873                     B   \n",
      "2221          0.000000                         0.000000                     A   \n",
      "2222          0.000000                         0.000000                     A   \n",
      "2223          0.000000                         0.000000                     A   \n",
      "2224          0.000000                         0.000000                     A   \n",
      "\n",
      "     Bank_Stability_Score Bank_Stability_Data_Source  \n",
      "0                      12                       TRPA  \n",
      "1                      12                       TRPA  \n",
      "2                      12                       TRPA  \n",
      "3                      12                       TRPA  \n",
      "4                      12                       TRPA  \n",
      "...                   ...                        ...  \n",
      "2220                    9                       TRPA  \n",
      "2221                   12                       TRPA  \n",
      "2222                   12                       TRPA  \n",
      "2223                   12                       TRPA  \n",
      "2224                   12                       TRPA  \n",
      "\n",
      "[2225 rows x 15 columns]\n",
      "     SEZ_ID  Year                          Assessment_Unit_Name  \\\n",
      "0         0  2019                     Kings Beach tributary - 5   \n",
      "1         1  2019    Saxon Creek meadows - below Fountain Place   \n",
      "2         1  2022    Saxon Creek meadows - below Fountain Place   \n",
      "3         2  2019  Saxon Creek meadows - above Fountain Place 1   \n",
      "4         2  2022  Saxon Creek meadows - above Fountain Place 1   \n",
      "..      ...   ...                                           ...   \n",
      "256     630  2019                        Marlette Creek - upper   \n",
      "257     633  2019                          Burton Creek - lower   \n",
      "258     635  2020          Edgewood Creek tributary - 2 - upper   \n",
      "259     640  2022                           Saxon Creek - upper   \n",
      "260     640  2023                           Saxon Creek - upper   \n",
      "\n",
      "     Bank_Stability_Percent_Unstable Bank_Stability_Rating  \\\n",
      "0                           0.000000                     A   \n",
      "1                           1.145412                     A   \n",
      "2                          26.454621                     C   \n",
      "3                          12.876199                     B   \n",
      "4                          16.582856                     B   \n",
      "..                               ...                   ...   \n",
      "256                        32.903295                     C   \n",
      "257                        18.323038                     B   \n",
      "258                         0.000000                     A   \n",
      "259                         3.751931                     A   \n",
      "260                         7.526967                     B   \n",
      "\n",
      "    Bank_Stability_Score Bank_Stability_Data_Source  \n",
      "0                     12                       TRPA  \n",
      "1                     12                       TRPA  \n",
      "2                      6                       TRPA  \n",
      "3                      9                       TRPA  \n",
      "4                      9                       TRPA  \n",
      "..                   ...                        ...  \n",
      "256                    6                       TRPA  \n",
      "257                    9                       TRPA  \n",
      "258                   12                       TRPA  \n",
      "259                   12                       TRPA  \n",
      "260                    9                       TRPA  \n",
      "\n",
      "[261 rows x 7 columns]\n",
      "Data appended to table successfully.\n"
     ]
    }
   ],
   "source": [
    "#----------------------------------------------------------------#\n",
    "#Get Data\n",
    "#----------------------------------------------------------------##Convert feature class in gdb to Pandas DataFrame this is for REST Service\n",
    "erosionfields = ['Assessment_Unit_Name', 'Shape.STLength()', 'Bank_Type', 'Percent_Unstable', 'Survey_Date']\n",
    "#erosiondf = pd.DataFrame.from_records(data=arcpy.da.SearchCursor(erosiondata, erosionfields), columns=erosionfields)\n",
    "\n",
    "# Initialize an empty list to store data\n",
    "data = []\n",
    "\n",
    " # Iterate over the rows in the feature class and extract data\n",
    "with arcpy.da.SearchCursor(erosiondata, erosionfields) as cursor:\n",
    "    for row in cursor:\n",
    "        data.append(row)\n",
    "\n",
    "# Convert the data to a Pandas DataFrame\n",
    "erosiondf = pd.DataFrame(data, columns=erosionfields)\n",
    "\n",
    "# Replace NaN values in 'Assessment_Unit_Name' column with 'Skylandia SEZ'\n",
    "erosiondf['Assessment_Unit_Name'] = erosiondf['Assessment_Unit_Name'].fillna('Skylandia SEZ')\n",
    "# Replace specific values in 'Assessment_Unit_Name' column\n",
    "erosiondf['Assessment_Unit_Name'] = erosiondf['Assessment_Unit_Name'].replace({'Blackwood Creek - upper 2': 'Blackwood Creek - Upper 2', 'Taylor Creek marsh - 1': 'Taylor Creek marsh'})\n",
    "\n",
    "#Add SEZ_ID column using lookup dictionary\n",
    "erosiondf['SEZ_ID'] = erosiondf['Assessment_Unit_Name'].map(lambda x: lookup_dict.get(x, {}).get('SEZ_ID', None))\n",
    "\n",
    "# Fill NaN values with a specific value, such as 0\n",
    "erosiondf['SEZ_ID'] = erosiondf['SEZ_ID'].fillna(0)\n",
    "\n",
    "# Convert SEZ ID column to integer\n",
    "erosiondf['SEZ_ID'] = erosiondf['SEZ_ID'].astype(int)\n",
    "\n",
    "#erosiondf = erosiondf.merge(df, on='Assessment_Unit_Name', how='left')\n",
    "\n",
    "#calculate year column \n",
    "erosiondf['Year'] = erosiondf['Survey_Date'].dt.year\n",
    "\n",
    "# Replace 'both_banks' with 'Both Banks' in Bank_Type column\n",
    "erosiondf['Bank_Type'] = erosiondf['Bank_Type'].replace(['both_banks', 'Both banks'], 'Both Banks' )\n",
    "erosiondf['Bank_Type'] = erosiondf['Bank_Type'].replace(['one_bank', 'One bank'], 'One Bank')\n",
    "erosiondf['Bank_Type'] = erosiondf['Bank_Type'].replace(['no_bank', 'No bank'], 'No Bank')\n",
    "\n",
    "#----------------------------------------------------------------#\n",
    "#Process Data\n",
    "#----------------------------------------------------------------#\n",
    "\n",
    "# Initialize variables\n",
    "erosiondf['bank_multiplier'] = erosiondf['Bank_Type'].apply(lambda x: 2 if x == 'Both Banks' else (1 if x == 'One Bank' else 0))\n",
    "\n",
    "\n",
    "# Calculate the product of 'Shape.STLength()' and 'bank_multiplier' to get the eroded banks per row\n",
    "erosiondf['eroded_banks_per_row'] = erosiondf['Shape.STLength()'] * erosiondf['bank_multiplier']\n",
    "\n",
    "# Group by Assessment_Unit_Name and year and sum the lengths of banks for each unit to get total banks assessed\n",
    "erosiondf['banks_assessed_per_unit'] = erosiondf.groupby(['Assessment_Unit_Name', 'Year'])['Shape.STLength()'].transform('sum') * 2\n",
    "\n",
    "# Group by Assessment_Unit_Name and sum the eroded banks per row for each unit\n",
    "erosiondf['SEZ_total_eroded'] = erosiondf.groupby(['Assessment_Unit_Name', 'Year'])['eroded_banks_per_row'].transform('sum')\n",
    "\n",
    "# Calculate percent unstable Bank Stability per Assessment Unit\n",
    "erosiondf['Bank_Stability_Percent_Unstable'] = (erosiondf['SEZ_total_eroded'] / erosiondf['banks_assessed_per_unit']) * 100\n",
    "\n",
    "#----------------------------------------------------------------#\n",
    "#Grade, Score\n",
    "#----------------------------------------------------------------#\n",
    "erosiondf['Bank_Stability_Rating']=erosiondf['Bank_Stability_Percent_Unstable'].apply(categorize_erosion)\n",
    "erosiondf['Bank_Stability_Score']= erosiondf['Bank_Stability_Rating'].apply(score_indicator)\n",
    "\n",
    "erosiondf['Bank_Stability_Data_Source'] = 'TRPA'\n",
    "\n",
    "erosiondf.head()\n",
    "\n",
    "print(erosiondf)\n",
    "#----------------------------------------------------------------#\n",
    "#post ending dataframe to bank_stability called stage_bank_stability GDB location\n",
    "#----------------------------------------------------------------#\n",
    "# Define the name of the feature class\n",
    "#feature_class_name = 'bank_stability'\n",
    "\n",
    "# Define the full path to the feature class\n",
    "#feature_class_path = stage_bank_stability \n",
    "\n",
    "#Field Mapping\n",
    "field_mapping = {\n",
    "    'Assessment_Unit_Name': 'Assessment_Unit_Name',\n",
    "    'Year': 'Year',\n",
    "    'Bank_Stability_Data_Source': 'Bank_Stability_Data_Source',\n",
    "    'Bank_Stability_Percent_Unstable': 'Bank_Stability_Percent_Unstable',\n",
    "    'Bank_Stability_Rating': 'Bank_Stability_Rating',\n",
    "    'Bank_Stability_Score': 'Bank_Stability_Score',\n",
    "    'SEZ_ID': 'SEZ_ID'\n",
    "}\n",
    "\n",
    "# Rename fields based on field mappings\n",
    "bank_stabilitydf = erosiondf.rename(columns=field_mapping).drop(columns=[col for col in erosiondf.columns if col not in field_mapping])\n",
    "\n",
    "readydf = bank_stabilitydf.groupby(['SEZ_ID', 'Year']).first().reset_index()\n",
    "\n",
    "# Convert \"Year\" column to datetime format with year frequency\n",
    "#readydf['Year'] = pd.to_datetime(readydf['Year'], format='%Y')\n",
    "\n",
    "print(readydf)\n",
    "\n",
    "#Write dataframe to fc in SEZ_Data.GDB\n",
    "# Convert DataFrame to a list of dictionaries\n",
    "data = readydf.to_dict(orient='records')\n",
    "\n",
    "# Get the field names from the field mapping\n",
    "field_names = list(readydf.columns)\n",
    "\n",
    "# Append data to existing table\n",
    "with arcpy.da.InsertCursor(stage_bank_stability, field_names) as cursor:\n",
    "    for row in data:\n",
    "        cursor.insertRow([row[field] for field in field_names])\n",
    "\n",
    "print(\"Data appended to table successfully.\")\n",
    "\n",
    "\n",
    "#Write dataframe to sde.collect.bank.stability eventually, current code write it to GDB in SEZ_Data.GDB\n",
    "# Set environment workspace to your SDE connection file\n",
    "#arcpy.env.workspace = master_path\n",
    "\n",
    "# Convert DataFrame to Feature Class\n",
    "#output_feature_class = \"ErosionUpdate\"  # Name for the output feature class\n",
    "#output_fc_path = os.path.join(arcpy.env.workspace, output_feature_class)\n",
    "\n",
    "# Assuming your DataFrame is already converted to a feature class\n",
    "# Replace \"path_to_your_feature_class\" with the actual path to your feature class\n",
    "#arcpy.conversion.TableToTable(\"path_to_your_feature_class\", arcpy.env.workspace, output_feature_class)\n",
    "\n",
    "# Overwrite Feature Class in SDE\n",
    "# Replace \"path_to_your_dataframe\" with the actual path to your DataFrame\n",
    "#arcpy.management.CopyFeatures(\"path_to_your_dataframe\", output_fc_path)\n",
    "\n",
    "\n",
    "#print(ready_df)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SEZ_ID                               int32\n",
      "Year                                object\n",
      "Assessment_Unit_Name                object\n",
      "Bank_Stability_Percent_Unstable    float64\n",
      "Bank_Stability_Rating               object\n",
      "Bank_Stability_Score                object\n",
      "Bank_Stability_Data_Source          object\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "print(readydf.dtypes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[  nan 15.32]\n"
     ]
    }
   ],
   "source": [
    "# Convert DataFrame to CSV\n",
    "#csv_path = os.path.join(working_folder, \"Erosiondatamaster.csv\")\n",
    "#ready_df.to_csv(csv_path, index=False) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Channel Incision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                             parentglobalid  bankfull_ratio  \\\n",
      "0    {7F109869-B2DC-43A8-839F-3639D7CDA2DA}             NaN   \n",
      "1    {F4338C41-C34D-4345-B466-BF5D35660913}             NaN   \n",
      "2    {6991D645-CBA2-4120-93FB-5A24C434EB9D}             NaN   \n",
      "3    {45EF5A48-BE35-40EC-8679-E7969C7AD379}             NaN   \n",
      "4    {BF1ACEBD-747D-4F80-9EC9-ED299B868027}             1.0   \n",
      "..                                      ...             ...   \n",
      "778  {A145AE49-F462-4CE1-A73D-5D7089BADFC0}             1.0   \n",
      "779  {A145AE49-F462-4CE1-A73D-5D7089BADFC0}             NaN   \n",
      "780  {8EC9058B-54D0-488C-BDA2-D17231078389}             1.0   \n",
      "781  {8EC9058B-54D0-488C-BDA2-D17231078389}             1.0   \n",
      "782  {8EC9058B-54D0-488C-BDA2-D17231078389}             1.0   \n",
      "\n",
      "           created_date                                GlobalID  \\\n",
      "0   2023-05-25 15:16:05  {7F109869-B2DC-43A8-839F-3639D7CDA2DA}   \n",
      "1   2023-05-25 15:19:50  {F4338C41-C34D-4345-B466-BF5D35660913}   \n",
      "2   2023-05-25 15:19:53  {6991D645-CBA2-4120-93FB-5A24C434EB9D}   \n",
      "3   2023-05-30 22:59:37  {45EF5A48-BE35-40EC-8679-E7969C7AD379}   \n",
      "4   2023-05-30 22:59:42  {BF1ACEBD-747D-4F80-9EC9-ED299B868027}   \n",
      "..                  ...                                     ...   \n",
      "778 2019-10-11 15:54:43  {A145AE49-F462-4CE1-A73D-5D7089BADFC0}   \n",
      "779 2019-10-11 15:54:43  {A145AE49-F462-4CE1-A73D-5D7089BADFC0}   \n",
      "780 2019-10-11 15:54:47  {8EC9058B-54D0-488C-BDA2-D17231078389}   \n",
      "781 2019-10-11 15:54:47  {8EC9058B-54D0-488C-BDA2-D17231078389}   \n",
      "782 2019-10-11 15:54:47  {8EC9058B-54D0-488C-BDA2-D17231078389}   \n",
      "\n",
      "     Assessment_Unit_Name  \n",
      "0                     NaN  \n",
      "1                     NaN  \n",
      "2                     NaN  \n",
      "3                     NaN  \n",
      "4                     NaN  \n",
      "..                    ...  \n",
      "778                   NaN  \n",
      "779                   NaN  \n",
      "780                   NaN  \n",
      "781                   NaN  \n",
      "782                   NaN  \n",
      "\n",
      "[783 rows x 5 columns]\n",
      "                             parentglobalid  bankfull_ratio  \\\n",
      "0    {7F109869-B2DC-43A8-839F-3639D7CDA2DA}             NaN   \n",
      "1    {F4338C41-C34D-4345-B466-BF5D35660913}             NaN   \n",
      "2    {6991D645-CBA2-4120-93FB-5A24C434EB9D}             NaN   \n",
      "3    {45EF5A48-BE35-40EC-8679-E7969C7AD379}             NaN   \n",
      "4    {BF1ACEBD-747D-4F80-9EC9-ED299B868027}             1.0   \n",
      "..                                      ...             ...   \n",
      "778  {A145AE49-F462-4CE1-A73D-5D7089BADFC0}             1.0   \n",
      "779  {A145AE49-F462-4CE1-A73D-5D7089BADFC0}             NaN   \n",
      "780  {8EC9058B-54D0-488C-BDA2-D17231078389}             1.0   \n",
      "781  {8EC9058B-54D0-488C-BDA2-D17231078389}             1.0   \n",
      "782  {8EC9058B-54D0-488C-BDA2-D17231078389}             1.0   \n",
      "\n",
      "           created_date                                GlobalID  \\\n",
      "0   2023-05-25 15:16:05  {7F109869-B2DC-43A8-839F-3639D7CDA2DA}   \n",
      "1   2023-05-25 15:19:50  {F4338C41-C34D-4345-B466-BF5D35660913}   \n",
      "2   2023-05-25 15:19:53  {6991D645-CBA2-4120-93FB-5A24C434EB9D}   \n",
      "3   2023-05-30 22:59:37  {45EF5A48-BE35-40EC-8679-E7969C7AD379}   \n",
      "4   2023-05-30 22:59:42  {BF1ACEBD-747D-4F80-9EC9-ED299B868027}   \n",
      "..                  ...                                     ...   \n",
      "778 2019-10-11 15:54:43  {A145AE49-F462-4CE1-A73D-5D7089BADFC0}   \n",
      "779 2019-10-11 15:54:43  {A145AE49-F462-4CE1-A73D-5D7089BADFC0}   \n",
      "780 2019-10-11 15:54:47  {8EC9058B-54D0-488C-BDA2-D17231078389}   \n",
      "781 2019-10-11 15:54:47  {8EC9058B-54D0-488C-BDA2-D17231078389}   \n",
      "782 2019-10-11 15:54:47  {8EC9058B-54D0-488C-BDA2-D17231078389}   \n",
      "\n",
      "     Assessment_Unit_Name    Year Incision_Rating Incision_Score  \\\n",
      "0                     NaN  2023.0               D              3   \n",
      "1                     NaN  2023.0               D              3   \n",
      "2                     NaN  2023.0               D              3   \n",
      "3                     NaN  2023.0               D              3   \n",
      "4                     NaN  2023.0               A             12   \n",
      "..                    ...     ...             ...            ...   \n",
      "778                   NaN  2019.0               A             12   \n",
      "779                   NaN  2019.0               D              3   \n",
      "780                   NaN  2019.0               A             12   \n",
      "781                   NaN  2019.0               A             12   \n",
      "782                   NaN  2019.0               A             12   \n",
      "\n",
      "    Incision_Data_Source  \n",
      "0                   TRPA  \n",
      "1                   TRPA  \n",
      "2                   TRPA  \n",
      "3                   TRPA  \n",
      "4                   TRPA  \n",
      "..                   ...  \n",
      "778                 TRPA  \n",
      "779                 TRPA  \n",
      "780                 TRPA  \n",
      "781                 TRPA  \n",
      "782                 TRPA  \n",
      "\n",
      "[783 rows x 9 columns]\n"
     ]
    }
   ],
   "source": [
    "#----------------------------------------------------------------#\n",
    "#Get Data\n",
    "#----------------------------------------------------------------##Convert feature class in gdb to Pandas DataFrame this is for REST Service\n",
    "incisionfields = ['parentglobalid', 'bankfull_ratio', 'created_date']\n",
    "#incisiondf = pd.DataFrame.from_records(data=arcpy.da.SearchCursor(erosiondata, erosionfields), columns=erosionfields)\n",
    "\n",
    "# Initialize an empty list to store data\n",
    "data = []\n",
    "\n",
    " # Iterate over the rows in the feature class and extract data\n",
    "with arcpy.da.SearchCursor(incisiondata, incisionfields) as cursor:\n",
    "    for row in cursor:\n",
    "        data.append(row)\n",
    "\n",
    "# Convert the data to a Pandas DataFrame\n",
    "incisiondf = pd.DataFrame(data, columns=incisionfields)\n",
    "\n",
    "# Replace  values in 'Assessment_Unit_Name' colum\n",
    "#incisiondf['Assessment_Unit_Name'] = SEZIDdf['Assessment_Unit_Name'].fillna('Skylandia SEZ')\n",
    "# Replace specific values in 'Assessment_Unit_Name' column\n",
    "#incisiondf['Assessment_Unit_Name'] = incisiondf['Assessment_Unit_Name'].replace({'Blackwood Creek - upper 2': 'Blackwood Creek - Upper 2', 'Taylor Creek marsh - 1': 'Taylor Creek marsh'})\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#----------------------------------------------------------------#\n",
    "#Add correct info to dataframe\n",
    "#----------------------------------------------------------------#\n",
    "# Create a new column 'SEZ ID' initialized with NaN values\n",
    "incisiondf['GlobalID']= incisiondf['parentglobalid']\n",
    "\n",
    "# Map ParentGlobalID to SEZ_ID using the lookup dictionary\n",
    "incisiondf['Assessment_Unit_Name'] = incisiondf['GlobalID'].map(lambda x: lookup_dict[x]['Assessment_Unit_Name'] if x in lookup_dict else np.nan)\n",
    "\n",
    "#incisiondf['SEZ ID'] = np.nan\n",
    "\n",
    "# Iterate through the rows in incisiondf\n",
    "#for index, row in incisiondf.iterrows():\n",
    " #   parentglobalid = row['parentglobalid']\n",
    "    \n",
    "      # Check if the parent_global_id exists in the lookup dictionary\n",
    "  #  if parentglobalid in lookup_dict:\n",
    "        # If it exists, retrieve the corresponding SEZ ID and fill it into SEZ ID column\n",
    "   #     corresponding_entry = lookup_dict[parentglobalid]\n",
    "    #    assert row['GlobalID'] == parentglobalid, \"ParentGlobalID does not match GlobalID in the lookup dictionary\"\n",
    "     #   incisiondf.at[index, 'SEZ_ID'] = corresponding_entry['SEZ_ID']\n",
    "\n",
    "# Display the updated incisiondf\n",
    "print(incisiondf)\n",
    "\n",
    "#Add SEZ_ID column using lookup dictionary\n",
    "#incisiondf['SEZ_ID'] = SEZIDdf['GlobalID'].map(lambda x: lookup_dict.get(x, {}).get('SEZ_ID', None))\n",
    "\n",
    "# Fill NaN values with a specific value, such as 0\n",
    "#incisiondf['SEZ_ID'] = incisiondf['SEZ_ID'].fillna(0)\n",
    "\n",
    "# Convert SEZ ID column to integer\n",
    "#incisiondf['SEZ_ID'] = incisiondf['SEZ_ID'].astype(int)\n",
    "\n",
    "#incisiondf = incisiondf.merge(df, on='Assessment_Unit_Name', how='left')\n",
    "\n",
    "#calculate year column \n",
    "incisiondf['Year'] = incisiondf['created_date'].dt.year\n",
    "\n",
    "\n",
    "#----------------------------------------------------------------#\n",
    "#Grade, Score\n",
    "#----------------------------------------------------------------#\n",
    "incisiondf['Incision_Rating']=incisiondf['bankfull_ratio'].apply(categorize_incision)\n",
    "incisiondf['Incision_Score']= incisiondf['Incision_Rating'].apply(score_indicator)\n",
    "\n",
    "incisiondf['Incision_Data_Source'] = 'TRPA'\n",
    "\n",
    "incisiondf.head()\n",
    "\n",
    "print(incisiondf)\n",
    "#----------------------------------------------------------------#\n",
    "#post ending dataframe to incision called stage_incision GDB location\n",
    "#----------------------------------------------------------------#\n",
    "# Define the name of the feature class\n",
    "feature_class_name = 'incision'\n",
    "\n",
    "# Define the full path to the feature class\n",
    "feature_class_path = stage_incision \n",
    "\n",
    "#Field Mapping\n",
    "field_mapping = {\n",
    "    'Assessment_Unit_Name': 'Assessment_Unit_Name',\n",
    "    'Year': 'Year',\n",
    "    'Incision_Data_Source': 'Incision_Data_Source',\n",
    "    'Incision_Ratio': 'bankfull_ratio',\n",
    "    'Incision_Rating': 'Incision_Rating',\n",
    "    'Incision_Score': 'Incision_Score',\n",
    "    'SEZ_ID': 'SEZ_ID'\n",
    "}\n",
    "\n",
    "# Rename fields based on field mappings\n",
    "#bank_stabilitydf = incisiondf.rename(columns=field_mapping).drop(columns=[col for col in incisiondf.columns if col not in field_mapping])\n",
    "\n",
    "#readydf = bank_stabilitydf.groupby(['SEZ_ID', 'Year']).first().reset_index()\n",
    "\n",
    "# Convert \"Year\" column to datetime format with year frequency\n",
    "#readydf['Year'] = pd.to_datetime(readydf['Year'], format='%Y')\n",
    "\n",
    "#print(readydf)\n",
    "\n",
    "#Write dataframe to fc in SEZ_Data.GDB\n",
    "# Convert DataFrame to a list of dictionaries\n",
    "#data = readydf.to_dict(orient='records')\n",
    "\n",
    "# Get the field names from the field mapping\n",
    "#field_names = list(readydf.columns)\n",
    "\n",
    "# Append data to existing table\n",
    "#with arcpy.da.InsertCursor(stage_bank_stability, field_names) as cursor:\n",
    " ##   for row in data:\n",
    "   #     cursor.insertRow([row[field] for field in field_names])\n",
    "\n",
    "#print(\"Data appended to table successfully.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Invasive Species"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Invasive Species"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### HEadcuts\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Headcuts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bioassessment/ Biotic Integrity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Bioassessment scores- get all stream data into sde.Stream first... then look at Biotic Integrit Data Source to find which stream was used to evaluate each meadow.. this will help with percent of stream miles I believe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Conifer Encroachment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Aquatic Organism /Fish Passage"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Code to make it a spatially enabled dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#code to conver to spatially enable geodataframe\n",
    "# Create a new DataFrame Final_df with columns based on the field mapping\n",
    "#df = df.rename(columns=field_mapping)\n",
    "\n",
    "# Convert DataFrame to Spatially Enabled DataFrame\n",
    "#sedf = GeoAccessor.from_xy(df, x_column='LONGITUDE', y_column='LATITUDE')\n",
    "\n",
    "# Convert the SEDF to a feature class without sanitizing columns\n",
    "#sedf.spatial.to_featureclass(location=os.path.join(workspace, 'PlanAreaNoise_23_Staging'), sanitize_columns=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
