{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set Up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import arcpy\n",
    "from datetime import datetime\n",
    "import os\n",
    "import sys\n",
    "from sqlalchemy.engine import URL\n",
    "from sqlalchemy import create_engine\n",
    "import sqlalchemy as sa\n",
    "import pandas as pd\n",
    "from arcgis import GIS\n",
    "from arcgis.features import FeatureSet, GeoAccessor, GeoSeriesAccessor, FeatureLayer\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import requests\n",
    "\n",
    "gis = GIS()\n",
    "# # Set Pandas display options to show all rows and columns\n",
    "# pd.set_option('display.max_rows', None)\n",
    "# pd.set_option('display.max_columns', None)\n",
    "# in memory output file path\n",
    "wk_memory = \"memory\" + \"\\\\\"\n",
    "\n",
    "# set workspace and sde connections \n",
    "working_folder = \"F:/GIS/GIS_DATA/Monitoring/\"\n",
    "workspace ='F:\\Research and Analysis\\Workspace\\Sarah\\Data Management 2023\\Scratch.gdb'\n",
    "arcpy.env.workspace = 'F:\\Research and Analysis\\Workspace\\Sarah\\Data Management 2023\\Scratch.gdb'\n",
    "\n",
    "# network path to connection files\n",
    "filePath = r'F:\\Research and Analysis\\Workspace\\Sarah'\n",
    "\n",
    "# database file path \n",
    "sdeBase    = os.path.join(filePath, \"SarahVector.sde\")\n",
    "#sdeCollect = os.path.join(filePath, \"Collection.sde\")\n",
    "\n",
    "#SDE Collection most our our files are in the SDE.Survey folder\n",
    "#Collection.sde.SDE.Survey\n",
    "\n",
    "\n",
    "# local variables\n",
    "fdata = os.path.join(sdeBase, \"sde.SDE.Monitoring\")\n",
    "## Final feature class to append to in Enterprise Geodatabase double check this\n",
    "sdeSEZ = os.path.join(sdeBase, \"sde.SDE.Monitoring\\sde.SDE.SEZ_Assessment_Unit\")\n",
    "\n",
    "## GDB with Raw Data straight from S123 not in the original folder (that one is not edited)\n",
    "headcut23gdb = os.path.join(working_folder,\"Stream_Headcut\",\"Stream_Headcut_Survey\", \"Stream_Headcut_Survey_2023.gdb\")\n",
    "headcut22gdb = os.path.join(working_folder,\"Stream_Headcut\",\"Stream_Headcut_Survey\", \"Stream_Headcut_Survey_2022.gdb\")\n",
    "headcut20gdb = os.path.join(working_folder,\"Stream_Headcut\",\"Stream_Headcut_Survey\", \"Stream_Headcut_Survey_2020.gdb\")\n",
    "erosion23gdb = os.path.join(working_folder, \"Stream_Erosion\",\"Stream_Erosion_Survey\", \"Stream_Erosion_Survey_2023.gdb\")\n",
    "erosion22gdb = os.path.join(working_folder, \"Stream_Erosion\",\"Stream_Erosion_Survey\", \"Stream_Erosion_Survey_2022.gdb\")\n",
    "erosion20gdb = os.path.join(working_folder, \"Stream_Erosion\",\"Stream_Erosion_Survey\", \"Stream_Erosion_Survey_2020.gdb\")\n",
    "channelincision23gdb = os.path.join(working_folder,\"Channel_Incision\",\"Channel_Incision_Survey\",\"Channel_Incision_Survey_2023.gdb\")\n",
    "channelincision22gdb = os.path.join(working_folder, \"Channel_Incision\",\"Channel_Incision_Survey\",\"Channel_Incision_Survey_2022.gdb\")\n",
    "channelincision20gdb = os.path.join(working_folder, \"Channel_Incision\",\"Channel_Incision_Survey\",\"Channel_Incision_Survey_2020.gdb\")\n",
    "invasiveplant23gdb= os.path.join(working_folder,\"Invasive_Species\",\"Invasive_Species_Survey\",\"Invasive_Species_Survey_2023.gdb\")\n",
    "invasiveplant22gdb= os.path.join(working_folder,\"Invasive_Species\",\"Invasive_Species_Survey\",\"Invasive_Species_Survey_2022.gdb\")\n",
    "invasiveplant20gdb= os.path.join(working_folder,\"Invasive_Species\",\"Invasive_Species_Survey\",\"Invasive_Species_Survey_2020.gdb\")\n",
    "\n",
    "#This is thelocatoin for the final SEZ GDB to be updated in the gdb on f drive in the AssessmentUnits Master (polygon) i believe\n",
    "#FinalGDBtoupdate:F:\\GIS\\PROJECTS\\ResearchAnalysis\\SEZ\\Data \\SEZ_Data.gdb\n",
    "\n",
    "#Monitoring Dashboard location\n",
    "#Finalsdelocation:f'Vector.SDE' Sde.Monitoring Sde. SEZ_Assessment_Unit\n",
    "\n",
    "#Threshold Location? sde.tabular"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Stream Erosion "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#one gdb at a time ?\n",
    "\n",
    "#2023gdb\n",
    "# Name of the feature class or table\n",
    "fc_name = 'Stream_Erosion'\n",
    "\n",
    "# List to store rows from the attribute table\n",
    "data = []\n",
    "\n",
    "# Fields to include in the DataFrame\n",
    "fields22 = ['Assessment_Unit_Name', 'Bank_Type', 'Shape_Length']  # Add the names of the fields you want to include\n",
    "\n",
    "# Iterate over the attribute table using SearchCursor\n",
    "with arcpy.da.SearchCursor(f'{erosion23gdb}\\\\{fc_name}', fields) as cursor:\n",
    "    for row in cursor:\n",
    "        data.append(row)\n",
    "\n",
    "# Create a DataFrame from the list of rows\n",
    "erosion23df = pd.DataFrame(data, columns=fields)\n",
    "\n",
    "# Print the DataFrame\n",
    "print(erosion23df)\n",
    "\n",
    "#2022gdb\n",
    "# Name of the feature class or table\n",
    "fc22_name = 'Stream_Erosion_2022'\n",
    "\n",
    "# List to store rows from the attribute table\n",
    "data22 = []\n",
    "\n",
    "# Iterate over the attribute table using SearchCursor\n",
    "with arcpy.da.SearchCursor(f'{erosion22gdb}\\\\{fc22_name}', fields22) as cursor:\n",
    "    for row in cursor:\n",
    "        data.append(row)\n",
    "\n",
    "# Create a DataFrame from the list of rows\n",
    "erosion22df = pd.DataFrame(data22, columns=fields)\n",
    "\n",
    "# Print the DataFrame\n",
    "print(erosion22df)\n",
    "\n",
    "#2020gdb\n",
    "# Name of the feature class or table\n",
    "fc20_name = 'Stream_Erosion_Final_2022'\n",
    "\n",
    "# List to store rows from the attribute table\n",
    "data20 = []\n",
    "\n",
    "# Iterate over the attribute table using SearchCursor\n",
    "with arcpy.da.SearchCursor(f'{erosion20gdb}\\\\{fc20_name}', fields) as cursor:\n",
    "    for row in cursor:\n",
    "        data20.append(row)\n",
    "\n",
    "# Create a DataFrame from the list of rows\n",
    "erosion20df = pd.DataFrame(data, columns=fields)\n",
    "\n",
    "# Print the DataFrame\n",
    "print(erosion20df)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndentationError",
     "evalue": "unindent does not match any outer indentation level (<tokenize>, line 18)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  File \u001b[1;32m\"<tokenize>\"\u001b[1;36m, line \u001b[1;32m18\u001b[0m\n\u001b[1;33m    df = pd.DataFrame(erosiondfs)\u001b[0m\n\u001b[1;37m    ^\u001b[0m\n\u001b[1;31mIndentationError\u001b[0m\u001b[1;31m:\u001b[0m unindent does not match any outer indentation level\n"
     ]
    }
   ],
   "source": [
    "# Stream Erosion Data Processing from GDB Bank Stability to get this to update sde i will need to pull from 2020-2023 gdbs\n",
    "\n",
    "# Set the workspace to your Geodatabases\n",
    "#arcpy.env.workspace = Scratch.Gdbgdb\n",
    "\n",
    "# List of paths to geodatabases\n",
    "Erosiongdbs = ['erosion20gdb', 'erosion22gdb', 'erosion23gdb']\n",
    "\n",
    "# Initialize an empty list to store DataFrames\n",
    "erosiondfs = []\n",
    " # Iterate over features using SearchCursor\n",
    "    for fc in feature_classes:\n",
    "    fc_attributes = []\n",
    "    with arcpy.da.SearchCursor(fc, '*') as cursor:\n",
    "        for row in cursor:\n",
    "            fc_attributes.append(row)\n",
    "    df = pd.DataFrame(fc_attributes)\n",
    "    erosiondfs.append(df)\n",
    "with arcpy.da.SearchCursor(erosiondfs, '*') as cursor:\n",
    "            for row in cursor:\n",
    "                # Append feature attributes to the list\n",
    "                erosiondfs.append(row)\n",
    "        \n",
    "        # Convert feature attributes to DataFrame\n",
    "        df = pd.DataFrame(erosiondfs)\n",
    "# Iterate over each geodatabase\n",
    "#for gdb in Erosiongdbs:\n",
    "# List feature classes or tables in the geodatabase\n",
    "feature_classes = arcpy.ListFeatureClasses(\"*\", \"All\", gdb)\n",
    "    \n",
    "    \n",
    "    # Iterate over feature classes and tables\n",
    "  #  for fc in feature_classes:\n",
    "        # Convert feature class or table to DataFrame\n",
    "   #     df = pd.DataFrame(arcpy.da.FeatureClassToNumPyArray(fc, '*'))arcpy.da.SearchCursor()\n",
    "erosiondfs.append(df)\n",
    "#\n",
    "# Concatenate all DataFrames into a single DataFrame\n",
    "erosion_df = pd.concat(erosiondfs)\n",
    "\n",
    "# Now you have a single DataFrame containing data from multiple geodatabases\n",
    "\n",
    "# Input feature class or table its not a feature class? or is it a feature class within the gdb.. Do i need to bring in the table with photos too?\n",
    "input_fc = 'Stream_Erosion'\n",
    "\n",
    "# Convert feature class to Pandas DataFrame\n",
    "erosionfields = ['Assessment_Unit_Name', 'Shape_Length', 'Bank_Type', 'Percent_Unstable',]\n",
    "erosiondf = pd.DataFrame.from_records(data=arcpy.da.SearchCursor(input_fc, erosionfields), columns=erosionfields)\n",
    "\n",
    "# Initialize variables\n",
    "erosion_df['bank_multiplier'] = erosion_df['Bank_Type'].apply(lambda x: 2 if x == 'Both Banks' else (1 if x == 'One Bank' else 0))\n",
    "\n",
    "# Calculate the total length of banks assessed\n",
    "total_banks_assessed = (erosion_df['Shape_Length'].sum()) * 2\n",
    "\n",
    "# Calculate the total length of eroded banks\n",
    "total_eroded_banks = (erosion_df['Shape_Length'] * erosion_df['bank_multiplier']).sum()\n",
    "\n",
    "# calculate percent unstable 'percent_unstable' column!!! Bank Stability and we will need to add a column to the dataframe\n",
    "erosion_df['percent_unstable'] = (total_eroded_banks / total_banks_assessed) * 100\n",
    "\n",
    "print(\"Total Banks Assessed:\", total_banks_assessed)\n",
    "print(\"Total Eroded Banks:\", total_eroded_banks)\n",
    "print(\"Updated DataFrame:\")\n",
    "print(erosion_df)\n",
    "\n",
    "#field mapping? what is the fi nal location\n",
    "#field_mapping ={\n",
    "\n",
    "    #'Assessment_Unit_Name': \n",
    "    #'Shape_Length'\n",
    "    #\"Bank_Type\"\n",
    "    #'Percent_Unstable'\n",
    "#}\n",
    "\n",
    "# Create a new DataFrame Final_df with columns based on the field mapping\n",
    "#df = df.rename(columns=field_mapping)\n",
    "\n",
    "# Convert DataFrame to Spatially Enabled DataFrame\n",
    "sedf = GeoAccessor.from_xy(erosion_df, x_column='LONGITUDE', y_column='LATITUDE')\n",
    "\n",
    "# Convert the SEDF to a feature class without sanitizing columns where do i want this to live... its all of the gdb's combined so where do i update it.. to each gdb or individually or create a new one or put a copy into scratch.gdb and then some how write back \n",
    "sedf.spatial.to_featureclass(location=os.path.join(workspace, 'Erosion_Staging'), sanitize_columns=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Channel Incision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Channel Incision Process Data\n",
    "\n",
    "# List of paths to geodatabases\n",
    "channelincisiongdbs = ['channelincision20gdb', 'channelincision22gdb', 'channelincision23gdb']\n",
    "\n",
    "# Initialize an empty list to store DataFrames\n",
    "channeldfs = []\n",
    "\n",
    "# Iterate over each geodatabase\n",
    "for gdb in channelincisiongdbs:\n",
    "    # List feature classes or tables in the geodatabase\n",
    "    feature_classes = arcpy.ListFeatureClasses(\"*\", \"All\", gdb)\n",
    "    tables = arcpy.ListTables(\"*\", \"All\", gdb)\n",
    "    \n",
    "    # Iterate over feature classes and tables\n",
    "    for fc in feature_classes + tables:\n",
    "        # Convert feature class or table to DataFrame\n",
    "        df = pd.DataFrame(arcpy.da.FeatureClassToNumPyArray(fc, '*'))\n",
    "        dhanneldfs.append(df)\n",
    "\n",
    "# Concatenate all DataFrames into a single DataFrame\n",
    "erosion_df = pd.concat(channeldfs)\n",
    "\n",
    "#Processing of Channel Incision Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Invasive Species"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Invasive Species"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### HEadcuts\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Headcuts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bioassessment/ Biotic Integrity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Bioassessment scores- get all stream data into sde.Stream first... then look at Biotic Integrit Data Source to find which stream was used to evaluate each meadow.. this will help with percent of stream miles I believe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Conifer Encroachment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Aquatic Organism /Fish Passage"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Code to make it a spatially enabled dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#code to conver to spatially enable geodataframe\n",
    "# Create a new DataFrame Final_df with columns based on the field mapping\n",
    "#df = df.rename(columns=field_mapping)\n",
    "\n",
    "# Convert DataFrame to Spatially Enabled DataFrame\n",
    "#sedf = GeoAccessor.from_xy(df, x_column='LONGITUDE', y_column='LATITUDE')\n",
    "\n",
    "# Convert the SEDF to a feature class without sanitizing columns\n",
    "#sedf.spatial.to_featureclass(location=os.path.join(workspace, 'PlanAreaNoise_23_Staging'), sanitize_columns=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Code for Grading each parameter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Grading for each parameter add to final SDE file?\n",
    "#Defining Grade for Channel Stability based on Erosiondf[percent_unstable]\n",
    "def categorize_erosion(Percent_Unstable):\n",
    "    if 0 <= value < 5:\n",
    "        return 'A'\n",
    "    elif 5 <= value < 20:\n",
    "        return 'B'\n",
    "    elif 20 <= value < 50:\n",
    "        return 'C'\n",
    "    else:\n",
    "        return 'D'\n",
    "\n",
    "\n",
    "#Define Grade for Incision based off of bankful height to bankful depth\n",
    "\n",
    "def categorize_incision(bankful_ratio)\n",
    "     if 0 <= bankful_ratio < 1.2:\n",
    "        return 'A'\n",
    "    elif 1.2 <= bankful_ratio < 1.6:\n",
    "        return 'B'\n",
    "    elif 1.6 <= bankful_ratio < 2.1:\n",
    "        return 'C'\n",
    "    else:\n",
    "        return 'D'\n",
    "\n",
    "#Define Grade for Headcut based off of headcut size---fix this\n",
    "def categorize_headcut(value)\n",
    "     if value = 0\n",
    "        return 'A'\n",
    "    elif 1.2 <= value < 1.6:\n",
    "        return 'B'\n",
    "    elif value =\n",
    "        return 'C'\n",
    "    else:\n",
    "        return 'D'\n",
    "\n",
    "Define Grade for Invasive based off of invasive\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
