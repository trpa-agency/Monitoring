{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set Up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import arcpy\n",
    "from datetime import datetime\n",
    "import os\n",
    "import sys\n",
    "from sqlalchemy.engine import URL\n",
    "from sqlalchemy import create_engine\n",
    "import sqlalchemy as sa\n",
    "import pandas as pd\n",
    "from arcgis import GIS\n",
    "from arcgis.features import FeatureSet, GeoAccessor, GeoSeriesAccessor, FeatureLayer\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import requests\n",
    "\n",
    "\n",
    "gis = GIS()\n",
    "# # Set Pandas display options to show all rows and columns\n",
    "# pd.set_option('display.max_rows', None)\n",
    "# pd.set_option('display.max_columns', None)\n",
    "\n",
    "# in memory output file path\n",
    "wk_memory = \"memory\" + \"\\\\\"\n",
    "\n",
    "\n",
    "# set workspace and sde connections \n",
    "#working_folder = \"C:\\GIS\"\n",
    "#working_folder = \"F:/GIS/GIS_DATA/Monitoring/\"\n",
    "workspace      = \"C:\\GIS\\Scratch.gdb\"\n",
    "#arcpy.env.workspace = \"C:\\GIS\\Scratch.gdb\"\n",
    "#workspace ='F:\\Research and Analysis\\Workspace\\Sarah\\Data Management 2023\\Scratch.gdb'\n",
    "#arcpy.env.workspace = 'F:\\Research and Analysis\\Workspace\\Sarah\\Data Management 2023\\Scratch.gdb'\n",
    "\n",
    "# network path to connection files\n",
    "filePath = \"C:\\\\GIS\\\\DB_CONNECT\"\n",
    "\n",
    "#path to GDB's to update and master data\n",
    "master_path = \"F:\\GIS\\PROJECTS\\ResearchAnalysis\\SEZ\\Data\\SEZ_Data.gdb\"\n",
    "SEZ_Master = os.path.join(master_path, \"AssessmentUnits_Master\")\n",
    "\n",
    "# database file paths \n",
    "### SDE Collection New data collected is put into SDE.Survey under the indicator name\n",
    "### SDE Vector is where the data will go \n",
    "#sdeBase    = os.path.join(filePath, \"Vector.sde\")\n",
    "sdeCollect = os.path.join(filePath, \"Collection.sde\")\n",
    "sdeBase    = os.path.join(filePath, \"SarahVector.sde\")\n",
    "#sdeCollect = os.path.join(filepath, \"SarahCollect.sde\")\n",
    "\n",
    "# setup connection string???\n",
    "connection_string = \"DRIVER={ODBC Driver 17 for SQL Server};SERVER=sql12;DATABASE=sde;UID=sde;PWD=staff\"\n",
    "connection_url = URL.create(\"mssql+pyodbc\", query={\"odbc_connect\": connection_string})\n",
    "engine = create_engine(connection_url)\n",
    "\n",
    "#with engine.begin() as sdeConnect:\n",
    " #   erosiondf      = pd.read_sql(\"SELECT * FROM sde.SDE.Stream_Erosion\", sdeConnect)\n",
    "\n",
    "# local variables sdata is starting data and f data is finishing datatables\n",
    "ffdata = os.path.join(sdeBase, \"sde.SDE.Monitoring\")\n",
    "sdata = os.path.join(sdeCollect, \"sde.SDE.Survey\")\n",
    "fdata = os.path.join(master_path, \"AssessmentUnits_Master\")\n",
    "\n",
    "##Tables we get the data from in Collect\n",
    "sezsurveytable = os.path.join(sdata, \"sde.SDE.sez_survey\")\n",
    "erosiondata = os.path.join(sdata, \"sde.SDE.Stream_Erosion\")\n",
    "incisiondata = os.path.join(sdata, \"sde.SDE.sez_channel_incision\")\n",
    "invasivedata = os.path.join(sdata, \"sde.SDE.sez_invasive_plant\")\n",
    "headcutdata = os.path.join(sdata, \"sde.SDE.sez_stream_headcut\")\n",
    "streamdata = os.path.join(ffdata, \"sde.SDE.Stream\")\n",
    "\n",
    "\n",
    "#Staging Tables currently living in SEZ_Data.GDB\n",
    "stage_bank_stability = os.path.join(master_path, \"bank_stability\") \n",
    "stage_All_SEZ_Scores = os.path.join(master_path, \"All_SEZ_Scores\")\n",
    "stage_biotic_integrity = os.path.join(master_path, \"biotic_integrity\")\n",
    "stage_headcuts_table = os.path.join(master_path, \"heacuts_table\")\n",
    "stage_incision = os.path.join(master_path, \"incision\")\n",
    "stage_invasives = os.path.join(master_path, \"invasives\")\n",
    "\n",
    "\n",
    "\n",
    "#Final table to append to\n",
    "#finalSEZtable = os.path.join(fdata, \"sde.SDE.SEZ_Assessment_Unit\")\n",
    "#finalSEZtable = os.path.join(master_path, \"AssessmentUnits_Master\")\n",
    "\n",
    "\n",
    "# network path to connection files??????\n",
    "#filePath = \"C:\\\\GIS\\\\DB_CONNECT\"\n",
    "# network path to connection files\n",
    "#filePath = r'F:\\Research and Analysis\\Workspace\\Sarah'\n",
    "\n",
    "#--------------------------------------------#\n",
    "#Notes to self\n",
    "#--------------------------------------------#\n",
    "#F:\\GIS\\PROJECTS\\ResearchAnalysis\\SEZ\\Data\\SEZ_Data.gdb. \n",
    "###'Assessment_Unit_Master' has all data for SEZ\n",
    "###“Bioassessment Sample Locations” has stream sites in SEZs\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "## GDB with Raw Data straight from S123 not in the original folder (that one is not edited)\n",
    "#headcut23gdb = os.path.join(working_folder,\"Stream_Headcut\",\"Stream_Headcut_Survey\", \"Stream_Headcut_Survey_2023.gdb\")\n",
    "#headcut22gdb = os.path.join(working_folder,\"Stream_Headcut\",\"Stream_Headcut_Survey\", \"Stream_Headcut_Survey_2022.gdb\")\n",
    "#headcut20gdb = os.path.join(working_folder,\"Stream_Headcut\",\"Stream_Headcut_Survey\", \"Stream_Headcut_Survey_2020.gdb\")\n",
    "#erosion23gdb = os.path.join(working_folder, \"Stream_Erosion\",\"Stream_Erosion_Survey\", \"Stream_Erosion_Survey_2023.gdb\")\n",
    "#erosion22gdb = os.path.join(working_folder, \"Stream_Erosion\",\"Stream_Erosion_Survey\", \"Stream_Erosion_Survey_2022.gdb\")\n",
    "#erosion20gdb = os.path.join(working_folder, \"Stream_Erosion\",\"Stream_Erosion_Survey\", \"Stream_Erosion_Survey_2020.gdb\")\n",
    "#channelincision23gdb = os.path.join(working_folder,\"Channel_Incision\",\"Channel_Incision_Survey\",\"Channel_Incision_Survey_2023.gdb\")\n",
    "#channelincision22gdb = os.path.join(working_folder, \"Channel_Incision\",\"Channel_Incision_Survey\",\"Channel_Incision_Survey_2022.gdb\")\n",
    "#channelincision20gdb = os.path.join(working_folder, \"Channel_Incision\",\"Channel_Incision_Survey\",\"Channel_Incision_Survey_2020.gdb\")\n",
    "#invasiveplant23gdb= os.path.join(working_folder,\"Invasive_Species\",\"Invasive_Species_Survey\",\"Invasive_Species_Survey_2023.gdb\")\n",
    "#invasiveplant22gdb= os.path.join(working_folder,\"Invasive_Species\",\"Invasive_Species_Survey\",\"Invasive_Species_Survey_2022.gdb\")\n",
    "#invasiveplant20gdb= os.path.join(working_folder,\"Invasive_Species\",\"Invasive_Species_Survey\",\"Invasive_Species_Survey_2020.gdb\")\n",
    "\n",
    "#This is thelocatoin for the final SEZ GDB to be updated in the gdb on f drive in the AssessmentUnits Master (polygon) i believe\n",
    "#FinalGDBtoupdate:F:\\GIS\\PROJECTS\\ResearchAnalysis\\SEZ\\Data \\SEZ_Data.gdb\n",
    "\n",
    "#Monitoring Dashboard location\n",
    "#Finalsdelocation:f'Vector.SDE' Sde.Monitoring Sde. SEZ_Assessment_Unit\n",
    "\n",
    "#Threshold Location? sde.tabular"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lookup Dictionary for SEZ ID's\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "ERROR 999999: Something unexpected caused the tool to fail. Contact Esri Technical Support (http://esriurl.com/support) to Report a Bug, and refer to the error help for potential solutions or workarounds.\nGeneral function failure",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_19984\\2439451946.py\u001b[0m in \u001b[0;36m<cell line: 14>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     12\u001b[0m \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     13\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 14\u001b[1;33m \u001b[1;32mwith\u001b[0m \u001b[0marcpy\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mSearchCursor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mSEZ_Master\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfields\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mcursor\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     15\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mrow\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mcursor\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     16\u001b[0m         \u001b[0mdata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrow\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Program Files\\ArcGIS\\Pro\\Resources\\ArcPy\\arcpy\\__init__.py\u001b[0m in \u001b[0;36mSearchCursor\u001b[1;34m(dataset, where_clause, spatial_reference, fields, sort_fields)\u001b[0m\n\u001b[0;32m   1260\u001b[0m        \u001b[0mFields\u001b[0m \u001b[0mused\u001b[0m \u001b[0mto\u001b[0m \u001b[0msort\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mrows\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mcursor\u001b[0m\u001b[1;33m.\u001b[0m \u001b[0mAscending\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mdescending\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1261\u001b[0m        order for each field is denoted by A and D.\"\"\"\n\u001b[1;32m-> 1262\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mgp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msearchCursor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mwhere_clause\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mspatial_reference\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfields\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msort_fields\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1263\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1264\u001b[0m \u001b[1;33m@\u001b[0m\u001b[0m_gptooldoc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"FeatureLayer\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"Table\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"TableView\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"Dataset\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"FeatureDataset\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Program Files\\ArcGIS\\Pro\\Resources\\ArcPy\\arcpy\\geoprocessing\\_base.py\u001b[0m in \u001b[0;36msearchCursor\u001b[1;34m(self, *args)\u001b[0m\n\u001b[0;32m    375\u001b[0m         \u001b[1;32mfrom\u001b[0m \u001b[0marcpy\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marcobjects\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marcobjectconversion\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mconvertArcObjectToPythonObject\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    376\u001b[0m         return convertArcObjectToPythonObject(\n\u001b[1;32m--> 377\u001b[1;33m                     self._gp.SearchCursor(*gp_fixargs(args, True)))\n\u001b[0m\u001b[0;32m    378\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mupdateCursor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    379\u001b[0m         \u001b[1;34m\"\"\"GP function UpdateCursor\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mRuntimeError\u001b[0m: ERROR 999999: Something unexpected caused the tool to fail. Contact Esri Technical Support (http://esriurl.com/support) to Report a Bug, and refer to the error help for potential solutions or workarounds.\nGeneral function failure"
     ]
    }
   ],
   "source": [
    "#Create look up dictionary for SEZ_ID fill in\n",
    "\n",
    "\n",
    "# Set workspace environment\n",
    "arcpy.env.workspace = master_path\n",
    "\n",
    "# Specify the feature class name SEZ_Master\n",
    "#feature_class = \"AssessmentUnits_Master\"\n",
    "\n",
    "# Create a cursor to iterate over the rows in the feature class\n",
    "fields = ['Assessment_Unit_Name', 'SEZ_ID']\n",
    "data = []\n",
    "\n",
    "with arcpy.SearchCursor(SEZ_Master, fields) as cursor:\n",
    "    for row in cursor:\n",
    "        data.append(row)\n",
    "\n",
    "# Convert the data to a Pandas DataFrame\n",
    "df = pd.DataFrame(data, columns=fields)\n",
    "\n",
    "# Define function to update SEZ ID lookup dictionary\n",
    "def update_SEZID_lookup_dict(df, lookup_dict):\n",
    "    for index, row in df.iterrows():\n",
    "        # Update SEZ_ID column in DataFrame with data from the lookup dictionary\n",
    "        df.at[index, 'SEZ_ID'] = lookup_dict.get(row['Assessment_Unit_Name'], None)\n",
    "\n",
    "    return df\n",
    "\n",
    "# Assuming 'Assessment_Unit_Name' is the common identifier between DataFrame and lookup dictionary\n",
    "selected_columns = ['Assessment_Unit_Name', 'SEZ_ID']\n",
    "\n",
    "# Drop duplicates based on 'Assessment_Unit_Name' and keep the first occurrence\n",
    "unique_values = df.drop_duplicates(subset='Assessment_Unit_Name', keep='first')\n",
    "\n",
    "# Convert selected columns to dictionary\n",
    "lookup_dict = unique_values[selected_columns].set_index('Assessment_Unit_Name').to_dict(orient='index')\n",
    "\n",
    "# Display the dictionary\n",
    "print(lookup_dict)\n",
    "\n",
    "# Update 'SEZ_ID' in other DataFrame with data from the lookup dictionary do this for each indicator...\n",
    "#Other_df = update_SEZID_lookup_dict(Other_df, lookup_dict)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "An error occurred: General function failure\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Stream Erosion "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "module 'geopandas' has no attribute 'DataFrame'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_19984\\1371007975.py\u001b[0m in \u001b[0;36m<cell line: 8>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[1;31m#counters = sdeBase + \"\\\\sde.SDE.Transportation\\\\sde.SDE.bike_ped_counter_spatial\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 8\u001b[1;33m \u001b[0merosiondf\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mspatial\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfrom_featureclass\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstreamerosiontable\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      9\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAttributeError\u001b[0m: module 'geopandas' has no attribute 'DataFrame'"
     ]
    }
   ],
   "source": [
    "#---------------------------------------------------------------#\n",
    "#GET DATA\n",
    "#---------------------------------------------------------------#\n",
    "#with engine.begin() as sdeConnect:\n",
    " #   erosiondf      = pd.read_sql(\"SELECT * FROM sde.SDE.Stream_Erosion\", sdeConnect)\n",
    "\n",
    "#counters = sdeBase + \"\\\\sde.SDE.Transportation\\\\sde.SDE.bike_ped_counter_spatial\"\n",
    "#erosiondf = pd.DataFrame.spatial.from_featureclass(streamerosiontable)\n",
    "\n",
    "#Convert feature class in gdb to Pandas DataFrame this is for REST Service\n",
    "erosionfields = ['Assessment_Unit_Name', 'Shape.STLength()', 'Bank_Type', 'Percent_Unstable',]\n",
    "erosiondf = pd.DataFrame.from_records(data=arcpy.da.SearchCursor(erosiondata, erosionfields), columns=erosionfields)\n",
    " \n",
    "#----------------------------------------------------------------#\n",
    "#Process Data, Grade, Score\n",
    "#----------------------------------------------------------------#\n",
    "#Initialize variables\n",
    "erosiondf['bank_multiplier'] = erosiondf['Bank_Type'].apply(lambda x: 2 if x == 'Both Banks' else (1 if x == 'One Bank' else 0))\n",
    "\n",
    "# Calculate the total length of banks assessed\n",
    "total_banks_assessed = (erosiondf['Shape_Length'].sum()) * 2\n",
    "\n",
    "# Calculate the total length of eroded banks\n",
    "total_eroded_banks = (erosiondf['Shape_Length'] * erosiondf['bank_multiplier']).sum()\n",
    "\n",
    "# calculate percent unstable 'percent_unstable' column!!! Bank Stability and we will need to add a column to the dataframe\n",
    "erosiondf['percent_unstable'] = (total_eroded_banks / total_banks_assessed) * 100\n",
    "\n",
    "print(\"Total Banks Assessed:\", total_banks_assessed)\n",
    "print(\"Total Eroded Banks:\", total_eroded_banks)\n",
    "print(\"Updated DataFrame:\")\n",
    "print(erosiondf)\n",
    "erosiondf.info()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Input feature class \n",
    "input_fc = 'Stream_Erosion'\n",
    "\n",
    "# Convert feature class to Pandas DataFrame\n",
    "erosionfields = ['Assessment_Unit_Name', 'Shape.STLength()', 'Bank_Type', 'Percent_Unstable',]\n",
    "erosiondf = pd.DataFrame.from_records(data=arcpy.da.SearchCursor(input_fc, erosionfields), columns=erosionfields)\n",
    "\n",
    "# Initialize variables\n",
    "erosiondf['bank_multiplier'] = erosiondf['Bank_Type'].apply(lambda x: 2 if x == 'Both Banks' else (1 if x == 'One Bank' else 0))\n",
    "\n",
    "# Calculate the total length of banks assessed\n",
    "total_banks_assessed = (erosiondf['Shape_Length'].sum()) * 2\n",
    "\n",
    "# Calculate the total length of eroded banks\n",
    "total_eroded_banks = (erosiondf['Shape_Length'] * erosiondf['bank_multiplier']).sum()\n",
    "\n",
    "# calculate percent unstable 'percent_unstable' column!!! Bank Stability and we will need to add a column to the dataframe\n",
    "erosiondf['percent_unstable'] = (total_eroded_banks / total_banks_assessed) * 100\n",
    "\n",
    "print(\"Total Banks Assessed:\", total_banks_assessed)\n",
    "print(\"Total Eroded Banks:\", total_eroded_banks)\n",
    "print(\"Updated DataFrame:\")\n",
    "print(erosiondf)\n",
    "\n",
    "#field mapping? what is the fi nal location\n",
    "#field_mapping ={\n",
    "\n",
    "    #'Assessment_Unit_Name': \n",
    "    #'Shape_Length'\n",
    "    #\"Bank_Type\"\n",
    "    #'Percent_Unstable'\n",
    "#}\n",
    "\n",
    "# Create a new DataFrame Final_df with columns based on the field mapping\n",
    "#df = df.rename(columns=field_mapping)\n",
    "\n",
    "# Convert DataFrame to Spatially Enabled DataFrame\n",
    "sedf = GeoAccessor.from_xy(erosiondf, x_column='LONGITUDE', y_column='LATITUDE')\n",
    "\n",
    "# Convert the SEDF to a feature class without sanitizing columns where do i want this to live... its all of the gdb's combined so where do i update it.. to each gdb or individually or create a new one or put a copy into scratch.gdb and then some how write back \n",
    "sedf.spatial.to_featureclass(location=os.path.join(workspace, 'Erosion_Staging'), sanitize_columns=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Channel Incision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Channel Incision Process Data\n",
    "\n",
    "# List of paths to geodatabases\n",
    "channelincisiongdbs = ['channelincision20gdb', 'channelincision22gdb', 'channelincision23gdb']\n",
    "\n",
    "# Initialize an empty list to store DataFrames\n",
    "channeldfs = []\n",
    "\n",
    "# Iterate over each geodatabase\n",
    "for gdb in channelincisiongdbs:\n",
    "    # List feature classes or tables in the geodatabase\n",
    "    feature_classes = arcpy.ListFeatureClasses(\"*\", \"All\", gdb)\n",
    "    tables = arcpy.ListTables(\"*\", \"All\", gdb)\n",
    "    \n",
    "    # Iterate over feature classes and tables\n",
    "    for fc in feature_classes + tables:\n",
    "        # Convert feature class or table to DataFrame\n",
    "        df = pd.DataFrame(arcpy.da.FeatureClassToNumPyArray(fc, '*'))\n",
    "        dhanneldfs.append(df)\n",
    "\n",
    "# Concatenate all DataFrames into a single DataFrame\n",
    "erosion_df = pd.concat(channeldfs)\n",
    "\n",
    "#Processing of Channel Incision Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Invasive Species"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Invasive Species"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### HEadcuts\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Headcuts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bioassessment/ Biotic Integrity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Bioassessment scores- get all stream data into sde.Stream first... then look at Biotic Integrit Data Source to find which stream was used to evaluate each meadow.. this will help with percent of stream miles I believe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Conifer Encroachment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Aquatic Organism /Fish Passage"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Code to make it a spatially enabled dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#code to conver to spatially enable geodataframe\n",
    "# Create a new DataFrame Final_df with columns based on the field mapping\n",
    "#df = df.rename(columns=field_mapping)\n",
    "\n",
    "# Convert DataFrame to Spatially Enabled DataFrame\n",
    "#sedf = GeoAccessor.from_xy(df, x_column='LONGITUDE', y_column='LATITUDE')\n",
    "\n",
    "# Convert the SEDF to a feature class without sanitizing columns\n",
    "#sedf.spatial.to_featureclass(location=os.path.join(workspace, 'PlanAreaNoise_23_Staging'), sanitize_columns=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Code for Grading each parameter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Grading for each parameter add to final SDE file?\n",
    "#Defining Grade for Bank Stability based on Erosiondf[percent_unstable]\n",
    "def categorize_erosion(Percent_Unstable):\n",
    "    if 0 <= value < 5:\n",
    "        return 'A'\n",
    "    elif 5 <= value < 20:\n",
    "        return 'B'\n",
    "    elif 20 <= value < 50:\n",
    "        return 'C'\n",
    "    else:\n",
    "        return 'D'\n",
    "    \n",
    "#Scoring based off of grading\n",
    "    def categorize_erosion(Bank_Stability_Score)\n",
    "\n",
    "\n",
    "#Define Grade for Incision based off of incisino ratio\n",
    "\n",
    "def categorize_incision(bankful_ratio)\n",
    "     if 0 <= bankful_ratio < 1.2:\n",
    "        return 'A'\n",
    "    elif 1.2 <= bankful_ratio < 1.6:\n",
    "        return 'B'\n",
    "    elif 1.6 <= bankful_ratio < 2.1:\n",
    "        return 'C'\n",
    "    else:\n",
    "        return 'D'\n",
    "\n",
    "#Define Grade for Bioassessment Score\n",
    "def categorize_csci(biotic_integrity)\n",
    "     if   biotic_integrity > 0.92:\n",
    "        return 'A'\n",
    "    elif 0.79 < biotic_integrity <= 0.92:\n",
    "        return 'B'\n",
    "    elif 0.62 < biotic_integrity <= 0.79:\n",
    "        return 'C'\n",
    "    else:\n",
    "        return 'D'\n",
    "\n",
    "#Define Grade for Invasive Plant Species Rating\n",
    "\n",
    "def categorize_invasive(Invasive_Level)\n",
    "      \n",
    "\n",
    "\n",
    "def invasive_rating(grade)\n",
    "\n",
    "#Define Size for Headcut based off of headcut size---fix this\n",
    "##A = 0 headcut, B 1+small headcut\n",
    "def categorize_headcut(value)\n",
    "     if 0.1 <= value < 0.5:\n",
    "        return 'small'\n",
    "    elif 0.5 <= value < 1:\n",
    "        return 'medium'\n",
    "    else:\n",
    "        return 'large'\n",
    "\n",
    "#Define Size for Headcut based off of headcut size---fix this\n",
    "##A = 0 headcut, B 1+small headcut\n",
    "def categorize_headcutgrade(headcutgrade)\n",
    "     if value = 0\n",
    "        return 'A'\n",
    "    elif 1.2 <= value < 1.6:\n",
    "        return 'B'\n",
    "    elif value =\n",
    "        return 'C'\n",
    "    else:\n",
    "        return 'D'\n",
    "\n",
    "#Define Grade for Invasive \n",
    "#A=0, B=1 level 2, C 2 level 2 or 1 level 1, D=3+ level 2 or 2+ level 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
