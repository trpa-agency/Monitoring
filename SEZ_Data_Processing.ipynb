{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set Up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import arcpy\n",
    "from datetime import datetime\n",
    "import os\n",
    "import sys\n",
    "from sqlalchemy.engine import URL\n",
    "from sqlalchemy import create_engine\n",
    "import sqlalchemy as sa\n",
    "import pandas as pd\n",
    "from arcgis import GIS\n",
    "from arcgis.features import FeatureSet, GeoAccessor, GeoSeriesAccessor, FeatureLayer\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import requests\n",
    "\n",
    "\n",
    "gis = GIS()\n",
    "# # Set Pandas display options to show all rows and columns\n",
    "# pd.set_option('display.max_rows', None)\n",
    "# pd.set_option('display.max_columns', None)\n",
    "\n",
    "# in memory output file path\n",
    "wk_memory = \"memory\" + \"\\\\\"\n",
    "\n",
    "\n",
    "# set workspace and sde connections \n",
    "#working_folder = \"C:\\GIS\"\n",
    "gdbworking_folder = \"F:\\GIS\\GIS_DATA\\Monitoring\"\n",
    "#workspace      = \"C:\\GIS\\Scratch.gdb\"\n",
    "#arcpy.env.workspace = \"C:\\GIS\\Scratch.gdb\"\n",
    "#workspace ='F:\\Research and Analysis\\Workspace\\Sarah\\Data Management 2023\\Scratch.gdb'\n",
    "#arcpy.env.workspace = 'F:\\Research and Analysis\\Workspace\\Sarah\\Data Management 2023\\Scratch.gdb'\n",
    "\n",
    "# network path to connection files\n",
    "filePath = \"F:\\\\GIS\\\\DB_CONNECT\"\n",
    "\n",
    "#path to GDB's to update and master data\n",
    "master_path = \"F:\\GIS\\PROJECTS\\ResearchAnalysis\\SEZ\\Data\\SEZ_Data.gdb\"\n",
    "SEZ_Master = os.path.join(master_path, \"AssessmentUnits_Master\")\n",
    "#set workspace for connection to GDB\n",
    "#workspace=master_path\n",
    "# database file paths \n",
    "### SDE Collection New data collected is put into SDE.Survey under the indicator name\n",
    "### SDE Vector is where the data will go \n",
    "#sdeBase    = os.path.join(filePath, \"Vector.sde\")\n",
    "sdeCollect = os.path.join(filePath, \"Collection.sde\")\n",
    "sdeBase    = os.path.join(filePath, \"SarahVector.sde\")\n",
    "#sdeCollect = os.path.join(filepath, \"SarahCollect.sde\")\n",
    "\n",
    "# setup connection string???\n",
    "connection_string = \"DRIVER={ODBC Driver 17 for SQL Server};SERVER=sql12;DATABASE=sde;UID=sde;PWD=staff\"\n",
    "connection_url = URL.create(\"mssql+pyodbc\", query={\"odbc_connect\": connection_string})\n",
    "engine = create_engine(connection_url)\n",
    "\n",
    "#with engine.begin() as sdeConnect:\n",
    " #   erosiondf      = pd.read_sql(\"SELECT * FROM sde.SDE.Stream_Erosion\", sdeConnect)\n",
    "\n",
    "# local variables sdata is starting data and f data is finishing datatables\n",
    "ffdata = os.path.join(sdeBase, \"sde.SDE.Monitoring\")\n",
    "sdata = os.path.join(sdeCollect, \"sde.SDE.Survey\")\n",
    "fdata = os.path.join(master_path, \"AssessmentUnits_Master\")\n",
    "\n",
    "##Tables we get the data from in Collect\n",
    "sezsurveytable = os.path.join(sdata, \"sde.SDE.sez_survey\")\n",
    "erosiondata = os.path.join(sdata, \"sde.SDE.Stream_Erosion\")\n",
    "incisiondata = os.path.join(sdata, \"sde.SDE.sez_channel_incision\")\n",
    "invasivedata = os.path.join(sdata, \"sde.SDE.sez_invasive_plant\")\n",
    "headcutdata = os.path.join(sdata, \"sde.SDE.sez_stream_headcut\")\n",
    "streamdata = os.path.join(ffdata, \"sde.SDE.Stream\")\n",
    "\n",
    "\n",
    "#Staging Tables currently living in SEZ_Data.GDB\n",
    "stage_bank_stability = os.path.join(master_path, \"bank_stability\") \n",
    "stage_All_SEZ_Scores = os.path.join(master_path, \"All_SEZ_Scores\")\n",
    "stage_biotic_integrity = os.path.join(master_path, \"biotic_integrity\")\n",
    "stage_headcuts = os.path.join(master_path, \"headcuts_table\")\n",
    "stage_incision = os.path.join(master_path, \"incision\")\n",
    "stage_invasives = os.path.join(master_path, \"invasives\")\n",
    "\n",
    "\n",
    "\n",
    "#Final table to append to\n",
    "#finalSEZtable = os.path.join(fdata, \"sde.SDE.SEZ_Assessment_Unit\")\n",
    "#finalSEZtable = os.path.join(master_path, \"AssessmentUnits_Master\")\n",
    "\n",
    "\n",
    "# network path to connection files??????\n",
    "#filePath = \"C:\\\\GIS\\\\DB_CONNECT\"\n",
    "# network path to connection files\n",
    "#filePath = r'F:\\Research and Analysis\\Workspace\\Sarah'\n",
    "\n",
    "#--------------------------------------------#\n",
    "#Notes to self\n",
    "#--------------------------------------------#\n",
    "#F:\\GIS\\PROJECTS\\ResearchAnalysis\\SEZ\\Data\\SEZ_Data.gdb. \n",
    "###'Assessment_Unit_Master' has all data for SEZ\n",
    "###“Bioassessment Sample Locations” has stream sites in SEZs\n",
    "\n",
    "\n",
    "headcutgdbfolder = os.path.join(gdbworking_folder, \"Stream_Headcut\", \"StreamHeadcut_Survey\")\n",
    "\n",
    "## GDB with Raw Data straight from S123 not in the original folder (that one is not edited)\n",
    "headcut23gdb = os.path.join(headcutgdbfolder, \"Stream_Headcut_Survey_2023.gdb\")\n",
    "headcut22gdb = os.path.join(headcutgdbfolder, \"Stream_Headcut_Survey_2022.gdb\")\n",
    "headcut20gdb = os.path.join(headcutgdbfolder, \"Stream_Headcut_Survey_2020.gdb\")\n",
    "headcut19gdb = os.path.join(headcutgdbfolder, \"Stream_Headcut_Survey_2019.gdb\")\n",
    "#erosion23gdb = os.path.join(gdbworking_folder, \"Stream_Erosion\",\"Stream_Erosion_Survey\", \"Stream_Erosion_Survey_2023.gdb\")\n",
    "#erosion22gdb = os.path.join(working_folder, \"Stream_Erosion\",\"Stream_Erosion_Survey\", \"Stream_Erosion_Survey_2022.gdb\")\n",
    "#erosion20gdb = os.path.join(working_folder, \"Stream_Erosion\",\"Stream_Erosion_Survey\", \"Stream_Erosion_Survey_2020.gdb\")\n",
    "#channelincision23gdb = os.path.join(working_folder,\"Channel_Incision\",\"Channel_Incision_Survey\",\"Channel_Incision_Survey_2023.gdb\")\n",
    "#channelincision22gdb = os.path.join(working_folder, \"Channel_Incision\",\"Channel_Incision_Survey\",\"Channel_Incision_Survey_2022.gdb\")\n",
    "#channelincision20gdb = os.path.join(working_folder, \"Channel_Incision\",\"Channel_Incision_Survey\",\"Channel_Incision_Survey_2020.gdb\")\n",
    "#invasiveplant23gdb= os.path.join(working_folder,\"Invasive_Species\",\"Invasive_Species_Survey\",\"Invasive_Species_Survey_2023.gdb\")\n",
    "#invasiveplant22gdb= os.path.join(working_folder,\"Invasive_Species\",\"Invasive_Species_Survey\",\"Invasive_Species_Survey_2022.gdb\")\n",
    "#invasiveplant20gdb= os.path.join(working_folder,\"Invasive_Species\",\"Invasive_Species_Survey\",\"Invasive_Species_Survey_2020.gdb\")\n",
    "\n",
    "#This is thelocatoin for the final SEZ GDB to be updated in the gdb on f drive in the AssessmentUnits Master (polygon) i believe\n",
    "#FinalGDBtoupdate:F:\\GIS\\PROJECTS\\ResearchAnalysis\\SEZ\\Data \\SEZ_Data.gdb\n",
    "\n",
    "#Monitoring Dashboard location\n",
    "#Finalsdelocation:f'Vector.SDE' Sde.Monitoring Sde. SEZ_Assessment_Unit\n",
    "\n",
    "#Threshold Location? sde.tabular"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lookup Dictionary for SEZ ID's -Old code uses AssessmentUnit_Master feature class in SEZ_Data.gdb- don't use for now\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#-----------------------------------------------------------------------------------#\n",
    "#Create look up dictionary for SEZ_ID fill in--currently works for stream erosion code--\n",
    "#-----------------------------------------------------------------------------------#\n",
    "#Add in SEZ_Survey table to match up parentglobalid to assessment unit name so we can match an sez_id\n",
    "#----------------------------------------------------------------##Convert feature class in gdb to Pandas DataFrame this is for REST Service\n",
    "# Set workspace environment\n",
    "arcpy.env.workspace = master_path\n",
    "\n",
    "# Specify the feature class name SEZ_Master\n",
    "#feature_class = \"AssessmentUnits_Master\"\n",
    "# Create a cursor to iterate over the rows in the feature class\n",
    "fields = ['Assessment_Unit_Name', 'SEZ_ID']\n",
    "\n",
    "data = []\n",
    "\n",
    "\n",
    "# Iterate over the rows in the second feature class and append to data list\n",
    "with arcpy.da.SearchCursor(SEZ_Master, fields) as cursor:\n",
    "    for row in cursor:\n",
    "        data.append(row)\n",
    "# Convert the data to a Pandas DataFrame\n",
    "df = pd.DataFrame(data, columns=fields)\n",
    "\n",
    "# Define function to update SEZ ID lookup dictionary\n",
    "def update_SEZID_lookup_dict(df, lookup_dict):\n",
    "    for index, row in df.iterrows():\n",
    "        # Update SEZ_ID column in DataFrame with data from the lookup dictionary\n",
    "        df.at[index, 'SEZ_ID'] = lookup_dict.get(row['Assessment_Unit_Name'], None)\n",
    "\n",
    "    return df\n",
    "\n",
    "# Assuming 'Assessment_Unit_Name' is the common identifier between DataFrame and lookup dictionary\n",
    "selected_columns = ['Assessment_Unit_Name', 'SEZ_ID']\n",
    "\n",
    "# Drop duplicates based on 'Assessment_Unit_Name' and keep the first occurrence\n",
    "unique_values = df.drop_duplicates(subset='Assessment_Unit_Name', keep='first')\n",
    "\n",
    "# Convert selected columns to dictionary\n",
    "lookup_dict = unique_values[selected_columns].set_index('Assessment_Unit_Name').to_dict(orient='index')\n",
    "\n",
    "# Display the dictionary\n",
    "print(lookup_dict)\n",
    "\n",
    "# Update 'SEZ_ID' in other DataFrame with data from the lookup dictionary do this for each indicator...\n",
    "#Other_df = update_SEZID_lookup_dict(Other_df, lookup_dict)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#-----------------------------------------------------------------------------------#\n",
    "# DONT USE YETT Create look up dictionary for SEZ_ID fill in with Global ID,SEZ ID, and Assessment Unit Name\n",
    "\n",
    "# Set workspace environment\n",
    "arcpy.env.workspace = master_path\n",
    "\n",
    "# Define the fields for SEZ_Master and the additional feature class\n",
    "Masterfields = ['Assessment_Unit_Name', 'SEZ_ID']\n",
    "surveyfields = ['assessment_unit_name', 'GlobalID']  # Add any additional fields you need\n",
    "\n",
    "# Create empty lists to store data\n",
    "Masterdata = []\n",
    "surveydata = []\n",
    "\n",
    "# Iterate over the rows in the SEZ_Master feature class and append to data list\n",
    "with arcpy.da.SearchCursor(SEZ_Master, Masterfields) as cursor:\n",
    "    for row in cursor:\n",
    "        Masterdata.append(row)\n",
    "\n",
    "# Iterate over the rows in the additional feature class and append to data list\n",
    "with arcpy.da.SearchCursor(sezsurveytable, surveyfields) as cursor:\n",
    "    for row in cursor:\n",
    "        surveydata.append(row)\n",
    "\n",
    "# Convert the data to Pandas DataFrames\n",
    "Masterdf = pd.DataFrame(Masterdata, columns=Masterfields)\n",
    "surveydf = pd.DataFrame(surveydata, columns=surveyfields)\n",
    "# Convert the column name in surveydf to match Masterdf\n",
    "surveydf = surveydf.rename(columns={'assessment_unit_name': 'Assessment_Unit_Name'})\n",
    "# Merge the DataFrames on 'Assessment_Unit_Name'\n",
    "SEZIDdf = pd.merge(Masterdf, surveydf, on='Assessment_Unit_Name', how='inner')\n",
    "\n",
    "# Check for missing values in 'GlobalID' or 'SEZ_ID'\n",
    "missing_values = SEZIDdf[SEZIDdf['GlobalID'].isna() | SEZIDdf['SEZ_ID'].isna()]\n",
    "\n",
    "# Replace missing values in 'SEZ_ID' with NaN\n",
    "SEZIDdf.loc[missing_values.index, 'SEZ_ID'] = np.nan\n",
    "\n",
    "\n",
    "\n",
    "# Display the merged DataFrame\n",
    "print(SEZIDdf)\n",
    "# Assuming 'Assessment_Unit_Name' is the common identifier between DataFrame and lookup dictionary\n",
    "selected_columns = ['Assessment_Unit_Name', 'SEZ_ID', 'GlobalID']\n",
    "\n",
    "# Drop duplicates based on 'Assessment_Unit_Name' and keep the first occurrence\n",
    "unique_values = SEZIDdf.drop_duplicates(subset='Assessment_Unit_Name', keep='first')\n",
    "\n",
    "# Convert selected columns to dictionary\n",
    "lookup_dict = unique_values[selected_columns].set_index('Assessment_Unit_Name').to_dict(orient='index')\n",
    "\n",
    "# Display the dictionary\n",
    "print(lookup_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### New SEZ ID based off of excel file- larger polygons only"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Angora Creek - tributary': 519, 'Angora Creek - upper': 520, 'Angora meadows - 1': 87, 'Angora meadows - 2': 90, 'Angora meadows - 3': 91, 'Angora meadows - 4': 143, 'Angora meadows - 5': 144, 'Angora meadows - 6': 142, 'Angora meadows - 7': 89, 'Angora meadows - 8': 88, 'Angora meadows - 9': 92, 'Angora meadows tributary - 1': 217, 'Angora meadows tributary - 2': 99, 'Angora meadows tributary - 3': 97, 'Angora meadows tributary - 4': 94, 'Angora meadows tributary - 5': 214, 'Angora meadows tributary - 6': 146, 'Angora meadows tributary - 7': 93, 'Angora meadows tributary - 8': 95, 'Angora meadows tributary - 9': 96, 'Angora tributary': 446, 'Antone meadows': 187, 'Baldwin marsh - 1': 160, 'Benwood meadows - 1': 129, 'Benwood meadows - 2': 131, 'Big Meadow - 1': 47, 'Big Meadow - 2': 48, 'Big Meadow - 3': 38, 'Big Meadow - 4': 39, 'Big Meadow - 5': 37, 'Big Meadow - 6': 40, 'Big meadow - 7': 126, 'Big Meadow Creek - lower': 521, 'Big Meadow Creek - upper': 491, 'Big Meadow Creek - upper 2': 522, 'Bijou meadows - 1': 115, 'Bijou meadows - 2': 116, 'Bijou meadows - 3': 164, 'Bijou meadows - private': 114, 'Bijou meadows - tributary 1': 226, 'Bijou Park Creek meadows - 1': 219, 'Bijou Park Creek meadows - 2': 166, 'Bijou Park Creek meadows - 3': 167, 'Bijou Park Creek meadows - 4': 163, 'Bijou Park Creek meadows - 5': 489, 'Bijou Park Creek meadows - 6': 488, 'Blackwood Creek - lower 1': 523, 'Blackwood Creek - lower 2': 596, 'Blackwood Creek - middle 1': 597, 'Blackwood Creek - middle 2': 524, 'Blackwood Creek - middle 3': 598, 'Blackwood Creek - middle 4': 525, 'Blackwood Creek - Upper 1': 599, 'Blackwood Creek - Upper 2': 526, 'Blackwood Creek - upper 3': 527, 'Blackwood meadows - 1': 66, 'Blackwood meadows - 3': 65, 'Buck Lake meadows': 176, 'Buddhas meadow': 168, 'Burke Creek - middle': 528, 'Burke Creek - upper': 503, 'Burke Creek meadows - 1': 171, 'Burke Creek meadows - 2': 3, 'Burke Creek tributary': 461, 'Burton Creek - lower': 633, 'Burton Creek - upper': 529, 'Carnelian Canyon Creek - lower': 620, 'Carnelian Canyon Creek - upper': 621, 'Cascade Creek - lower': 501, 'Cascade Creek - upper': 498, 'Casino meadows': 170, 'Christmas Valley meadows - 1': 136, 'Christmas Valley meadows - 2': 134, 'Christmas Valley meadows - 3': 130, 'Christmas Valley meadows - 4': 225, 'Cold Creek - Highland Woods': 110, 'Cold Creek - middle': 530, 'Cold Creek - tributary 1': 532, 'Cold Creek - tributary 2': 533, 'Cold Creek - tributary 3': 531, 'Cold Creek - upper': 534, 'Cold Creek tributary - 4': 465, 'Cold Creek tributary - 5': 466, 'Colony Inn meadows - lower': 169, 'Colony Inn meadows - upper': 485, 'Cookhouse meadow': 128, 'Deer Creek - headwaters': 535, 'Deer Creek - lower': 537, 'Deer Creek - middle': 538, 'Deer Creek - middle 2': 539, 'Deer Creek - upper': 536, 'Deer Creek meadows': 30, 'Dollar Creek - lower': 540, 'Dollar Creek - upper': 512, 'Eagle Creek': 497, 'Echo Creek - below lake': 541, 'Echo Creek - upper': 494, 'Edgewood Creek - middle': 542, 'Edgewood Creek tributary - 2 - headwaters': 462, 'Edgewood Creek tributary - 2 - upper': 635, 'Edgewood Creek tributary - 2 - lower': 476, 'Edgewood Creek tributary - 3 - lower': 628, 'Edgewood Creek tributary - 3 - upper': 629, 'Edgewood meadows': 221, 'Elks Club meadows - 1': 141, 'Elks Club meadows - 2': 85, 'Fallen Leaf meadows - 1': 154, 'Fallen Leaf meadows - 2': 155, 'Fallen Leaf meadows - 3': 147, 'Fallen Leaf meadows - 4': 76, 'First Creek - lower': 543, 'First Creek - upper': 516, 'Freel Meadows - 1': 25, 'Freel Meadows - 2': 24, 'Gardner meadow': 150, 'General Creek - lower': 544, 'General Creek - middle': 506, 'General Creek - upper': 545, 'General Creek meadows': 61, 'Ginny Lake Meadows': 193, 'Glen Alpine Creek - lower': 546, 'Glen Alpine Creek - upper': 606, 'Glenbrook Creek - middle': 510, 'Glenbrook Creek - upper': 547, 'Glenbrook meadows - 1': 177, 'Glenbrook meadows - 2': 178, 'Golden Bear meadows - 1': 212, 'Golden Bear meadows - 2': 196, 'Grass Lake Creek': 609, 'Grass Lake meadow': 127, 'Griff Creek - lower': 514, 'Griff Creek - tributary': 548, 'Griff Creek - upper': 549, 'Griff Creek meadows': 35, 'Haypress Meadows': 50, 'Heavenly Valley Creek - middle': 550, 'Heavenly Valley Creek - upper': 499, 'Heavenly Valley Creek meadows - 1': 111, 'Heavenly Valley Creek meadows - 2': 112, 'Heavenly Valley Creek meadows - 3': 152, 'Heavenly Valley Creek meadows - 4': 113, 'Hell Hole meadows - 1': 230, 'Hell Hole Meadows - 2': 8, 'Hidden Valley Creek - lower': 551, 'Hidden Valley Creek - upper': 552, 'High meadows - 1': 203, 'High meadows - 2': 198, 'High Meadows - 3': 200, 'High meadows - 4': 202, 'High meadows - 6': 437, 'Homewood Canyon Creek - lower': 600, 'Homewood Canyon Creek - upper': 508, 'Incline Creek - lower': 553, 'Incline Creek - middle 1': 554, 'Incline Creek - middle 2': 555, 'Incline Creek - middle 3': 636, 'Incline Creek - ski run': 556, 'Incline Creek - upper': 557, 'Incline Lake meadows - 1': 192, 'Incline Lake meadows - 2': 190, 'Incline Village tributary - 1': 458, 'Incline Village tributary - 2': 459, 'Incline Village tributary - 3': 460, 'Incline Village tributary - 4': 457, 'Kahle meadows - 2': 204, 'Kahle meadows - 3': 172, 'Kahle meadows - 4': 468, 'Kahle meadows - 5': 118, 'Kahle meadows - 6': 469, 'Kahle meadows - 7': 119, 'Kahle meadows - 8': 486, 'Kingsbury meadows': 222, 'Lake Forest meadows - 1': 185, 'Lake Forest meadows - 2': 186, 'Lake Forest meadows - 3': 184, 'Lake Forest meadows - 4': 487, 'Lake Forest meadows - 5': 223, 'Lake Forest meadows - 6': 183, 'Lake Forest tributary': 624, 'Lakeshore meadows': 72, 'Logan House Creek - lower': 558, 'Logan House Creek - upper': 507, 'Logan House meadow': 13, 'Lonely Gulch Creek - lower': 559, 'Lonely Gulch Creek - middle': 560, 'Lonely Gulch Creek - upper': 504, 'Madden Creek': 561, 'Marlette Creek - lower': 562, 'Marlette Creek - old dam site': 564, 'Marlette Creek - south fork (lower)': 642, 'Marlette Creek - south fork (upper)': 563, 'Marlette Creek - upper': 631, 'Marlette Lake meadows': 32, 'McFaul Creek - lower': 565, 'McFual meadow': 71, 'McKinney Creek - lower': 566, 'McKinney Creek - middle': 567, 'McKinney Creek - upper': 505, 'McKinney tributary - 1': 626, 'McKinney tributary - 2': 453, 'Meeks Bay meadows - 1': 205, 'Meeks Bay meadows - 2': 207, 'Meeks Bay meadows - 3': 36, 'Meeks Bay meadows - 4': 206, 'Meeks Creek - upper': 502, 'Meeks Bay Lagoon': 235, 'Meiss meadows - 1': 123, 'Meiss meadows - 2': 122, 'Meiss meadows - 3': 124, 'Meiss meadows - 4': 210, 'Meiss meadows - 5': 209, 'Meyers meadow': 218, 'Meyers tributary - 1': 447, 'Meyers tributary - 2': 467, 'Mill Creek - lower': 568, 'Mill Creek - upper': 515, 'Mill Creek meadows': 234, 'Mount Rainier Drive meadows - 1': 215, 'Mount Rainier Drive meadows - 2': 216, 'Muskawi Drive meadows': 83, 'North Logan House Creek': 509, 'North Logan House meadows': 12, 'North Zephyr Creek - lower': 570, 'North Zephyr Creek - middle': 615, 'North Zephyr Creek - tributary': 569, 'North Zephyr Creek - upper': 571, 'Nottaway Drive meadows': 213, 'Osgood Creek - above road': 572, 'Osgood Creek - below road': 573, 'Osgood Swamp': 482, 'Paige meadows': 182, 'Pope marsh meadow': 483, 'Quail Creek - lower': 574, 'Quail Creek - upper': 575, 'Quail Creek meadow': 26, 'Rosewood Creek - lower': 576, 'Rosewood Creek - middle 1': 586, 'Rosewood Creek - middle 2': 587, 'Rosewood Creek - middle 3': 588, 'Rubicon Creek': 601, 'Rubicon Creek - tributary': 602, 'Rubicon Meadows': 60, 'Saxon Creek - headwaters': 495, 'Saxon Creek - upper': 641, 'Saxon Creek meadows - above Fountain Place 1': 2, 'Saxon Creek meadows - above Fountain Place 2': 102, 'Saxon Creek meadows - below Fountain Place': 1, 'Saxon Creek tributary meadows - 1': 101, 'Saxon Creek tributary meadows - 3': 100, 'Saxon Creek tributary meadows - 4': 140, 'Saxon Creek tributary meadows - 5': 197, 'Saxon Creek tributary meadows - 6': 139, 'Saxon Creek tributary meadows - 7': 231, 'Second Creek - lower': 591, 'Second Creek - lower 2': 592, 'Second Creek - middle': 593, 'Second Creek - upper': 517, 'Secret Harbor Creek - lower': 618, 'Secret Harbor Creek - upper': 619, 'Sierra Tract wetlands': 211, 'Ski Run meadows': 220, 'Sky meadows': 79, 'Skylandia SEZ': 622, 'Slaughterhouse Creek - lower': 614, 'Slaughterhouse Creek - middle': 616, 'Slaughterhouse Creek - upper': 617, 'Slaughterhouse Meadows - 1': 6, 'Slaughterhouse meadows - 2': 180, 'small meadow 1': 11, 'small meadow 10': 64, 'small meadow 100': 77, 'small meadow 105': 125, 'small meadow 111': 132, 'small meadow 112': 133, 'small meadow 113': 135, 'small meadow 116': 181, 'small meadow 13': 20, 'small meadow 14': 19, 'small meadow 15': 18, 'small meadow 16': 21, 'small meadow 17': 28, 'small meadow 19': 63, 'small meadow 2': 10, 'small meadow 20': 623, 'small meadow 21': 67, 'small meadow 22': 53, 'small meadow 23': 54, 'small meadow 24': 56, 'small meadow 25': 55, 'small meadow 26': 57, 'small meadow 27': 58, 'small meadow 28': 59, 'small meadow 29': 174, 'small meadow 3': 70, 'small meadow 30': 175, 'small meadow 32': 51, 'small meadow 35': 49, 'small meadow 36': 52, 'small meadow 40': 74, 'small meadow 5': 29, 'small meadow 50': 23, 'small meadow 51': 42, 'small meadow 52': 41, 'small meadow 54': 22, 'small meadow 56': 46, 'small meadow 57': 73, 'small meadow 58': 173, 'small meadow 59': 14, 'small meadow 6': 17, 'small meadow 7': 27, 'small meadow 8': 69, 'small meadow 82': 232, 'small meadow 9': 68, 'small meadow 92': 31, 'small meadow 93': 33, 'small meadow 95': 43, 'small meadow 96': 44, 'small meadow 98': 62, 'small meadow 99': 75, 'Snow Creek tributary - 1': 451, 'Snow Creek tributary - 2': 452, 'Snow Creek wetlands - 1': 188, 'Snow Creek wetlands - 2': 189, 'South Lake Tahoe - wetland 1': 229, 'South Lake Tahoe airport': 484, 'South Lake Tahoe tributary - 1': 463, 'South Lake Tahoe tributary - 2': 464, 'South Lake Tahoe tributary - 3': 627, 'Spooner meadows - 1': 445, 'Spooner meadows - 2': 431, 'Spooner meadows - 3': 120, 'Spooner Meadows - 4': 5, 'Spooner meadows - 5': 121, 'Star Lake meadows': 45, 'Susquehana meadows - 1': 108, 'Susquehana meadows - 2': 107, 'Tahoe City meadow': 224, 'Tahoe City tributary - 1': 449, 'Tahoe City tributary - 2': 450, 'Tahoe Island meadows - 1': 158, 'Tahoe Island meadows - 2': 156, 'Tahoe Keys': 162, 'Tahoe Paradise golf course': 632, 'Tahoe Valley meadows - 1': 153, 'Tahoe Valley meadows - 2': 228, 'Tahoe Vista meadows': 227, 'Tallac Creek - abv highway - 1': 334, 'Tallac Creek - abv highway - 2': 604, 'Tallac Creek - tributary': 500, 'Tallac marsh': 159, 'Tallac meadows': 157, 'Taylor Creek': 605, 'Taylor Creek marsh': 208, 'Third Creek - headwaters': 585, 'Third Creek - lower': 577, 'Third Creek - lower 2': 578, 'Third Creek - middle': 581, 'Third Creek - middle 1': 579, 'Third Creek - middle 2': 580, 'Third Creek - upper 1': 582, 'Third Creek - upper 2': 584, 'Third Creek - upper 3': 583, 'Third Creek meadows - 1': 191, 'Third Creek meadows - 3': 34, 'Third Creek meadows - 4': 195, 'Third Creek meadows - 6': 194, 'Third Creek meadows - 7': 16, 'Third Creek meadows - 8': 15, 'Trout Creek - Highland Woods': 109, 'Trout Creek - tributary 2': 613, 'Trout Creek - tributary 3': 612, 'Trout Creek - upper': 496, 'Trout Creek above Black Bart': 149, 'Trout Creek below Black Bart': 161, 'Trout Creek headwaters meadows - 1': 137, 'Trout Creek headwaters meadows - 2': 9, 'Trout Creek meadows - above Fountain Place': 103, 'Trout Creek meadows - above Pioneer 1': 148, 'Trout Creek meadows - above Pioneer 2': 106, 'Trout Creek meadows - above Pioneer 3': 105, 'Trout Creek meadows - above Pioneer 4': 104, 'Upper Truckee River - Meyers': 138, 'Upper Truckee River - Tahoe Paradise': 7, 'UTR - Airport reach': 82, 'UTR - Christmas Valley 1': 608, 'UTR - Christmas Valley 3': 493, 'UTR - golf course meadows': 86, 'UTR - Johnson meadows - 2': 151, 'UTR - Johnson meadows - 3': 81, 'UTR - middle': 492, 'UTR - Reach 5': 80, 'UTR - Reach 6': 84, 'UTR - tributary 1': 610, 'UTR - tributary 3': 611, 'UTR - upper': 490, 'UTR - Washoe Meadows': 607, 'UTR marsh - Trout Creek side': 165, 'UTR Marsh - UTR side': 78, 'Van Sickle meadows': 117, 'Ward Creek - lower': 594, 'Ward Creek - middle': 595, 'Ward Creek - upper': 511, 'Ward Creek meadow': 625, 'Washoan Blvd meadows': 145, 'Washoe State Parks meadow - 1': 4, 'Washoe State Parks meadow - 2': 98, 'Watson Creek': 513, 'West Shore tributary - 1': 455, 'West Shore tributary - 2 - lower': 639, 'West Shore tributary - 2 - upper': 448, 'West Shore tributary - 3': 456, 'West Shore tributary - 4': 454, 'Woods Creek - lower': 589, 'Woods Creek - middle': 590, 'Woods Creek - upper': 518, 'High meadows - 5': 201}\n"
     ]
    }
   ],
   "source": [
    "#-----------------------------------------------------------------------------------#\n",
    "#Create look up dictionary for SEZ_ID fill in--currently works for stream erosion code--- change to use excel so its not messy\n",
    "#-----------------------------------------------------------------------------------#\n",
    "\n",
    "# Step 1: Read the Excel file into a DataFrame\n",
    "excel_data = pd.read_excel(\"F:\\GIS\\PROJECTS\\ResearchAnalysis\\SEZ\\SEZID lookup.xlsx\")  # Replace 'your_excel_file.xlsx' with the path to your Excel file\n",
    "\n",
    "#Define Empty look up dataframe\n",
    "lookup_dict = {}\n",
    "\n",
    "for index, row in excel_data.iterrows():\n",
    "    lookup_dict[row['Assessment_Unit_Name']] = row['SEZ_ID']\n",
    "\n",
    "# See dictionary where keys are Assessment Unit Names and values are SEZ IDs\n",
    "print(lookup_dict)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pprint\n",
    "\n",
    "# Display the dictionary using pprint\n",
    "pprint.pprint(lookup_dict)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Code for Grading each parameter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Grading for each parameter \n",
    "#Defining Grade for Bank Stability based on Erosiondf[percent_unstable]\n",
    "def categorize_erosion(Percent_Unstable):\n",
    "    if 0 <= Percent_Unstable < 5:\n",
    "        return 'A'\n",
    "    elif 5 <= Percent_Unstable < 20:\n",
    "        return 'B'\n",
    "    elif 20 <= Percent_Unstable < 50:\n",
    "        return 'C'\n",
    "    else:\n",
    "        return 'D'\n",
    "    \n",
    "#Scoring based off of grading - check this\n",
    "def score_indicator(Rating):\n",
    "    if  Rating == 'A':\n",
    "        return '12'\n",
    "    elif Rating == 'B':\n",
    "        return '9'\n",
    "    elif Rating == 'C':\n",
    "        return '6'\n",
    "    else:\n",
    "        return '3'\n",
    "\n",
    "#Define Grade for Incision based off of incisino ratio\n",
    "\n",
    "def categorize_incision(bankfull_ratio):\n",
    "    if 0 <= bankfull_ratio < 1.2:\n",
    "        return 'A'\n",
    "    elif 1.2 <= bankfull_ratio < 1.6:\n",
    "        return 'B'\n",
    "    elif 1.6 <= bankfull_ratio < 2.1:\n",
    "        return 'C'\n",
    "    else:\n",
    "        return 'D'\n",
    "\n",
    "#Define Grade for Bioassessment Score\n",
    "#def categorize_csci(biotic_integrity)\n",
    " #    if   biotic_integrity > 0.92:\n",
    "  #      return 'A'\n",
    "   # elif 0.79 < biotic_integrity <= 0.92:\n",
    "    #    return 'B'\n",
    "    #elif 0.62 < biotic_integrity <= 0.79:\n",
    "     #   return 'C'\n",
    "    #else:\n",
    "     #   return 'D'\n",
    "\n",
    "#Define Grade for Invasive Plant Species Rating\n",
    "\n",
    "#def categorize_invasive(Invasive_Level)\n",
    "      \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#Define Size for Headcut based off of headcut size\n",
    "##A = 0 headcut, B 1+small headcut\n",
    "def categorize_headcut(headcutdepth):\n",
    "    if pd.isnull(headcutdepth) or headcutdepth == 0:\n",
    "        return np.nan\n",
    "    elif 0.1 <= headcutdepth < 0.5:\n",
    "        return 'small'\n",
    "    elif 0.5 <= headcutdepth < 1:\n",
    "        return 'medium'\n",
    "    else:\n",
    "        return 'large'\n",
    "\n",
    "#define rating for headcut health per sez\n",
    "def rate_headcut(row):\n",
    "    # Check if the SEZ has at least one large headcut\n",
    "    if row['large'] >= 1:\n",
    "        return 'D'  # Assign score D\n",
    "    elif row['medium'] >= 1:\n",
    "        return 'C'  # Assign score C\n",
    "    elif row['small'] >= 1:\n",
    "       return 'B'  # Assign score B\n",
    "    else:\n",
    "        return 'A'  # Assign score A (no headcuts)\n",
    "#Define grade for Headcut based off of headcut size---fix this\n",
    "##A = 0 headcut, B 1+small headcut\n",
    "#def categorize_headcutgrade(headcutsize):\n",
    " #   if pd.isnull(headcutsize):\n",
    "  #      return 'A'\n",
    "   # elif headcutsize == 'small':\n",
    "    #    return 'B'\n",
    "    #elif headcutsize == 'medium':\n",
    "     #   return 'C'\n",
    "    #else:\n",
    "     #   return 'D'\n",
    "\n",
    "#Define Grade for Invasive \n",
    "#A=0, B=1 level 2, C 2 level 2 or 1 level 1, D=3+ level 2 or 2+ level 1\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Stream Erosion "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#----------------------------------------------------------------#\n",
    "#Get Data\n",
    "#----------------------------------------------------------------##Convert feature class in gdb to Pandas DataFrame this is for REST Service\n",
    "erosionfields = ['Assessment_Unit_Name', 'Shape.STLength()', 'Bank_Type', 'Survey_Date']\n",
    "#erosiondf = pd.DataFrame.from_records(data=arcpy.da.SearchCursor(erosiondata, erosionfields), columns=erosionfields)\n",
    "\n",
    "# Initialize an empty list to store data\n",
    "data = []\n",
    "\n",
    " # Iterate over the rows in the feature class and extract data\n",
    "with arcpy.da.SearchCursor(erosiondata, erosionfields) as cursor:\n",
    "    for row in cursor:\n",
    "        data.append(row)\n",
    "\n",
    "# Convert the data to a Pandas DataFrame\n",
    "erosiondf = pd.DataFrame(data, columns=erosionfields)\n",
    "\n",
    "# Replace NaN values in 'Assessment_Unit_Name' column with 'Skylandia SEZ'\n",
    "#erosiondf['Assessment_Unit_Name'] = erosiondf['Assessment_Unit_Name'].fillna('Skylandia SEZ')\n",
    "# Replace specific values in 'Assessment_Unit_Name' column\n",
    "erosiondf['Assessment_Unit_Name'] = erosiondf['Assessment_Unit_Name'].replace({'Blackwood Creek - upper 2': 'Blackwood Creek - Upper 2', 'Taylor Creek marsh - 1': 'Taylor Creek marsh'})\n",
    "\n",
    "\n",
    "#Add SEZ_ID column using lookup dictionary\n",
    "#erosiondf['SEZ_ID'] = erosiondf['Assessment_Unit_Name'].map(lambda x: lookup_dict.get(x, {}).get('SEZ_ID', None))\n",
    "\n",
    "#This code is for the excel look up dictionary\n",
    "erosiondf['SEZ_ID'] = erosiondf['Assessment_Unit_Name'].map(lookup_dict)\n",
    "\n",
    "\n",
    "# Fill NaN values with a specific value, such as 0\n",
    "erosiondf['SEZ_ID'] = erosiondf['SEZ_ID'].fillna(0)\n",
    "\n",
    "# Convert SEZ ID column to integer\n",
    "erosiondf['SEZ_ID'] = erosiondf['SEZ_ID'].astype(int)\n",
    "\n",
    "#erosiondf = erosiondf.merge(df, on='Assessment_Unit_Name', how='left')\n",
    "\n",
    "#calculate year column \n",
    "erosiondf['Year'] = erosiondf['Survey_Date'].dt.year\n",
    "\n",
    "# Replace 'both_banks' with 'Both Banks' in Bank_Type column\n",
    "erosiondf['Bank_Type'] = erosiondf['Bank_Type'].replace(['both_banks', 'Both banks'], 'Both Banks' )\n",
    "erosiondf['Bank_Type'] = erosiondf['Bank_Type'].replace(['one_bank', 'One bank'], 'One Bank')\n",
    "erosiondf['Bank_Type'] = erosiondf['Bank_Type'].replace(['no_bank', 'No bank'], 'No Bank')\n",
    "\n",
    "#----------------------------------------------------------------#\n",
    "#Process Data\n",
    "#----------------------------------------------------------------#\n",
    "\n",
    "# Initialize variables\n",
    "erosiondf['bank_multiplier'] = erosiondf['Bank_Type'].apply(lambda x: 2 if x == 'Both Banks' else (1 if x == 'One Bank' else 0))\n",
    "\n",
    "\n",
    "# Calculate the product of 'Shape.STLength()' and 'bank_multiplier' to get the eroded banks per row\n",
    "erosiondf['eroded_banks_per_row'] = erosiondf['Shape.STLength()'] * erosiondf['bank_multiplier']\n",
    "\n",
    "# Group by Assessment_Unit_Name and year and sum the lengths of banks for each unit to get total banks assessed\n",
    "erosiondf['banks_assessed_per_unit'] = erosiondf.groupby(['Assessment_Unit_Name', 'Year'])['Shape.STLength()'].transform('sum') * 2\n",
    "\n",
    "# Group by Assessment_Unit_Name and sum the eroded banks per row for each unit\n",
    "erosiondf['SEZ_total_eroded'] = erosiondf.groupby(['Assessment_Unit_Name', 'Year'])['eroded_banks_per_row'].transform('sum')\n",
    "\n",
    "# Calculate percent unstable Bank Stability per Assessment Unit\n",
    "erosiondf['Bank_Stability_Percent_Unstable'] = (erosiondf['SEZ_total_eroded'] / erosiondf['banks_assessed_per_unit']) * 100\n",
    "\n",
    "#----------------------------------------------------------------#\n",
    "#Grade, Score\n",
    "#----------------------------------------------------------------#\n",
    "erosiondf['Bank_Stability_Rating']=erosiondf['Bank_Stability_Percent_Unstable'].apply(categorize_erosion)\n",
    "erosiondf['Bank_Stability_Score']= erosiondf['Bank_Stability_Rating'].apply(score_indicator)\n",
    "\n",
    "erosiondf['Bank_Stability_Data_Source'] = 'TRPA'\n",
    "\n",
    "erosiondf.head()\n",
    "\n",
    "print(erosiondf)\n",
    "#----------------------------------------------------------------#\n",
    "#post ending dataframe to bank_stability called stage_bank_stability GDB location\n",
    "#----------------------------------------------------------------#\n",
    "# Define the name of the feature class\n",
    "feature_class_name = 'bank_stability'\n",
    "\n",
    "# Define the full path to the feature class\n",
    "feature_class_path = stage_bank_stability \n",
    "\n",
    "#Field Mapping\n",
    "field_mapping = {\n",
    "    'Assessment_Unit_Name': 'Assessment_Unit_Name',\n",
    "    'Year': 'Year',\n",
    "    'Bank_Stability_Data_Source': 'Bank_Stability_Data_Source',\n",
    "    'Bank_Stability_Percent_Unstable': 'Bank_Stability_Percent_Unstable',\n",
    "    'Bank_Stability_Rating': 'Bank_Stability_Rating',\n",
    "    'Bank_Stability_Score': 'Bank_Stability_Score',\n",
    "    'SEZ_ID': 'SEZ_ID'\n",
    "}\n",
    "\n",
    "# Rename fields based on field mappings\n",
    "bank_stabilitydf = erosiondf.rename(columns=field_mapping).drop(columns=[col for col in erosiondf.columns if col not in field_mapping])\n",
    "\n",
    "readydf = bank_stabilitydf.groupby(['SEZ_ID', 'Year']).first().reset_index()\n",
    "\n",
    "# Convert \"Year\" column to datetime format with year frequency\n",
    "#readydf['Year'] = pd.to_datetime(readydf['Year'], format='%Y')\n",
    "\n",
    "# Fix data type of Year so it writes to table\n",
    "#readydf['Year'] = pd.to_datetime(readydf['Year'], format='%Y', errors='coerce')\n",
    "\n",
    "# Setting the frequency to 'Y' for year\n",
    "#readydf['Year'] = readydf['Year'].dt.to_period('Y')\n",
    "\n",
    "print(readydf)\n",
    "\n",
    "#Write dataframe to fc in SEZ_Data.GDB\n",
    "# Convert DataFrame to a list of dictionaries\n",
    "data = readydf.to_dict(orient='records')\n",
    "\n",
    "# Get the field names from the field mapping\n",
    "field_names = list(readydf.columns)\n",
    "\n",
    "# Append data to existing table\n",
    "with arcpy.da.InsertCursor(stage_bank_stability, field_names) as cursor:\n",
    "    for row in data:\n",
    "        cursor.insertRow([row[field] for field in field_names])\n",
    "\n",
    "print(\"Data appended to table successfully.\")\n",
    "\n",
    "\n",
    "#Write dataframe to sde.collect.bank.stability eventually, current code write it to GDB in SEZ_Data.GDB\n",
    "# Set environment workspace to your SDE connection file\n",
    "#arcpy.env.workspace = master_path\n",
    "\n",
    "# Convert DataFrame to Feature Class\n",
    "#output_feature_class = \"ErosionUpdate\"  # Name for the output feature class\n",
    "#output_fc_path = os.path.join(arcpy.env.workspace, output_feature_class)\n",
    "\n",
    "# Assuming your DataFrame is already converted to a feature class\n",
    "# Replace \"path_to_your_feature_class\" with the actual path to your feature class\n",
    "#arcpy.conversion.TableToTable(\"path_to_your_feature_class\", arcpy.env.workspace, output_feature_class)\n",
    "\n",
    "# Overwrite Feature Class in SDE\n",
    "# Replace \"path_to_your_dataframe\" with the actual path to your DataFrame\n",
    "#arcpy.management.CopyFeatures(\"path_to_your_dataframe\", output_fc_path)\n",
    "\n",
    "\n",
    "#print(ready_df)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(readydf.dtypes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert DataFrame to CSV\n",
    "#csv_path = os.path.join(working_folder, \"Erosiondatamaster.csv\")\n",
    "#ready_df.to_csv(csv_path, index=False) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create lookup dictionary for parentglobalid,sez_id,Assessment unit\n",
    "\n",
    "#parentglobalid= global id in sez survey and then we can match upa ssessment unit name... do we even need this "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Channel Incision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                  Assessment_Unit_Name  incision_ratio         survey_date  \\\n",
      "0             Angora Creek - tributary             NaN 2023-05-24 12:00:00   \n",
      "1                   Angora meadows - 8             NaN 2023-05-24 12:00:00   \n",
      "2             Angora Creek - tributary             NaN 2023-05-24 12:00:00   \n",
      "3             Glenbrook Creek - middle             NaN 2023-05-30 12:00:00   \n",
      "4                Glenbrook meadows - 1        1.000000 2023-05-30 12:00:00   \n",
      "..                                 ...             ...                 ...   \n",
      "223              Hell Hole meadows - 1        1.365100 2022-10-17 12:00:00   \n",
      "224  Saxon Creek tributary meadows - 1        1.000000 2022-10-17 12:00:00   \n",
      "225                Griff Creek meadows        1.000000 2022-10-18 12:00:00   \n",
      "226              General Creek - lower        1.916733 2022-10-20 12:00:00   \n",
      "227                  Star Lake meadows        1.000000 2022-10-19 12:00:00   \n",
      "\n",
      "     SEZ_ID  Year  \n",
      "0       519  2023  \n",
      "1        88  2023  \n",
      "2       519  2023  \n",
      "3       510  2023  \n",
      "4       177  2023  \n",
      "..      ...   ...  \n",
      "223     230  2022  \n",
      "224     101  2022  \n",
      "225      35  2022  \n",
      "226     544  2022  \n",
      "227      45  2022  \n",
      "\n",
      "[228 rows x 5 columns]\n",
      "     SEZ_ID  Year                          Assessment_Unit_Name  \\\n",
      "0         0  2020                     Blackwood Creek - Upper 2   \n",
      "1         2  2019  Saxon Creek meadows - above Fountain Place 1   \n",
      "2         2  2022  Saxon Creek meadows - above Fountain Place 1   \n",
      "3         5  2023                           Spooner Meadows - 4   \n",
      "4         6  2023                    Slaughterhouse Meadows - 1   \n",
      "..      ...   ...                                           ...   \n",
      "199     633  2019                          Burton Creek - lower   \n",
      "200     641  2020                           Saxon Creek - upper   \n",
      "201     641  2022                           Saxon Creek - upper   \n",
      "202     641  2023                           Saxon Creek - upper   \n",
      "203     642  2020           Marlette Creek - south fork (lower)   \n",
      "\n",
      "     Incision_Ratio Incision_Rating Incision_Score Incision_Data_Source  \n",
      "0          1.142850               A             12                 TRPA  \n",
      "1          2.542367               D              3                 TRPA  \n",
      "2          2.107667               D              3                 TRPA  \n",
      "3               NaN               D              3                 TRPA  \n",
      "4               NaN               D              3                 TRPA  \n",
      "..              ...             ...            ...                  ...  \n",
      "199        1.000000               A             12                 TRPA  \n",
      "200        2.467957               D              3                 TRPA  \n",
      "201        1.529471               B              9                 TRPA  \n",
      "202        1.779729               C              6                 TRPA  \n",
      "203        2.363650               D              3                 TRPA  \n",
      "\n",
      "[204 rows x 7 columns]\n",
      "Data appended to table successfully.\n"
     ]
    }
   ],
   "source": [
    "#----------------------------------------------------------------#\n",
    "#Get Data-- all the data we need is in sde.collect.sde.survey.sde.sez_survey\n",
    "#----------------------------------------------------------------##Convert feature class in gdb to Pandas DataFrame this is for REST Service\n",
    "incisionfields = ['Assessment_Unit_Name', 'incision_ratio', 'survey_date']\n",
    "#incisiondf = pd.DataFrame.from_records(data=arcpy.da.SearchCursor(erosiondata, erosionfields), columns=erosionfields)\n",
    "\n",
    "# Initialize an empty list to store data\n",
    "data = []\n",
    "\n",
    " # Iterate over the rows in the feature class and extract data\n",
    "with arcpy.da.SearchCursor(sezsurveytable, incisionfields) as cursor:\n",
    "    for row in cursor:\n",
    "        data.append(row)\n",
    "\n",
    "# Convert the data to a Pandas DataFrame\n",
    "incisiondf = pd.DataFrame(data, columns=incisionfields)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#----------------------------------------------------------------#\n",
    "#Add correct info to dataframe\n",
    "#----------------------------------------------------------------#\n",
    "#use this until we fix the domain\n",
    "incisiondf['Assessment_Unit_Name'] = incisiondf['Assessment_Unit_Name'].replace({'Blackwood Creek - upper 2': 'Blackwood Creek - Upper 2', 'Taylor Creek marsh - 1': 'Taylor Creek marsh'})\n",
    "# Create a new column 'SEZ ID'\n",
    "#This code is for the excel look up dictionary\n",
    "incisiondf['SEZ_ID'] = incisiondf['Assessment_Unit_Name'].map(lookup_dict)\n",
    "\n",
    "\n",
    "# Fill NaN values with a specific value, such as 0\n",
    "incisiondf['SEZ_ID'] = incisiondf['SEZ_ID'].fillna(0)\n",
    "\n",
    "# Convert SEZ ID column to integer\n",
    "incisiondf['SEZ_ID'] = incisiondf['SEZ_ID'].astype(int)\n",
    "\n",
    "#calculate year column \n",
    "incisiondf['Year'] = incisiondf['survey_date'].dt.year\n",
    "\n",
    "\n",
    "#incisiondf['SEZ ID'] = np.nan\n",
    "\n",
    "# Iterate through the rows in incisiondf\n",
    "#for index, row in incisiondf.iterrows():\n",
    " #   parentglobalid = row['parentglobalid']\n",
    "    \n",
    "      # Check if the parent_global_id exists in the lookup dictionary\n",
    "  #  if parentglobalid in lookup_dict:\n",
    "        # If it exists, retrieve the corresponding SEZ ID and fill it into SEZ ID column\n",
    "   #     corresponding_entry = lookup_dict[parentglobalid]\n",
    "    #    assert row['GlobalID'] == parentglobalid, \"ParentGlobalID does not match GlobalID in the lookup dictionary\"\n",
    "     #   incisiondf.at[index, 'SEZ_ID'] = corresponding_entry['SEZ_ID']\n",
    "\n",
    "# Display the updated incisiondf\n",
    "print(incisiondf)\n",
    "\n",
    "#Add SEZ_ID column using lookup dictionary\n",
    "#incisiondf['SEZ_ID'] = SEZIDdf['GlobalID'].map(lambda x: lookup_dict.get(x, {}).get('SEZ_ID', None))\n",
    "\n",
    "# Fill NaN values with a specific value, such as 0\n",
    "#incisiondf['SEZ_ID'] = incisiondf['SEZ_ID'].fillna(0)\n",
    "\n",
    "# Convert SEZ ID column to integer\n",
    "#incisiondf['SEZ_ID'] = incisiondf['SEZ_ID'].astype(int)\n",
    "\n",
    "#incisiondf = incisiondf.merge(df, on='Assessment_Unit_Name', how='left')\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#----------------------------------------------------------------#\n",
    "#Grade, Score\n",
    "#----------------------------------------------------------------#\n",
    "incisiondf['Incision_Rating']=incisiondf['incision_ratio'].apply(categorize_incision)\n",
    "incisiondf['Incision_Score']= incisiondf['Incision_Rating'].apply(score_indicator)\n",
    "\n",
    "incisiondf['Incision_Data_Source'] = 'TRPA'\n",
    "\n",
    "incisiondf.head()\n",
    "#----------------------------------------------------------------#\n",
    "#post ending dataframe to incision called stage_incision GDB location\n",
    "#----------------------------------------------------------------#\n",
    "# Define the name of the feature class\n",
    "feature_class_name = 'incision'\n",
    "\n",
    "# Define the full path to the feature class\n",
    "feature_class_path = stage_incision \n",
    "\n",
    "#Field Mapping\n",
    "field_mapping = {\n",
    "    'Assessment_Unit_Name': 'Assessment_Unit_Name',\n",
    "    'Year': 'Year',\n",
    "    'Incision_Data_Source': 'Incision_Data_Source',\n",
    "    'incision_ratio': 'Incision_Ratio',\n",
    "    'Incision_Rating': 'Incision_Rating',\n",
    "    'Incision_Score': 'Incision_Score',\n",
    "    'SEZ_ID': 'SEZ_ID'\n",
    "}\n",
    "\n",
    "# Rename fields based on field mappings\n",
    "incisionfinaldf = incisiondf.rename(columns=field_mapping).drop(columns=[col for col in incisiondf.columns if col not in field_mapping])\n",
    "\n",
    "readydf = incisionfinaldf.groupby(['SEZ_ID', 'Year']).first().reset_index()\n",
    "\n",
    "# Convert \"Year\" column to datetime format with year frequency\n",
    "#readydf['Year'] = pd.to_datetime(readydf['Year'], format='%Y')\n",
    "\n",
    "print(readydf)\n",
    "\n",
    "#Write dataframe to fc in SEZ_Data.GDB\n",
    "# Convert DataFrame to a list of dictionaries\n",
    "data = readydf.to_dict(orient='records')\n",
    "\n",
    "# Get the field names from the field mapping\n",
    "field_names = list(readydf.columns)\n",
    "\n",
    "# Append data to existing table\n",
    "with arcpy.da.InsertCursor(stage_incision, field_names) as cursor:\n",
    "    for row in data:\n",
    "        cursor.insertRow([row[field] for field in field_names])\n",
    "\n",
    "print(\"Data appended to table successfully.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Invasive Species"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Invasive Species\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### HEadcuts\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                      Assessment_Unit_Name  headcut_depth        created_date\n",
      "0                   Susquehana meadows - 1           0.50 2019-05-13 00:00:00\n",
      "1                   Susquehana meadows - 1           0.50 2019-05-13 00:00:00\n",
      "2                  Golden Bear meadows - 1           0.60 2019-05-13 00:00:00\n",
      "3                  Golden Bear meadows - 1           0.40 2019-05-13 00:00:00\n",
      "4                  Golden Bear meadows - 1           0.70 2019-05-13 00:00:00\n",
      "..                                     ...            ...                 ...\n",
      "601     Trout Creek headwaters meadows - 1           0.40 2023-08-18 18:10:40\n",
      "602     Trout Creek headwaters meadows - 1           0.44 2023-08-18 18:10:40\n",
      "603  Trout Creek meadows - above Pioneer 4           1.30 2023-08-30 23:05:09\n",
      "604               Incline Lake meadows - 2           0.50 2023-09-18 15:26:54\n",
      "605               Incline Lake meadows - 2           1.30 2023-09-18 15:26:54\n",
      "\n",
      "[606 rows x 3 columns]\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Headcut_Size          Assessment_Unit_Name  Year  large  medium  small\n",
      "0                 Angora Creek - tributary  2023      0       0      4\n",
      "1                       Angora meadows - 5  2019      1       1      2\n",
      "2                       Angora meadows - 8  2019      0       0      1\n",
      "3                       Angora meadows - 8  2023      2       0      0\n",
      "4             Angora meadows tributary - 1  2019      0       1      0\n",
      "..                                     ...   ...    ...     ...    ...\n",
      "95                          small meadow 2  2022      0       3      2\n",
      "96                         small meadow 24  2023      0       0      1\n",
      "97                          small meadow 5  2019      1       0      0\n",
      "98                          small meadow 7  2023      1       2      4\n",
      "99                         small meadow 95  2019      0       1      0\n",
      "\n",
      "[100 rows x 5 columns]\n",
      "Headcut_Size          Assessment_Unit_Name  Year  large  medium  small  \\\n",
      "0                 Angora Creek - tributary  2023      0       0      4   \n",
      "1                       Angora meadows - 5  2019      1       1      2   \n",
      "2                       Angora meadows - 8  2019      0       0      1   \n",
      "3                       Angora meadows - 8  2023      2       0      0   \n",
      "4             Angora meadows tributary - 1  2019      0       1      0   \n",
      "..                                     ...   ...    ...     ...    ...   \n",
      "95                          small meadow 2  2022      0       3      2   \n",
      "96                         small meadow 24  2023      0       0      1   \n",
      "97                          small meadow 5  2019      1       0      0   \n",
      "98                          small meadow 7  2023      1       2      4   \n",
      "99                         small meadow 95  2019      0       1      0   \n",
      "\n",
      "Headcut_Size Headcuts_Rating  Number_of_Headcuts Headcuts_Score  \\\n",
      "0                          B                   4              9   \n",
      "1                          D                   4              3   \n",
      "2                          B                   1              9   \n",
      "3                          D                   2              3   \n",
      "4                          C                   1              6   \n",
      "..                       ...                 ...            ...   \n",
      "95                         C                   5              6   \n",
      "96                         B                   1              9   \n",
      "97                         D                   1              3   \n",
      "98                         D                   7              3   \n",
      "99                         C                   1              6   \n",
      "\n",
      "Headcut_Size Headcuts_Data_Source  SEZ_ID  \n",
      "0                            TRPA     519  \n",
      "1                            TRPA     144  \n",
      "2                            TRPA      88  \n",
      "3                            TRPA      88  \n",
      "4                            TRPA     217  \n",
      "..                            ...     ...  \n",
      "95                           TRPA      10  \n",
      "96                           TRPA      56  \n",
      "97                           TRPA      29  \n",
      "98                           TRPA      27  \n",
      "99                           TRPA      43  \n",
      "\n",
      "[100 rows x 10 columns]\n",
      "Data appended to table successfully.\n"
     ]
    }
   ],
   "source": [
    "#Headcuts\n",
    "#--------------------------------#\n",
    "#Get Data from GDB's with assessment unit name \n",
    "#--------------------------------#\n",
    "\n",
    "# Paths to the feature classes\n",
    "headcut19fc = os.path.join(headcut19gdb, \"Stream_Headcut_2019\")\n",
    "headcut20fc = os.path.join(headcut20gdb, \"Stream_Headcut_2020\")\n",
    "headcut22fc = os.path.join(headcut22gdb, \"Stream_Headcut_2022\")\n",
    "headcut23fc = os.path.join(headcut23gdb, \"sez_stream_headcut\")\n",
    "\n",
    "\n",
    "#Use gdb because they have assessment unit name in them... 2022 i had to manually add in PRO\n",
    "headcut23fields = ['Assessment_Unit', 'headcut_depth', 'created_date']\n",
    "headcut22fields = ['Assessment_Unit', 'Headcut_Depth', 'synced_date']\n",
    "headcut20fields = ['Assessment_Unit_Name', 'Headcut_Depth','Survey_Date']\n",
    "headcut19fields = ['SITE_NAME', 'HEADCUT_DEPTH', 'SURVEY_DATE' ]\n",
    "# Initialize an empty list to store data\n",
    "data = []\n",
    "\n",
    "\n",
    "# Function to read feature class into DataFrame\n",
    "def feature_class_to_dataframe(feature_class, fields):\n",
    "    data = [row for row in arcpy.da.SearchCursor(feature_class, fields)]\n",
    "    return pd.DataFrame(data, columns=fields)\n",
    "\n",
    "# Read feature classes into DataFrames\n",
    "# Read feature classes into DataFrames\n",
    "headcut19df = feature_class_to_dataframe(headcut19fc, headcut19fields)\n",
    "headcut20df = feature_class_to_dataframe(headcut20fc, headcut20fields)\n",
    "headcut22df = feature_class_to_dataframe(headcut22fc, headcut22fields)\n",
    "headcut23df = feature_class_to_dataframe(headcut23fc, headcut23fields)\n",
    "\n",
    "# Rename fields\n",
    "headcut19df.rename(columns={'SITE_NAME': 'Assessment_Unit_Name', 'HEADCUT_DEPTH': 'headcut_depth', 'SURVEY_DATE': 'created_date'}, inplace=True)\n",
    "headcut20df.rename(columns={'Assessment_Unit_Name': 'Assessment_Unit_Name', 'Headcut_Depth': 'headcut_depth', 'Survey_Date': 'created_date'}, inplace=True)\n",
    "headcut22df.rename(columns={'Assessment_Unit': 'Assessment_Unit_Name', 'Headcut_Depth': 'headcut_depth', 'synced_date': 'created_date'}, inplace=True)\n",
    "headcut23df.rename(columns={'Assessment_Unit': 'Assessment_Unit_Name', 'headcut_depth': 'headcut_depth', 'created_date': 'created_date'}, inplace=True)\n",
    "\n",
    "# Concatenate DataFrames\n",
    "headcutdf = pd.concat([headcut19df, headcut20df, headcut22df, headcut23df], ignore_index=True)\n",
    "\n",
    "# Display merged DataFrame\n",
    "print(headcutdf)\n",
    "\n",
    "#hopefully this is just one time\n",
    "\n",
    "\n",
    "#--------------------------------#\n",
    "#Get Data from exported table where Assessment Unit is joined---parentglobalids don't match up for years before 2023. need to redo sde.collect 2019-2022 data append.... \n",
    "#--------------------------------#\n",
    "\n",
    "#--------------------------------#\n",
    "#Get Data from SDE.Collect...instead of GDB\n",
    "#--------------------------------#\n",
    "#----------------------------------------------------------------#\n",
    "#Add correct info to dataframe\n",
    "#----------------------------------------------------------------#\n",
    "# Create a new column 'SEZ ID'\n",
    "#This code is for the excel look up dictionary---ADD last? this is goo dfor QA on assessment unit names because 0's tell you the name is wrong\n",
    "headcutdf['SEZ_ID'] = headcutdf['Assessment_Unit_Name'].map(lookup_dict)\n",
    "\n",
    "\n",
    "# Fill NaN values with a specific value, such as 0\n",
    "headcutdf['SEZ_ID'] = headcutdf['SEZ_ID'].fillna(0)\n",
    "\n",
    "# Convert SEZ ID column to integer\n",
    "headcutdf['SEZ_ID'] = headcutdf['SEZ_ID'].astype(int)\n",
    "headcutdf['Assessment_Unit_Name'] = headcutdf['Assessment_Unit_Name'].replace({'Blackwood Creek - upper 2': 'Blackwood Creek - Upper 2', 'Taylor Creek marsh - 1': 'Taylor Creek marsh', 'Sky meadows - 1': 'Sky Meadows'})\n",
    "\n",
    "#calculate year column \n",
    "headcutdf['Year'] = headcutdf['created_date'].dt.year\n",
    "\n",
    "#----------------------------------------------#\n",
    "# Process Data\n",
    "#----------------------------------------------#\n",
    "# assign small, medium, large to headcut\n",
    "headcutdf['Headcut_Size']=headcutdf['headcut_depth'].apply(categorize_headcut)\n",
    "\n",
    "\n",
    "# Group by 'SEZ_ID', 'Year', and 'Headcut_Size', and count the number of occurrences for each group\n",
    "headcut_summary = headcutdf.groupby(['Assessment_Unit_Name', 'Year', 'Headcut_Size']).size().reset_index(name='Count')\n",
    "\n",
    "print(type(headcut_summary))\n",
    "# Pivot the table to have 'Headcut_Size' categories as columns\n",
    "headcut_summary_sml = headcut_summary.pivot_table(index=['Assessment_Unit_Name', 'Year'], columns='Headcut_Size', values='Count', fill_value=0)\n",
    "\n",
    "# Reset the index to flatten the DataFrame\n",
    "headcut_summary_sml.reset_index(inplace=True)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Display the summarized DataFrame\n",
    "print(headcut_summary_sml)\n",
    "\n",
    "#----------------------------------------------------------------#\n",
    "#Grade, Score, # of Headcuts\n",
    "#----------------------------------------------------------------#\n",
    "    \n",
    "    # Process Data\n",
    "def rate_headcut(row):\n",
    "    # Check if the SEZ has at least one large headcut\n",
    "    if row['large'] >= 1:\n",
    "        return 'D'  # Assign score D\n",
    "    elif row['medium'] >= 1:\n",
    "        return 'C'  # Assign score C\n",
    "    elif row['small'] >= 1:\n",
    "       return 'B'  # Assign score B\n",
    "    else:\n",
    "        return 'A'  # Assign score A (no headcuts)\n",
    "\n",
    "# Apply the rating function to the summary DataFrame\n",
    "headcut_summary_sml['Headcuts_Rating'] = headcut_summary_sml.apply(rate_headcut, axis=1)\n",
    "\n",
    "#Calculate total number of headcuts per sez per year\n",
    "headcut_summary_sml['Number_of_Headcuts']= headcut_summary_sml[['large', 'medium', 'small']].sum(axis=1)\n",
    "\n",
    "#Calculate the score for the sez\n",
    "headcut_summary_sml['Headcuts_Score']= headcut_summary_sml['Headcuts_Rating'].apply(score_indicator)\n",
    "\n",
    "#Add Datasource\n",
    "headcut_summary_sml['Headcuts_Data_Source'] = 'TRPA'\n",
    "\n",
    "\n",
    "#----------------------------------------------------------------#\n",
    "#post ending dataframe to incision called stage_incision GDB location\n",
    "#----------------------------------------------------------------#\n",
    "\n",
    "\n",
    "#Field Mapping\n",
    "field_mapping = {\n",
    "    'Assessment_Unit_Name': 'Assessment_Unit_Name',\n",
    "    'Year': 'Year',\n",
    "    'Headcuts_Data_Source': 'Headcuts_Data_Source',\n",
    "    'Number_of_Headcuts': 'Number_of_Headcuts',\n",
    "    'Headcuts_Rating': 'Headcuts_Rating',\n",
    "    'Headcuts_Score': 'Headcuts_Score',\n",
    "    'SEZ_ID': 'SEZ_ID',\n",
    "    'small': 'small',\n",
    "    'medium': 'medium',\n",
    "    'large': 'large'\n",
    "}\n",
    "\n",
    "# Rename fields based on field mappings\n",
    "readydf = headcut_summary_sml.rename(columns=field_mapping).drop(columns=[col for col in headcut_summary_sml.columns if col not in field_mapping])\n",
    "\n",
    "readydf['SEZ_ID'] = readydf['Assessment_Unit_Name'].map(lookup_dict)\n",
    "\n",
    "# Convert \"Year\" column to datetime format with year frequency\n",
    "#readydf['Year'] = pd.to_datetime(readydf['Year'], format='%Y')\n",
    "\n",
    "print(readydf)\n",
    "\n",
    "# Convert DataFrame to a list of dictionaries\n",
    "data = readydf.to_dict(orient='records')\n",
    "\n",
    "# Get the field names from the field mapping\n",
    "field_names = list(readydf.columns)\n",
    "\n",
    "# Append data to existing table\n",
    "with arcpy.da.InsertCursor(stage_headcuts, field_names) as cursor:\n",
    "    for row in data:\n",
    "        cursor.insertRow([row[field] for field in field_names])\n",
    "\n",
    "print(\"Data appended to table successfully.\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bioassessment/ Biotic Integrity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Bioassessment scores- get all stream data into sde.Stream first... then look at Biotic Integrit Data Source to find which stream was used to evaluate each meadow.. this will help with percent of stream miles I believe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Conifer Encroachment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Aquatic Organism /Fish Passage"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Code to make it a spatially enabled dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#code to conver to spatially enable geodataframe\n",
    "# Create a new DataFrame Final_df with columns based on the field mapping\n",
    "#df = df.rename(columns=field_mapping)\n",
    "\n",
    "# Convert DataFrame to Spatially Enabled DataFrame\n",
    "#sedf = GeoAccessor.from_xy(df, x_column='LONGITUDE', y_column='LATITUDE')\n",
    "\n",
    "# Convert the SEDF to a feature class without sanitizing columns\n",
    "#sedf.spatial.to_featureclass(location=os.path.join(workspace, 'PlanAreaNoise_23_Staging'), sanitize_columns=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
